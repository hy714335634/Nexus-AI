#!/usr/bin/env python3
"""
å·¥ä½œæµæ€»ç»“æŠ¥å‘Šç”Ÿæˆå™¨
ç”¨äºè§£æå·¥ä½œæµæ‰§è¡Œç»“æœå¹¶ç”Ÿæˆè¯¦ç»†çš„æ€»ç»“æŠ¥å‘Š
åŸºäºå®˜æ–¹Strands GraphResultæ•°æ®ç»“æ„
"""

import os
import json
import time
from datetime import datetime
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict

# def extract_agent_result(agent_list: List[AgentResult]) -> Any:
#     for i in agent_list:
#         # metrics:
#         # EventLoopMetrics(
#         #     cycle_count=2, 
#         #     tool_metrics={
#         #         'calculator': ToolMetrics(
#         #             tool={
#         #                 'toolUseId': 'tooluse_tcu7yc8tTuiXU1hQ3tlxaw',
#         #                 'name': 'calculator', 
#         #                 'input': {'expression': '25 * 48'}
#         #                 'input': {'expression': '25 * 48'}
#         #             },
#         #         call_count=1,
#         #         success_count=1,
#         #         error_count=0,
#         #         total_time=0.009796857833862305
#         #         )
#         #     }, 
#         #     cycle_durations=[2.1938259601593018], 
#         #     traces=[
#         #         <strands.telemetry.metrics.Trace object at 0x10f1027b0>,
#         #         <strands.telemetry.metrics.Trace object at 0x10f115e00>
#         #     ], 
#         #     accumulated_usage={
#         #         'inputTokens': 3998,
#         #         'outputTokens': 87,
#         #         'totalTokens': 4085
#         #     }, 
#         #     accumulated_metrics={'latencyMs': 3656}
#         tool_metrics = i.metrics.tool_metrics



@dataclass
class StageMetrics:
    """å•ä¸ªé˜¶æ®µçš„æ‰§è¡ŒæŒ‡æ ‡"""
    stage_name: str
    start_time: Optional[str] = None
    end_time: Optional[str] = None
    duration: Optional[float] = None
    input_tokens: int = 0
    output_tokens: int = 0
    tool_calls: int = 0
    tool_call_details: List[Dict[str, Any]] = None
    success: bool = True
    error_message: Optional[str] = None
    
    def __post_init__(self):
        if self.tool_call_details is None:
            self.tool_call_details = []


@dataclass
class WorkflowSummary:
    """å·¥ä½œæµæ€»ä½“æ€»ç»“"""
    project_name: str
    workflow_start_time: str
    workflow_end_time: str
    total_duration: float
    total_input_tokens: int
    total_output_tokens: int
    total_tool_calls: int
    successful_stages: int
    failed_stages: int
    stages: List[StageMetrics]
    tool_usage_summary: Dict[str, int]
    cost_estimation: Dict[str, Any]
    project_config_summary: Optional[Dict[str, Any]] = None
    total_tools: int = 0


class WorkflowReportGenerator:
    """å·¥ä½œæµæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.stages_order = [
            "orchestrator",
            "requirements_analyzer", 
            "system_architect",
            "agent_designer",
            "tool_developer",
            "prompt_engineer",
            "agent_code_developer",
            "agent_developer_manager",
            "agent_deployer"
        ]
    
    def _load_project_config(self, project_dir: str) -> tuple[Optional[Dict[str, Any]], int]:
        """
        ä»é¡¹ç›®ç›®å½•ä¸­åŠ è½½project_config.jsonæ–‡ä»¶
        
        Args:
            project_dir: é¡¹ç›®ç›®å½•è·¯å¾„
            
        Returns:
            tuple: (project_config_summary, total_tools)
        """
        try:
            config_path = os.path.join(project_dir, "project_config.json")
            
            if not os.path.exists(config_path):
                print(f"âš ï¸ é¡¹ç›®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                return None, 0
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            # æå–summaryå’Œtotal_toolsä¿¡æ¯
            summary = config_data.get('summary', {})
            total_tools = config_data.get('total_tools', 0)
            
            print(f"ğŸ” æˆåŠŸåŠ è½½é¡¹ç›®é…ç½®: {config_path}")
            print(f"ğŸ” é¡¹ç›®é…ç½®æ‘˜è¦: {summary}")
            print(f"ğŸ” æ€»å·¥å…·æ•°é‡: {total_tools}")
            
            return summary, total_tools
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½é¡¹ç›®é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return None, 0
    
    def parse_workflow_result(self, graph_result: Any, project_dir: str = None) -> WorkflowSummary:
        """è§£æGraphResultå¯¹è±¡"""
        try:
            
            # æ£€æŸ¥accumulated_usage
            if hasattr(graph_result, 'accumulated_usage'):
                usage = graph_result.accumulated_usage
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°accumulated_usageå±æ€§")
            
            # æ£€æŸ¥results
            if hasattr(graph_result, 'results'):
                results = graph_result.results
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°resultså±æ€§")
            
            # æå–é¡¹ç›®åç§°
            project_name = self._extract_project_name_from_orchestrator(graph_result)
            
            # æå–æ—¶é—´ä¿¡æ¯
            workflow_start_time = datetime.now().isoformat()  # è¿™é‡Œåº”è¯¥ä»å®é™…æ‰§è¡Œæ—¶é—´è·å–
            workflow_end_time = datetime.now().isoformat()
            
            # è§£æå„ä¸ªé˜¶æ®µçš„æŒ‡æ ‡
            stages = self._parse_stages_metrics(graph_result)
            
            # ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿçº§åˆ«çš„çœŸå®Tokenç»Ÿè®¡
            total_input_tokens = 0
            total_output_tokens = 0
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç³»ç»Ÿçº§åˆ«çš„accumulated_usage
            # GraphResultç»§æ‰¿è‡ªMultiAgentResultï¼Œaccumulated_usageå¯èƒ½åœ¨çˆ¶ç±»ä¸­
            usage = None
            if hasattr(graph_result, 'accumulated_usage'):
                usage = graph_result.accumulated_usage
            elif hasattr(graph_result, '__dict__'):
                # æ£€æŸ¥æ‰€æœ‰å±æ€§ï¼Œå¯»æ‰¾usageç›¸å…³ä¿¡æ¯
                for attr_name, attr_value in graph_result.__dict__.items():
                    if 'usage' in attr_name.lower() and hasattr(attr_value, 'inputTokens'):
                        usage = attr_value
                        break
            
            if usage:
                # æ”¯æŒå­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼çš„usage
                if isinstance(usage, dict):
                    total_input_tokens = usage.get('inputTokens', 0)
                    total_output_tokens = usage.get('outputTokens', 0)
                elif hasattr(usage, 'inputTokens') and hasattr(usage, 'outputTokens'):
                    total_input_tokens = usage.inputTokens
                    total_output_tokens = usage.outputTokens
                else:
                    print(f"âš ï¸ usageæ ¼å¼ä¸æ”¯æŒ: {type(usage)}")
                    usage = None
            
            if not usage:
                # å¦‚æœæ²¡æœ‰ç³»ç»Ÿçº§åˆ«ç»Ÿè®¡ï¼Œä½¿ç”¨å„é˜¶æ®µç´¯åŠ 
                total_input_tokens = sum(stage.input_tokens for stage in stages)
                total_output_tokens = sum(stage.output_tokens for stage in stages)
            
            # è®¡ç®—å…¶ä»–æŒ‡æ ‡
            total_tool_calls = sum(stage.tool_calls for stage in stages)
            successful_stages = sum(1 for stage in stages if stage.success)
            failed_stages = len(stages) - successful_stages
            
            # ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿçº§åˆ«çš„æ‰§è¡Œæ—¶é—´
            if hasattr(graph_result, 'execution_time'):
                total_duration = graph_result.execution_time / 1000.0  # è½¬æ¢ä¸ºç§’
            else:
                # å¦‚æœæ²¡æœ‰ç³»ç»Ÿçº§åˆ«æ—¶é—´ï¼Œä½¿ç”¨å„é˜¶æ®µç´¯åŠ 
                total_duration = sum(stage.duration or 0 for stage in stages)
            
            # ç”Ÿæˆå·¥å…·ä½¿ç”¨æ€»ç»“
            tool_usage_summary = self._generate_tool_usage_summary(stages)
            
            # æˆæœ¬ä¼°ç®—
            cost_estimation = self._estimate_costs(total_input_tokens, total_output_tokens)
            
            # åŠ è½½é¡¹ç›®é…ç½®ä¿¡æ¯
            project_config_summary, total_tools = self._load_project_config(project_dir) if project_dir else (None, 0)
            
            return WorkflowSummary(
                project_name=project_name,
                workflow_start_time=workflow_start_time,
                workflow_end_time=workflow_end_time,
                total_duration=total_duration,
                total_input_tokens=total_input_tokens,
                total_output_tokens=total_output_tokens,
                total_tool_calls=total_tool_calls,
                successful_stages=successful_stages,
                failed_stages=failed_stages,
                stages=stages,
                tool_usage_summary=tool_usage_summary,
                cost_estimation=cost_estimation,
                project_config_summary=project_config_summary,
                total_tools=total_tools
            )
            
        except Exception as e:
            print(f"âŒ è§£æå·¥ä½œæµç»“æœå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çš„ç©ºæ€»ç»“
            return self._create_empty_summary()
    
    def _extract_project_name_from_orchestrator(self, graph_result: Any) -> str:
        """ä»å¤šä¸ªæ¥æºæå–é¡¹ç›®åç§°"""
        try:
            # æ–¹æ³•1: ä»orchestratoré˜¶æ®µçš„project_initå·¥å…·è°ƒç”¨ä¸­æå–
            project_name = self._extract_from_orchestrator_tools(graph_result)
            if project_name != "unknown_project":
                print(f"ğŸ” ä»orchestratorå·¥å…·è°ƒç”¨ä¸­æå–é¡¹ç›®åç§°: {project_name}")
                return project_name
            
            # æ–¹æ³•2: ä»resultå¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤ºä¸­æå–
            project_name = self._extract_from_result_string(graph_result)
            if project_name != "unknown_project":
                print(f"ğŸ” ä»resultå­—ç¬¦ä¸²ä¸­æå–é¡¹ç›®åç§°: {project_name}")
                return project_name
            
            # æ–¹æ³•3: ä»accumulated_usageä¸­æå–ï¼ˆå¦‚æœæœ‰é¡¹ç›®ä¿¡æ¯ï¼‰
            project_name = self._extract_from_usage_info(graph_result)
            if project_name != "unknown_project":
                print(f"ğŸ” ä»usageä¿¡æ¯ä¸­æå–é¡¹ç›®åç§°: {project_name}")
                return project_name
            
            print(f"âš ï¸ æ— æ³•ä»ä»»ä½•æ¥æºæå–é¡¹ç›®åç§°")
            return "unknown_project"
            
        except Exception as e:
            print(f"âš ï¸ æå–é¡¹ç›®åç§°å¤±è´¥: {e}")
            return "unknown_project"
    
    def _extract_from_orchestrator_tools(self, graph_result: Any) -> str:
        """ä»orchestratoré˜¶æ®µçš„å·¥å…·è°ƒç”¨ä¸­æå–é¡¹ç›®åç§°"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰resultså±æ€§
            if not hasattr(graph_result, 'results') or not graph_result.results:
                return "unknown_project"
            
            results = graph_result.results
            
            # æŸ¥æ‰¾orchestratoré˜¶æ®µ
            if 'orchestrator' not in results:
                return "unknown_project"
            
            orchestrator_result = results['orchestrator']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰resultå±æ€§
            if not hasattr(orchestrator_result, 'result'):
                return "unknown_project"
            
            orchestrator_agent_result = orchestrator_result.result
            
            # æ£€æŸ¥æ˜¯å¦æœ‰metricså’Œtool_metrics
            if (not hasattr(orchestrator_agent_result, 'metrics') or
                not hasattr(orchestrator_agent_result.metrics, 'tool_metrics')):
                return "unknown_project"
            
            tool_metrics = orchestrator_agent_result.metrics.tool_metrics
            
            # æŸ¥æ‰¾project_initå·¥å…·è°ƒç”¨
            if 'project_init' not in tool_metrics:
                return "unknown_project"
            
            project_init_tool = tool_metrics['project_init']
            
            # ä»å·¥å…·è¾“å…¥ä¸­æå–é¡¹ç›®åç§°
            if hasattr(project_init_tool, 'tool') and project_init_tool.tool:
                tool_info = project_init_tool.tool
                if isinstance(tool_info, dict) and 'input' in tool_info:
                    project_name = tool_info['input'].get('project_name')
                    if project_name:
                        return project_name
            
            return "unknown_project"
            
        except Exception as e:
            print(f"âš ï¸ ä»orchestratorå·¥å…·è°ƒç”¨æå–é¡¹ç›®åç§°å¤±è´¥: {e}")
            return "unknown_project"
    
    def _extract_from_result_string(self, graph_result: Any) -> str:
        """ä»resultå¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤ºä¸­æå–é¡¹ç›®åç§°"""
        try:
            # å°†æ•´ä¸ªresultå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œæœç´¢
            result_str = str(graph_result)
            
            import re
            # æŸ¥æ‰¾é¡¹ç›®åç§°æ¨¡å¼
            project_patterns = [
                r"'([^']+_agent)'",
                r"'([^']+_generator)'", 
                r"'([^']+_tool)'",
                r"'([^']+_cloner)'",
                r'"([^"]+_agent)"',
                r'"([^"]+_generator)"',
                r'"([^"]+_tool)"',
                r'"([^"]+_cloner)"'
            ]
            
            for pattern in project_patterns:
                matches = re.findall(pattern, result_str)
                for match in matches:
                    if len(match) > 3 and not match.startswith('_') and not match.startswith('unknown'):
                        return match
            
            return "unknown_project"
            
        except Exception as e:
            print(f"âš ï¸ ä»resultå­—ç¬¦ä¸²æå–é¡¹ç›®åç§°å¤±è´¥: {e}")
            return "unknown_project"
    
    def _extract_from_usage_info(self, graph_result: Any) -> str:
        """ä»usageä¿¡æ¯ä¸­æå–é¡¹ç›®åç§°"""
        try:
            # è¿™ä¸ªæ–¹æ³•å¯ä»¥æ‰©å±•ï¼Œæ¯”å¦‚ä»ç‰¹å®šçš„usageå­—æ®µä¸­æå–é¡¹ç›®ä¿¡æ¯
            # ç›®å‰è¿”å›unknown_projectï¼Œä½†ä¸ºå°†æ¥æ‰©å±•é¢„ç•™
            return "unknown_project"
            
        except Exception as e:
            print(f"âš ï¸ ä»usageä¿¡æ¯æå–é¡¹ç›®åç§°å¤±è´¥: {e}")
            return "unknown_project"
    
    def _parse_stages_metrics(self, graph_result: Any) -> List[StageMetrics]:
        """è§£æå„ä¸ªé˜¶æ®µçš„æ‰§è¡ŒæŒ‡æ ‡"""
        stages = []
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰resultså±æ€§
            if not hasattr(graph_result, 'results') or not graph_result.results:
                # åˆ›å»ºé»˜è®¤é˜¶æ®µ
                for stage_name in self.stages_order:
                    stages.append(StageMetrics(
                        stage_name=stage_name,
                        success=False,
                        error_message="æ²¡æœ‰æ‰¾åˆ°resultså±æ€§"
                    ))
                return stages
            
            results = graph_result.results
            
            # éå†å„ä¸ªé˜¶æ®µ
            for stage_name in self.stages_order:
                stage_metrics = self._parse_single_stage(stage_name, results)
                stages.append(stage_metrics)
            
        except Exception as e:
            print(f"âš ï¸ è§£æé˜¶æ®µæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            # åˆ›å»ºé»˜è®¤é˜¶æ®µ
            for stage_name in self.stages_order:
                stages.append(StageMetrics(
                    stage_name=stage_name,
                    success=False,
                    error_message=f"è§£æé”™è¯¯: {str(e)}"
                ))
        
        return stages
    
    def _parse_single_stage(self, stage_name: str, results: dict) -> StageMetrics:
        """è§£æå•ä¸ªé˜¶æ®µçš„æŒ‡æ ‡"""
        try:
            # åˆå§‹åŒ–é˜¶æ®µæŒ‡æ ‡
            stage_metrics = StageMetrics(stage_name=stage_name)
            
            # æ£€æŸ¥è¯¥é˜¶æ®µæ˜¯å¦å­˜åœ¨
            if stage_name not in results:
                stage_metrics.success = False
                stage_metrics.error_message = "é˜¶æ®µæœªæ‰§è¡Œ"
                return stage_metrics
            
            node_result = results[stage_name]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºçš„NodeResult
            if not hasattr(node_result, 'result') or not node_result.result:
                stage_metrics.success = False
                stage_metrics.error_message = "é˜¶æ®µç»“æœä¸ºç©º"
                print(f"âš ï¸ é˜¶æ®µ {stage_name} ç»“æœä¸ºç©º")
                return stage_metrics
            
            # æå–execution_time
            if hasattr(node_result, 'execution_time'):
                stage_metrics.duration = node_result.execution_time / 1000.0  # è½¬æ¢ä¸ºç§’
                print(f"ğŸ” é˜¶æ®µ {stage_name} æ‰§è¡Œæ—¶é—´: {stage_metrics.duration:.2f}ç§’")
            
            # æå–status
            if hasattr(node_result, 'status'):
                status_str = str(node_result.status)
                stage_metrics.success = 'COMPLETED' in status_str or 'completed' in status_str
                print(f"ğŸ” é˜¶æ®µ {stage_name} çŠ¶æ€: {status_str} -> æˆåŠŸ: {stage_metrics.success}")
            
            # æå–è¯¥é˜¶æ®µè‡ªå·±çš„accumulated_usageä¸­çš„tokenä¿¡æ¯
            if hasattr(node_result, 'accumulated_usage'):
                usage = node_result.accumulated_usage
                # æ”¯æŒå­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼
                if isinstance(usage, dict):
                    stage_metrics.input_tokens = usage.get('inputTokens', 0)
                    stage_metrics.output_tokens = usage.get('outputTokens', 0)
                    print(f"ğŸ” é˜¶æ®µ {stage_name} Tokenç»Ÿè®¡(å­—å…¸æ ¼å¼): input={stage_metrics.input_tokens}, output={stage_metrics.output_tokens}")
                elif hasattr(usage, 'inputTokens') and hasattr(usage, 'outputTokens'):
                    stage_metrics.input_tokens = usage.inputTokens
                    stage_metrics.output_tokens = usage.outputTokens
                    print(f"ğŸ” é˜¶æ®µ {stage_name} Tokenç»Ÿè®¡(å¯¹è±¡æ ¼å¼): input={stage_metrics.input_tokens}, output={stage_metrics.output_tokens}")
                else:
                    print(f"ğŸ” é˜¶æ®µ {stage_name} accumulated_usageæ ¼å¼ä¸æ”¯æŒ: {type(usage)}")
            else:
                print(f"ğŸ” é˜¶æ®µ {stage_name} æ— accumulated_usageä¿¡æ¯")
            
            # æå–AgentResultä¸­çš„metricsä¿¡æ¯
            if hasattr(node_result, 'result'):
                agent_result = node_result.result
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯AgentResult
                if hasattr(agent_result, 'metrics'):
                    metrics = agent_result.metrics
                    
                    # æå–cycle_count
                    if hasattr(metrics, 'cycle_count'):
                        cycle_count = metrics.cycle_count
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°tokenä¿¡æ¯ï¼Œä½¿ç”¨cycle_countä¼°ç®—
                        if stage_metrics.input_tokens == 0:
                            stage_metrics.input_tokens = cycle_count * 150
                        if stage_metrics.output_tokens == 0:
                            stage_metrics.output_tokens = cycle_count * 75
                    
                    # æå–tool_metrics
                    if hasattr(metrics, 'tool_metrics'):
                        tool_metrics = metrics.tool_metrics
                        
                        # è®¡ç®—å·¥å…·è°ƒç”¨æ¬¡æ•°
                        stage_metrics.tool_calls = len(tool_metrics)
                        
                        # è§£ææ¯ä¸ªå·¥å…·çš„è¯¦ç»†ä¿¡æ¯
                        for tool_name, tool_metric in tool_metrics.items():
                            tool_detail = {
                                'tool_name': tool_name,
                                'call_count': getattr(tool_metric, 'call_count', 0),
                                'success_count': getattr(tool_metric, 'success_count', 0),
                                'error_count': getattr(tool_metric, 'error_count', 0),
                                'total_time': getattr(tool_metric, 'total_time', 0.0)
                            }
                            stage_metrics.tool_call_details.append(tool_detail)
            
            # å¦‚æœæ²¡æœ‰ä»metricsè·å–åˆ°æ‰§è¡Œæ—¶é—´ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if stage_metrics.duration is None or stage_metrics.duration == 0:
                stage_metrics.duration = 2.0  # é»˜è®¤2ç§’
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°tokenä¿¡æ¯ï¼Œæ ‡è®°ä¸º0è€Œä¸æ˜¯ä¼°ç®—
            # è¿™æ ·å¯ä»¥åŒºåˆ†çœŸå®æ•°æ®å’Œç¼ºå¤±æ•°æ®
            if stage_metrics.input_tokens == 0:
                print(f"ğŸ” é˜¶æ®µ {stage_name} æ— è¾“å…¥Tokenæ•°æ®")
            if stage_metrics.output_tokens == 0:
                print(f"ğŸ” é˜¶æ®µ {stage_name} æ— è¾“å‡ºTokenæ•°æ®")
            
            return stage_metrics
            
        except Exception as e:
            return StageMetrics(
                stage_name=stage_name,
                success=False,
                error_message=f"è§£æé˜¶æ®µæŒ‡æ ‡å¤±è´¥: {str(e)}"
            )
    
    def _generate_tool_usage_summary(self, stages: List[StageMetrics]) -> Dict[str, int]:
        """ç”Ÿæˆå·¥å…·ä½¿ç”¨æ€»ç»“"""
        tool_summary = {}
        
        for stage in stages:
            for tool_detail in stage.tool_call_details:
                tool_name = tool_detail['tool_name']
                call_count = tool_detail['call_count']
                tool_summary[tool_name] = tool_summary.get(tool_name, 0) + call_count
        
        return tool_summary
    
    def _calculate_tool_statistics(self, stages: List[StageMetrics]) -> Dict[str, Dict[str, Any]]:
        """è®¡ç®—å·¥å…·è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        tool_stats = {}
        
        for stage in stages:
            for tool_detail in stage.tool_call_details:
                tool_name = tool_detail['tool_name']
                
                if tool_name not in tool_stats:
                    tool_stats[tool_name] = {
                        'call_count': 0,
                        'success_count': 0,
                        'error_count': 0,
                        'total_time': 0.0,
                        'avg_time': 0.0,
                        'success_rate': 0.0
                    }
                
                stats = tool_stats[tool_name]
                stats['call_count'] += tool_detail['call_count']
                stats['success_count'] += tool_detail['success_count']
                stats['error_count'] += tool_detail['error_count']
                stats['total_time'] += tool_detail['total_time']
        
        # è®¡ç®—å¹³å‡å€¼å’ŒæˆåŠŸç‡
        for tool_name, stats in tool_stats.items():
            if stats['call_count'] > 0:
                stats['avg_time'] = stats['total_time'] / stats['call_count']
                stats['success_rate'] = (stats['success_count'] / stats['call_count']) * 100
        
        return tool_stats
    
    def _generate_key_findings(self, summary: WorkflowSummary) -> List[str]:
        """ç”Ÿæˆå…³é”®å‘ç°"""
        findings = []
        
        # åˆ†ææ‰§è¡Œæ—¶é—´
        if summary.total_duration > 300:  # è¶…è¿‡5åˆ†é’Ÿ
            findings.append(f"âš ï¸ æ‰§è¡Œæ—¶é—´è¾ƒé•¿ ({self._format_duration(summary.total_duration)})ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ")
        elif summary.total_duration < 30:  # å°‘äº30ç§’
            findings.append(f"âœ… æ‰§è¡Œæ—¶é—´è¾ƒçŸ­ ({self._format_duration(summary.total_duration)})ï¼Œæ€§èƒ½è¡¨ç°è‰¯å¥½")
        
        # åˆ†æTokenä½¿ç”¨
        token_efficiency = summary.total_output_tokens / max(summary.total_input_tokens, 1)
        if token_efficiency < 0.1:
            findings.append(f"âš ï¸ Tokenæ•ˆç‡è¾ƒä½ ({token_efficiency:.2f})ï¼Œè¾“å‡ºç›¸å¯¹è¾“å…¥è¾ƒå°‘")
        elif token_efficiency > 0.5:
            findings.append(f"âœ… Tokenæ•ˆç‡è¾ƒé«˜ ({token_efficiency:.2f})ï¼Œè¾“å‡ºç›¸å¯¹è¾“å…¥è¾ƒå¤š")
        
        # åˆ†æå¤±è´¥é˜¶æ®µ
        if summary.failed_stages > 0:
            findings.append(f"âŒ æœ‰ {summary.failed_stages} ä¸ªé˜¶æ®µæ‰§è¡Œå¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é”™è¯¯åŸå› ")
        
        # åˆ†æå·¥å…·ä½¿ç”¨
        if summary.total_tool_calls == 0:
            findings.append("âš ï¸ æ²¡æœ‰å·¥å…·è°ƒç”¨è®°å½•ï¼Œå¯èƒ½å½±å“åŠŸèƒ½å®Œæ•´æ€§")
        elif summary.total_tool_calls > 50:
            findings.append(f"ğŸ“Š å·¥å…·è°ƒç”¨æ¬¡æ•°è¾ƒå¤š ({summary.total_tool_calls})ï¼Œè¯´æ˜å·¥ä½œæµå¤æ‚åº¦è¾ƒé«˜")
        
        # åˆ†ææˆæœ¬
        cost_per_tool = summary.cost_estimation.get('total_cost_usd', 0) / max(summary.total_tool_calls, 1)
        if cost_per_tool > 0.01:  # æ¯ä¸ªå·¥å…·è°ƒç”¨æˆæœ¬è¶…è¿‡1ç¾åˆ†
            findings.append(f"ğŸ’° å·¥å…·è°ƒç”¨æˆæœ¬è¾ƒé«˜ (${cost_per_tool:.4f}/æ¬¡)ï¼Œå»ºè®®ä¼˜åŒ–å·¥å…·ä½¿ç”¨")
        
        return findings
    
    def _generate_optimization_suggestions(self, summary: WorkflowSummary) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # åŸºäºæ‰§è¡Œæ—¶é—´çš„å»ºè®®
        if summary.total_duration > 300:
            suggestions.append("è€ƒè™‘å¹¶è¡ŒåŒ–å¤„ç†æˆ–ä¼˜åŒ–ç®—æ³•ä»¥å‡å°‘æ‰§è¡Œæ—¶é—´")
        
        # åŸºäºTokenä½¿ç”¨çš„å»ºè®®
        token_efficiency = summary.total_output_tokens / max(summary.total_input_tokens, 1)
        if token_efficiency < 0.1:
            suggestions.append("ä¼˜åŒ–æç¤ºè¯è®¾è®¡ï¼Œæé«˜è¾“å‡ºè´¨é‡")
        
        # åŸºäºå¤±è´¥é˜¶æ®µçš„å»ºè®®
        if summary.failed_stages > 0:
            suggestions.append("æ£€æŸ¥å¤±è´¥é˜¶æ®µçš„é”™è¯¯æ—¥å¿—ï¼Œä¿®å¤ç›¸å…³é—®é¢˜")
        
        # åŸºäºå·¥å…·ä½¿ç”¨çš„å»ºè®®
        if summary.total_tool_calls > 0:
            tool_stats = self._calculate_tool_statistics(summary.stages)
            slow_tools = [name for name, stats in tool_stats.items() if stats['avg_time'] > 1.0]
            if slow_tools:
                suggestions.append(f"ä¼˜åŒ–æ…¢é€Ÿå·¥å…·: {', '.join(slow_tools)}")
        
        # åŸºäºæˆæœ¬çš„å»ºè®®
        if summary.cost_estimation.get('total_cost_usd', 0) > 1.0:
            suggestions.append("è€ƒè™‘ä½¿ç”¨æ›´ç»æµçš„æ¨¡å‹æˆ–ä¼˜åŒ–Tokenä½¿ç”¨")
        
        # é€šç”¨å»ºè®®
        suggestions.extend([
            "å®šæœŸç›‘æ§å·¥ä½œæµæ€§èƒ½æŒ‡æ ‡",
            "å»ºç«‹æ€§èƒ½åŸºå‡†å’Œå‘Šè­¦æœºåˆ¶",
            "è€ƒè™‘ç¼“å­˜é‡å¤è®¡ç®—çš„ç»“æœ"
        ])
        
        return suggestions
    
    def _format_tokens(self, tokens: int) -> str:
        """æ ¼å¼åŒ–Tokenæ•°é‡ï¼ŒæŒ‰Kä¸ºå•ä½æ˜¾ç¤º"""
        if tokens >= 1000:
            return f"{tokens/1000:.1f}K"
        else:
            return str(tokens)
    
    def _format_duration(self, duration: float) -> str:
        """æ ¼å¼åŒ–æ‰§è¡Œæ—¶é—´ï¼Œæ˜¾ç¤ºä¸ºæ›´æ˜“è¯»çš„æ ¼å¼"""
        if duration < 60:
            return f"{duration:.1f}ç§’"
        elif duration < 3600:
            minutes = int(duration // 60)
            seconds = duration % 60
            return f"{minutes}åˆ†{seconds:.1f}ç§’"
        else:
            hours = int(duration // 3600)
            minutes = int((duration % 3600) // 60)
            return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
    
    def _calculate_stage_efficiency(self, stage: StageMetrics) -> str:
        """è®¡ç®—é˜¶æ®µæ•ˆç‡è¯„åˆ†"""
        if not stage.success:
            return "âŒ å¤±è´¥"
        
        if stage.duration and stage.duration > 0:
            # åŸºäºæ‰§è¡Œæ—¶é—´å’Œå·¥å…·è°ƒç”¨æ¬¡æ•°è®¡ç®—æ•ˆç‡
            tool_efficiency = stage.tool_calls / stage.duration if stage.duration > 0 else 0
            if tool_efficiency > 2:
                return "ğŸš€ ä¼˜ç§€"
            elif tool_efficiency > 1:
                return "âœ… è‰¯å¥½"
            elif tool_efficiency > 0.5:
                return "âš ï¸ ä¸€èˆ¬"
            else:
                return "ğŸŒ è¾ƒæ…¢"
        else:
            return "â“ æœªçŸ¥"
    
    def _estimate_costs(self, input_tokens: int, output_tokens: int) -> Dict[str, Any]:
        """ä¼°ç®—æˆæœ¬ï¼ˆåŸºäºClaude 4.5 Sonnetå®šä»·ï¼‰"""
        # Claude 4.5 Sonnetå®šä»·ï¼ˆæ¯1000ä¸ªtokenï¼‰
        input_cost_per_1k = 0.003  # $0.003 per 1K input tokens
        output_cost_per_1k = 0.015  # $0.015 per 1K output tokens
        
        input_cost = (input_tokens / 1000) * input_cost_per_1k
        output_cost = (output_tokens / 1000) * output_cost_per_1k
        total_cost = input_cost + output_cost
        
        return {
            "input_cost_usd": round(input_cost, 6),
            "output_cost_usd": round(output_cost, 6),
            "total_cost_usd": round(total_cost, 6),
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "pricing_model": "Claude 4.5 Sonnet",
            "input_rate_per_1k": input_cost_per_1k,
            "output_rate_per_1k": output_cost_per_1k
        }
    
    def _create_empty_summary(self) -> WorkflowSummary:
        """åˆ›å»ºç©ºçš„æ€»ç»“ï¼ˆå½“è§£æå¤±è´¥æ—¶ï¼‰"""
        current_time = datetime.now().isoformat()
        
        return WorkflowSummary(
            project_name="unknown_project",
            workflow_start_time=current_time,
            workflow_end_time=current_time,
            total_duration=0.0,
            total_input_tokens=0,
            total_output_tokens=0,
            total_tool_calls=0,
            successful_stages=0,
            failed_stages=len(self.stages_order),
            stages=[],
            tool_usage_summary={},
            cost_estimation={
                "total_cost_usd": 0.0, 
                "pricing_model": "Claude 4.5 Sonnet",
                "input_rate_per_1k": 0.003,
                "output_rate_per_1k": 0.015
            },
            project_config_summary=None,
            total_tools=0
        )
    
    def generate_markdown_report(self, summary: WorkflowSummary, output_path: str) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        try:
            report_content = self._format_markdown_report(summary)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"âœ… å·¥ä½œæµæ€»ç»“æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def _format_markdown_report(self, summary: WorkflowSummary) -> str:
        """æ ¼å¼åŒ–MarkdownæŠ¥å‘Šå†…å®¹"""
        report_lines = [
            "# å·¥ä½œæµæ‰§è¡Œæ€»ç»“æŠ¥å‘Š",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**é¡¹ç›®åç§°**: {summary.project_name}",
            "",
            "## ğŸ“Š æ€»ä½“æ¦‚è§ˆ",
            "",
            f"- **å·¥ä½œæµçŠ¶æ€**: {'âœ… æˆåŠŸå®Œæˆ' if summary.failed_stages == 0 else f'âš ï¸ éƒ¨åˆ†å¤±è´¥ ({summary.failed_stages}ä¸ªé˜¶æ®µå¤±è´¥)'}",
            f"- **æ€»æ‰§è¡Œæ—¶é—´**: {summary.total_duration:.2f} ç§’ ({self._format_duration(summary.total_duration)})",
            f"- **æˆåŠŸé˜¶æ®µæ•°**: {summary.successful_stages}/{len(summary.stages)}",
            f"- **æ€»è¾“å…¥Token**: {self._format_tokens(summary.total_input_tokens)}",
            f"- **æ€»è¾“å‡ºToken**: {self._format_tokens(summary.total_output_tokens)}",
            f"- **æ€»å·¥å…·è°ƒç”¨æ¬¡æ•°**: {summary.total_tool_calls}",
            "",
        ]
        
        # æ·»åŠ é¡¹ç›®é…ç½®ä¿¡æ¯
        if summary.project_config_summary or summary.total_tools > 0:
            report_lines.extend([
                "## ğŸ“‹ é¡¹ç›®é…ç½®ä¿¡æ¯",
                "",
            ])
            
            if summary.total_tools > 0:
                report_lines.append(f"- **é¡¹ç›®æ€»å·¥å…·æ•°é‡**: {summary.total_tools}")
            
            if summary.project_config_summary:
                config_summary = summary.project_config_summary
                report_lines.extend([
                    f"- **æ™ºèƒ½ä½“è„šæœ¬æ•°é‡**: {config_summary.get('agent_scripts_count', 0)}",
                    f"- **æç¤ºæ–‡ä»¶æ•°é‡**: {config_summary.get('prompt_files_count', 0)}",
                    f"- **ç”Ÿæˆå·¥å…·æ–‡ä»¶æ•°é‡**: {config_summary.get('generated_tool_files_count', 0)}",
                    f"- **æ‰€æœ‰è„šæœ¬æœ‰æ•ˆ**: {'âœ… æ˜¯' if config_summary.get('all_scripts_valid', False) else 'âŒ å¦'}",
                    f"- **æ‰€æœ‰å·¥å…·æœ‰æ•ˆ**: {'âœ… æ˜¯' if config_summary.get('all_tools_valid', False) else 'âŒ å¦'}",
                    f"- **æ‰€æœ‰æç¤ºæœ‰æ•ˆ**: {'âœ… æ˜¯' if config_summary.get('all_prompts_valid', False) else 'âŒ å¦'}",
                ])
            
            report_lines.append("")
        
        report_lines.extend([
            "## ğŸ’° æˆæœ¬ä¼°ç®—",
            "",
            f"- **è¾“å…¥æˆæœ¬**: ${summary.cost_estimation.get('input_cost_usd', 0):.6f} USD",
            f"- **è¾“å‡ºæˆæœ¬**: ${summary.cost_estimation.get('output_cost_usd', 0):.6f} USD", 
            f"- **æ€»æˆæœ¬**: ${summary.cost_estimation.get('total_cost_usd', 0):.6f} USD",
            f"- **å®šä»·æ¨¡å‹**: {summary.cost_estimation.get('pricing_model', 'Unknown')}",
            f"- **è¾“å…¥è´¹ç‡**: ${summary.cost_estimation.get('input_rate_per_1k', 0):.3f} USD/1K tokens",
            f"- **è¾“å‡ºè´¹ç‡**: ${summary.cost_estimation.get('output_rate_per_1k', 0):.3f} USD/1K tokens",
            "",
            "## ğŸ”„ é˜¶æ®µæ‰§è¡Œè¯¦æƒ…",
            "",
            "| é˜¶æ®µåç§° | çŠ¶æ€ | æ‰§è¡Œæ—¶é—´(ç§’) | è¾“å…¥Token | è¾“å‡ºToken | å·¥å…·è°ƒç”¨æ¬¡æ•° | æ•ˆç‡è¯„åˆ† |",
            "|---------|------|-------------|-----------|-----------|-------------|----------|"
        ])
        
        # æ·»åŠ å„é˜¶æ®µè¯¦æƒ…
        for stage in summary.stages:
            status_icon = "âœ…" if stage.success else "âŒ"
            duration = f"{stage.duration:.2f}" if stage.duration else "N/A"
            efficiency = self._calculate_stage_efficiency(stage)
            
            report_lines.append(
                f"| {stage.stage_name} | {status_icon} | {duration} | {self._format_tokens(stage.input_tokens)} | {self._format_tokens(stage.output_tokens)} | {stage.tool_calls} | {efficiency} |"
            )
            
            # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œæ·»åŠ è¯¦ç»†ä¿¡æ¯
            if stage.error_message:
                report_lines.append(f"| | **é”™è¯¯**: {stage.error_message} | | | | | |")
        
        report_lines.extend([
            "",
            "## ğŸ› ï¸ å·¥å…·ä½¿ç”¨ç»Ÿè®¡",
            "",
            "| å·¥å…·åç§° | è°ƒç”¨æ¬¡æ•° | ä½¿ç”¨é¢‘ç‡ | å¹³å‡è€—æ—¶(ç§’) | æˆåŠŸç‡ |",
            "|---------|----------|----------|-------------|--------|"
        ])
        
        # æ·»åŠ å·¥å…·ä½¿ç”¨ç»Ÿè®¡
        if summary.tool_usage_summary:
            tool_stats = self._calculate_tool_statistics(summary.stages)
            for tool_name, stats in sorted(tool_stats.items(), key=lambda x: x[1]['call_count'], reverse=True):
                frequency = f"{stats['call_count']}/{summary.total_tool_calls}" if summary.total_tool_calls > 0 else "0/0"
                avg_time = f"{stats['avg_time']:.3f}" if stats['avg_time'] > 0 else "N/A"
                success_rate = f"{stats['success_rate']:.1f}%" if stats['success_rate'] >= 0 else "N/A"
                report_lines.append(f"| {tool_name} | {stats['call_count']} | {frequency} | {avg_time} | {success_rate} |")
        else:
            report_lines.append("| æ— å·¥å…·è°ƒç”¨è®°å½• | 0 | 0/0 | N/A | N/A |")
        
        report_lines.extend([
            "",
            "## ğŸ“ˆ æ€§èƒ½åˆ†æ",
            "",
            f"- **å¹³å‡æ¯é˜¶æ®µæ‰§è¡Œæ—¶é—´**: {summary.total_duration / len(summary.stages):.2f} ç§’",
            f"- **Tokenæ•ˆç‡**: {summary.total_output_tokens / max(summary.total_input_tokens, 1):.2f} (è¾“å‡º/è¾“å…¥æ¯”)",
            f"- **å·¥å…·è°ƒç”¨é¢‘ç‡**: {summary.total_tool_calls / max(summary.total_duration, 1):.2f} æ¬¡/ç§’",
            f"- **å¹³å‡æ¯é˜¶æ®µTokenæ¶ˆè€—**: {self._format_tokens((summary.total_input_tokens + summary.total_output_tokens) // len(summary.stages))}",
            f"- **æˆæœ¬æ•ˆç‡**: ${summary.cost_estimation.get('total_cost_usd', 0) / max(summary.total_tool_calls, 1):.6f} USD/å·¥å…·è°ƒç”¨",
            "",
            "### ğŸ¯ é˜¶æ®µæ€§èƒ½å¯¹æ¯”",
            "",
            "| é˜¶æ®µ | æ‰§è¡Œæ—¶é—´å æ¯” | Tokenå æ¯” | å·¥å…·è°ƒç”¨å æ¯” | æ•ˆç‡ç­‰çº§ |",
            "|------|-------------|----------|-------------|----------|"
        ])
        
        # æ·»åŠ é˜¶æ®µæ€§èƒ½å¯¹æ¯”
        for stage in summary.stages:
            time_ratio = (stage.duration / summary.total_duration * 100) if summary.total_duration > 0 and stage.duration else 0
            token_ratio = ((stage.input_tokens + stage.output_tokens) / (summary.total_input_tokens + summary.total_output_tokens) * 100) if (summary.total_input_tokens + summary.total_output_tokens) > 0 else 0
            tool_ratio = (stage.tool_calls / summary.total_tool_calls * 100) if summary.total_tool_calls > 0 else 0
            efficiency = self._calculate_stage_efficiency(stage)
            
            report_lines.append(
                f"| {stage.stage_name} | {time_ratio:.1f}% | {token_ratio:.1f}% | {tool_ratio:.1f}% | {efficiency} |"
            )
        
        report_lines.extend([
            "",
            "## ğŸ” è¯¦ç»†å·¥å…·è°ƒç”¨è®°å½•",
            ""
        ])
        
        # æ·»åŠ è¯¦ç»†å·¥å…·è°ƒç”¨è®°å½•
        for stage in summary.stages:
            if stage.tool_call_details:
                report_lines.extend([
                    f"### {stage.stage_name}",
                    "",
                    "| å·¥å…·åç§° | è°ƒç”¨æ¬¡æ•° | æˆåŠŸæ¬¡æ•° | å¤±è´¥æ¬¡æ•° | æ€»è€—æ—¶(ç§’) | å¹³å‡è€—æ—¶(ç§’) | æˆåŠŸç‡ |",
                    "|---------|----------|----------|----------|------------|-------------|--------|"
                ])
                
                for tool_detail in stage.tool_call_details:
                    avg_time = tool_detail['total_time'] / tool_detail['call_count'] if tool_detail['call_count'] > 0 else 0
                    success_rate = (tool_detail['success_count'] / tool_detail['call_count'] * 100) if tool_detail['call_count'] > 0 else 0
                    
                    report_lines.append(
                        f"| {tool_detail['tool_name']} | {tool_detail['call_count']} | "
                        f"{tool_detail['success_count']} | {tool_detail['error_count']} | "
                        f"{tool_detail['total_time']:.3f} | {avg_time:.3f} | {success_rate:.1f}% |"
                    )
                report_lines.append("")
        
        report_lines.extend([
            "## ğŸ“ æ€»ç»“ä¸å»ºè®®",
            "",
            f"æœ¬æ¬¡å·¥ä½œæµæ‰§è¡Œå…±æ¶‰åŠ {len(summary.stages)} ä¸ªé˜¶æ®µï¼Œ",
            f"æˆåŠŸå®Œæˆ {summary.successful_stages} ä¸ªé˜¶æ®µï¼Œ",
            f"æ€»è€—æ—¶ {summary.total_duration:.2f} ç§’ ({self._format_duration(summary.total_duration)})ï¼Œ",
            f"æ¶ˆè€—Token {self._format_tokens(summary.total_input_tokens + summary.total_output_tokens)} ä¸ªï¼Œ",
            f"è°ƒç”¨å·¥å…· {summary.total_tool_calls} æ¬¡ï¼Œ",
            f"æ€»æˆæœ¬ ${summary.cost_estimation.get('total_cost_usd', 0):.6f} USDã€‚",
            "",
            "### ğŸ¯ å…³é”®å‘ç°",
            ""
        ])
        
        # æ·»åŠ å…³é”®å‘ç°
        findings = self._generate_key_findings(summary)
        for finding in findings:
            report_lines.append(f"- {finding}")
        
        report_lines.extend([
            "",
            "### ğŸ’¡ ä¼˜åŒ–å»ºè®®",
            ""
        ])
        
        # æ·»åŠ ä¼˜åŒ–å»ºè®®
        suggestions = self._generate_optimization_suggestions(summary)
        for suggestion in suggestions:
            report_lines.append(f"- {suggestion}")
        
        report_lines.extend([
            "",
            "---",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        ])
        
        return "\n".join(report_lines)

def generate_workflow_summary_report_bk(graph_result: Any, 
                                   default_project_root_path: str) -> str:
    """
    ç”Ÿæˆå·¥ä½œæµæ€»ç»“æŠ¥å‘Šçš„ä¸»å‡½æ•°
    
    Args:
        graph_result: GraphResultå¯¹è±¡
        default_project_root_path: é¡¹ç›®æ ¹è·¯å¾„
    
    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    try:
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = WorkflowReportGenerator()
        
        # è§£æå·¥ä½œæµç»“æœ
        summary = generator.parse_workflow_result(graph_result)
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if default_project_root_path.startswith('/projects/'):
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            project_root = os.path.join(os.getcwd(), default_project_root_path.lstrip('/'))
        else:
            project_root = default_project_root_path
        
        # åœ¨projects/<project_name>ä¸‹ç”ŸæˆæŠ¥å‘Š
        project_dir = os.path.join(project_root, summary.project_name)
        output_path = os.path.join(project_dir, "workflow_summary_report.md")
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = generator.generate_markdown_report(summary, output_path)
        
        return report_path
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå·¥ä½œæµæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
        return ""


def generate_workflow_summary_report(graph_result: Any, 
                                   default_project_root_path: str) -> str:
    """
    ç”Ÿæˆå·¥ä½œæµæ€»ç»“æŠ¥å‘Šçš„ä¸»å‡½æ•°
    
    Args:
        graph_result: GraphResultå¯¹è±¡
        default_project_root_path: é¡¹ç›®æ ¹è·¯å¾„
    
    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    try:
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = WorkflowReportGenerator()
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if default_project_root_path.startswith('/projects/'):
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            project_root = os.path.join(os.getcwd(), default_project_root_path.lstrip('/'))
        else:
            project_root = default_project_root_path
        
        # å…ˆè§£æå·¥ä½œæµç»“æœè·å–é¡¹ç›®åç§°
        temp_summary = generator.parse_workflow_result(graph_result)
        project_name = temp_summary.project_name
        
        # åœ¨projects/<project_name>ä¸‹ç”ŸæˆæŠ¥å‘Š
        project_dir = os.path.join(project_root, project_name)
        output_path = os.path.join(project_dir, "workflow_summary_report.md")
        
        # é‡æ–°è§£æå·¥ä½œæµç»“æœï¼Œè¿™æ¬¡åŒ…å«é¡¹ç›®ç›®å½•ä¿¡æ¯
        summary = generator.parse_workflow_result(graph_result, project_dir)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = generator.generate_markdown_report(summary, output_path)
        
        return report_path
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå·¥ä½œæµæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
        return ""


def parse_agent_result_metrics(agent_result: Any, stage_name: str) -> StageMetrics:
    """
    ä»AgentResultå¯¹è±¡ä¸­è§£æmetricsä¿¡æ¯
    
    Args:
        agent_result: AgentResultå¯¹è±¡
        stage_name: é˜¶æ®µåç§°
    
    Returns:
        StageMetricså¯¹è±¡
    """
    stage_metrics = StageMetrics(stage_name=stage_name)
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰metricså±æ€§
        if not hasattr(agent_result, 'metrics'):
            stage_metrics.success = False
            stage_metrics.error_message = "AgentResultæ²¡æœ‰metricså±æ€§"
            return stage_metrics
        
        metrics = agent_result.metrics
        
        # æå–accumulated_usageä¸­çš„tokenä¿¡æ¯
        if hasattr(metrics, 'accumulated_usage'):
            usage = metrics.accumulated_usage
            if isinstance(usage, dict):
                stage_metrics.input_tokens = usage.get('inputTokens', 0)
                stage_metrics.output_tokens = usage.get('outputTokens', 0)
            elif hasattr(usage, 'inputTokens') and hasattr(usage, 'outputTokens'):
                stage_metrics.input_tokens = usage.inputTokens
                stage_metrics.output_tokens = usage.outputTokens
        
        # æå–æ‰§è¡Œæ—¶é—´ï¼ˆä»cycle_durationsè®¡ç®—ï¼‰
        if hasattr(metrics, 'cycle_durations') and metrics.cycle_durations:
            stage_metrics.duration = sum(metrics.cycle_durations)
        
        # æå–tool_metrics
        if hasattr(metrics, 'tool_metrics'):
            tool_metrics = metrics.tool_metrics
            
            # è®¡ç®—å·¥å…·è°ƒç”¨æ¬¡æ•°
            total_tool_calls = 0
            for tool_name, tool_metric in tool_metrics.items():
                call_count = getattr(tool_metric, 'call_count', 0)
                total_tool_calls += call_count
                
                # è§£ææ¯ä¸ªå·¥å…·çš„è¯¦ç»†ä¿¡æ¯
                tool_detail = {
                    'tool_name': tool_name,
                    'call_count': call_count,
                    'success_count': getattr(tool_metric, 'success_count', 0),
                    'error_count': getattr(tool_metric, 'error_count', 0),
                    'total_time': getattr(tool_metric, 'total_time', 0.0)
                }
                stage_metrics.tool_call_details.append(tool_detail)
            
            stage_metrics.tool_calls = total_tool_calls
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°tokenä¿¡æ¯ï¼Œå°è¯•ä»cycle_countä¼°ç®—
        if stage_metrics.input_tokens == 0 and hasattr(metrics, 'cycle_count'):
            cycle_count = metrics.cycle_count
            stage_metrics.input_tokens = cycle_count * 150
            stage_metrics.output_tokens = cycle_count * 75
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ‰§è¡Œæ—¶é—´ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if stage_metrics.duration is None or stage_metrics.duration == 0:
            stage_metrics.duration = 2.0  # é»˜è®¤2ç§’
        
        stage_metrics.success = True
        
    except Exception as e:
        stage_metrics.success = False
        stage_metrics.error_message = f"è§£æmetricså¤±è´¥: {str(e)}"
    
    return stage_metrics


def extract_project_name_from_agent_results(execution_results: Dict[str, Any]) -> str:
    """
    ä»agentæ‰§è¡Œç»“æœä¸­æå–é¡¹ç›®åç§°

    Args:
        execution_results: åŒ…å«æ‰€æœ‰agentæ‰§è¡Œç»“æœçš„å­—å…¸

    Returns:
        é¡¹ç›®åç§°
    """
    try:
        # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å– project_idï¼ˆæœ€å¯é çš„æ–¹å¼ï¼‰
        import os
        project_id_from_env = os.environ.get("NEXUS_STAGE_TRACKER_PROJECT_ID")
        if project_id_from_env and not project_id_from_env.startswith("job_"):
            # å¦‚æœä¸æ˜¯ job_xxx æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
            return project_id_from_env

        # å°è¯•ä» projects ç›®å½•ä¸‹è¯»å–æœ€è¿‘åˆ›å»ºçš„é¡¹ç›®
        projects_dir = "./projects"
        if os.path.exists(projects_dir):
            projects = [d for d in os.listdir(projects_dir)
                       if os.path.isdir(os.path.join(projects_dir, d))
                       and d != "unknown_project"
                       and not d.startswith('.')]
            if projects:
                # æŒ‰ç…§ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
                projects.sort(key=lambda x: os.path.getmtime(os.path.join(projects_dir, x)), reverse=True)
                latest_project = projects[0]
                # éªŒè¯æ˜¯å¦æœ‰ config.yaml
                config_path = os.path.join(projects_dir, latest_project, "config.yaml")
                if os.path.exists(config_path):
                    try:
                        import yaml
                        with open(config_path, 'r', encoding='utf-8') as f:
                            config = yaml.safe_load(f)
                            if config and 'project' in config and 'name' in config['project']:
                                return config['project']['name']
                    except Exception:
                        pass
                return latest_project

        # å°è¯•ä»orchestratorçš„å·¥å…·è°ƒç”¨ä¸­æå–é¡¹ç›®åç§°
        if "orchestrator" in execution_results:
            orchestrator_result = execution_results["orchestrator"]
            if hasattr(orchestrator_result, 'metrics') and hasattr(orchestrator_result.metrics, 'tool_metrics'):
                tool_metrics = orchestrator_result.metrics.tool_metrics
                if 'project_init' in tool_metrics:
                    project_init_tool = tool_metrics['project_init']
                    if hasattr(project_init_tool, 'tool') and project_init_tool.tool:
                        tool_info = project_init_tool.tool
                        if isinstance(tool_info, dict) and 'input' in tool_info:
                            project_name = tool_info['input'].get('project_name')
                            if project_name:
                                return project_name
                        elif hasattr(tool_info, 'input'):
                            input_data = tool_info.input
                            if isinstance(input_data, dict):
                                project_name = input_data.get('project_name')
                                if project_name:
                                    return project_name

        # å¦‚æœæ— æ³•ä»å·¥å…·è°ƒç”¨ä¸­æå–ï¼Œå°è¯•ä»å†…å®¹ä¸­æœç´¢
        import re
        for stage_name, agent_result in execution_results.items():
            content = str(agent_result.content) if hasattr(agent_result, 'content') else str(agent_result)
            # æŸ¥æ‰¾é¡¹ç›®åç§°æ¨¡å¼
            patterns = [
                r"'([^']+_agent)'",
                r'"([^"]+_agent)"',
                r'project_name["\']?\s*[:=]\s*["\']?([^"\']+)',
            ]
            for pattern in patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    if len(match) > 3 and not match.startswith('_') and not match.startswith('unknown'):
                        return match

        return "unknown_project"

    except Exception as e:
        print(f"âš ï¸ æå–é¡¹ç›®åç§°å¤±è´¥: {e}")
        return "unknown_project"


def generate_sequential_workflow_report(
    execution_results: Dict[str, Any],
    execution_order: List[str],
    execution_time: float,
    intent_analysis: Any,
    default_project_root_path: str = './projects',
    is_update_workflow: bool = False
) -> str:
    """
    ä¸ºé¡ºåºè°ƒç”¨çš„å·¥ä½œæµç”ŸæˆæŠ¥å‘Š
    
    Args:
        execution_results: åŒ…å«æ‰€æœ‰agentæ‰§è¡Œç»“æœçš„å­—å…¸ï¼Œkeyä¸ºstage_nameï¼Œvalueä¸ºAgentResultå¯¹è±¡
        execution_order: æ‰§è¡Œé¡ºåºåˆ—è¡¨
        execution_time: æ€»æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
        intent_analysis: æ„å›¾åˆ†æç»“æœ
        default_project_root_path: é¡¹ç›®æ ¹è·¯å¾„
        is_update_workflow: æ˜¯å¦ä¸ºæ›´æ–°å·¥ä½œæµï¼Œå¦‚æœæ˜¯åˆ™ä¸å†æ‹¼æ¥é¡¹ç›®å
    
    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    try:
        generator = WorkflowReportGenerator()
        
        # è§£æå„ä¸ªé˜¶æ®µçš„metrics
        stages = []
        for stage_name in execution_order:
            if stage_name in execution_results:
                agent_result = execution_results[stage_name]
                stage_metrics = parse_agent_result_metrics(agent_result, stage_name)
                stages.append(stage_metrics)
            else:
                # å¦‚æœæŸä¸ªé˜¶æ®µæ²¡æœ‰ç»“æœï¼Œåˆ›å»ºå¤±è´¥è®°å½•
                stages.append(StageMetrics(
                    stage_name=stage_name,
                    success=False,
                    error_message="é˜¶æ®µæœªæ‰§è¡Œ"
                ))
        
        # æå–é¡¹ç›®åç§°
        project_name = extract_project_name_from_agent_results(execution_results)
        
        # è®¡ç®—æ€»tokenä½¿ç”¨é‡
        total_input_tokens = sum(stage.input_tokens for stage in stages)
        total_output_tokens = sum(stage.output_tokens for stage in stages)
        
        # è®¡ç®—å…¶ä»–æŒ‡æ ‡
        total_tool_calls = sum(stage.tool_calls for stage in stages)
        successful_stages = sum(1 for stage in stages if stage.success)
        failed_stages = len(stages) - successful_stages
        
        # ç”Ÿæˆå·¥å…·ä½¿ç”¨æ€»ç»“
        tool_usage_summary = generator._generate_tool_usage_summary(stages)
        
        # æˆæœ¬ä¼°ç®—
        cost_estimation = generator._estimate_costs(total_input_tokens, total_output_tokens)
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if default_project_root_path.startswith('/projects/'):
            project_root = os.path.join(os.getcwd(), default_project_root_path.lstrip('/'))
        else:
            project_root = default_project_root_path
        
        # æ ¹æ®å·¥ä½œæµç±»å‹å†³å®šæŠ¥å‘Šè·¯å¾„
        if is_update_workflow:
            # æ›´æ–°å·¥ä½œæµï¼šdefault_project_root_path å·²ç»æ˜¯ç‰ˆæœ¬ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨
            project_dir = project_root
        else:
            # æ„å»ºå·¥ä½œæµï¼šåœ¨ projects/<project_name> ä¸‹ç”ŸæˆæŠ¥å‘Š
            project_dir = os.path.join(project_root, project_name)
        
        output_path = os.path.join(project_dir, "workflow_summary_report.md")
        
        # åŠ è½½é¡¹ç›®é…ç½®ä¿¡æ¯
        project_config_summary, total_tools = generator._load_project_config(project_dir) if os.path.exists(project_dir) else (None, 0)
        
        # åˆ›å»ºWorkflowSummaryå¯¹è±¡
        workflow_start_time = datetime.now().isoformat()
        workflow_end_time = datetime.now().isoformat()
        
        summary = WorkflowSummary(
            project_name=project_name,
            workflow_start_time=workflow_start_time,
            workflow_end_time=workflow_end_time,
            total_duration=execution_time,
            total_input_tokens=total_input_tokens,
            total_output_tokens=total_output_tokens,
            total_tool_calls=total_tool_calls,
            successful_stages=successful_stages,
            failed_stages=failed_stages,
            stages=stages,
            tool_usage_summary=tool_usage_summary,
            cost_estimation=cost_estimation,
            project_config_summary=project_config_summary,
            total_tools=total_tools
        )
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = generator.generate_markdown_report(summary, output_path)
        
        return report_path
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆé¡ºåºå·¥ä½œæµæŠ¥å‘Šå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return ""


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("å·¥ä½œæµæŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯•")
    print("è¯·ç›´æ¥ä¼ é€’GraphResultå¯¹è±¡ç»™generate_workflow_summary_reportå‡½æ•°")
    print("ç¤ºä¾‹ç”¨æ³•:")
    print("  from nexus_utils.workflow_report_generator import generate_workflow_summary_report")
    print("  report_path = generate_workflow_summary_report(graph_result, './projects')")
    print("\næˆ–è€…ä½¿ç”¨é¡ºåºå·¥ä½œæµæŠ¥å‘Šç”Ÿæˆ:")
    print("  from nexus_utils.workflow_report_generator import generate_sequential_workflow_report")
    print("  report_path = generate_sequential_workflow_report(execution_results, execution_order, execution_time, intent_analysis, './projects')")