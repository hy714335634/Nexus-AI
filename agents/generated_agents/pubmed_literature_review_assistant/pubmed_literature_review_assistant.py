#!/usr/bin/env python3
"""
PubMed Literature Reviewer Agent

ä¸“ä¸šçš„ç§‘ç ”æ–‡çŒ®/æŠ¥å‘Šå®¡æ ¸Agentï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æä¾›çš„å®Œæ•´æ–‡çŒ®ï¼Œç»“åˆåœ¨çº¿æ£€ç´¢PMCæ–‡çŒ®çš„å·¥å…·ï¼Œ
è¿›è¡ŒçŠ€åˆ©çš„è¯„ä»·ä¸åé¦ˆï¼ŒæŒ‡å‡ºä¿¡æ¯ä¸å…¨ã€å¹»è§‰ç­‰é—®é¢˜ï¼Œå¹¶æä¾›ä¿®æ­£å»ºè®®ã€‚

åŠŸèƒ½ç‰¹ç‚¹:
- å¤šç»´åº¦è¯„ä¼°ç§‘ç ”æ–‡çŒ®è´¨é‡
- éªŒè¯æ–‡çŒ®ä¸­çš„å…³é”®å£°æ˜å’Œæ•°æ®
- è¯†åˆ«ä¿¡æ¯ä¸å…¨ã€å¹»è§‰ç­‰é—®é¢˜
- æä¾›ç»“æ„åŒ–çš„JSONæ ¼å¼è¯„ä¼°ç»“æœ
- æ”¯æŒresearch_idå‚æ•°æŒ‡å®šç¼“å­˜ç›®å½•
- æä¾›å…·ä½“çš„ä¿®æ­£å»ºè®®
"""

import os
import json
import logging
import uuid
import time
from typing import Dict, List, Any, Optional, Union
from pathlib import Path

from nexus_utils.agent_factory import create_agent_from_prompt_template
from strands.telemetry import StrandsTelemetry
from strands.session.file_session_manager import FileSessionManager
from nexus_utils.config_loader import ConfigLoader
config = ConfigLoader()
# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# é…ç½®é¥æµ‹
os.environ["BYPASS_TOOL_CONSENT"] = "true"
otel_endpoint = config.get_with_env_override(
    "OTEL_EXPORTER_OTLP_ENDPOINT",
    "nexus_ai", "OTEL_EXPORTER_OTLP_ENDPOINT",
    default="http://localhost:4318"
)
os.environ.setdefault("OTEL_EXPORTER_OTLP_ENDPOINT", otel_endpoint)
strands_telemetry = StrandsTelemetry()
strands_telemetry.setup_otlp_exporter()

class PubmedLiteratureReviewer:
    """PubMedæ–‡çŒ®å®¡æ ¸ä¸“å®¶æ™ºèƒ½ä½“ç±»"""
    
    def __init__(self, session_manager=None, env: str = "production", version: str = "latest", model_id: str = "default"):
        """
        åˆå§‹åŒ–PubMedæ–‡çŒ®å®¡æ ¸ä¸“å®¶æ™ºèƒ½ä½“
        
        Args:
            session_manager: ä¼šè¯ç®¡ç†å™¨å®ä¾‹
            env (str): ç¯å¢ƒé…ç½® (development, production, testing)
            version (str): æ™ºèƒ½ä½“ç‰ˆæœ¬
            model_id (str): ä½¿ç”¨çš„æ¨¡å‹ID
        """
        self.env = env
        self.version = version
        self.model_id = model_id
        self.session_manager = session_manager
        
        # æ™ºèƒ½ä½“å‚æ•°
        self.agent_params = {
            "env": self.env,
            "version": self.version,
            "model_id": self.model_id
        }
        
        # åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹
        self.agent = create_agent_from_prompt_template(
            agent_name="generated_agents_prompts/pubmed_literature_review_assistant/pubmed_literature_review_assistant",
            session_manager=self.session_manager,
            **self.agent_params
        )
        
        logger.info(f"PubMedæ–‡çŒ®å®¡æ ¸ä¸“å®¶æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ: {self.agent.name}")
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        self.base_cache_dir = Path(".cache/pmc_literature")
        self.base_cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ç»Ÿä¸€è¾“å‡ºå­è·¯å¾„
        self.feedback_subpath = Path("feedback") / "reviewer"

    # ----------------------
    # å†…éƒ¨å·¥å…·æ–¹æ³•ï¼šç»Ÿä¸€è¾“å‡ºä¸ç‰ˆæœ¬æ§åˆ¶
    # ----------------------
    def _ensure_research_id(self, research_id: Optional[str]) -> str:
        """ç¡®ä¿å­˜åœ¨research_idï¼›è‹¥æœªæä¾›ï¼Œåˆ™ç”Ÿæˆä¸€ä¸ªæ–°çš„uuidå¹¶è¿”å›ã€‚"""
        if not research_id:
            generated = str(uuid.uuid4())
            logger.info(f"æœªæä¾›research_idï¼Œå·²è‡ªåŠ¨ç”Ÿæˆ: {generated}")
            return generated
        return research_id

    def _get_output_dir(self, research_id: str, version: Optional[int] = None) -> Path:
        """è·å–æ ‡å‡†è¾“å‡ºç›®å½• .cache/pmc_literature/<research_id>/feedback/reviewer[/<version>] å¹¶ç¡®ä¿å­˜åœ¨ã€‚"""
        out_dir = self.base_cache_dir / research_id / self.feedback_subpath
        if version is not None:
            out_dir = out_dir / str(version)
        out_dir.mkdir(parents=True, exist_ok=True)
        return out_dir

    def _now_ts(self) -> str:
        """è¿”å›æ—¶é—´æˆ³ï¼šYYYYMMDDThhmmss"""
        return time.strftime("%Y%m%dT%H%M%S", time.localtime())

    def _load_status(self, research_id: str) -> Dict[str, Any]:
        """è¯»å– .cache/pmc_literature/<research_id>/step5.statusï¼ˆè‹¥ä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤ç»“æ„ï¼‰ã€‚"""
        status_path = self.base_cache_dir / research_id / "step5.status"
        if status_path.exists():
            try:
                with open(status_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"è¯»å–step5.statuså¤±è´¥ï¼Œå°†é‡å»ºã€‚é”™è¯¯: {e}")
        return {
            "research_id": research_id,
            "latest_version": 0,
            "versions": {}
        }

    def _get_or_create_run_version(self, research_id: str) -> int:
        """åœ¨ä¸€æ¬¡agentè¿è¡Œä¸­å›ºå®šç‰ˆæœ¬å·ï¼š
        - ä¼˜å…ˆè¯»å– .current_run_version 
        - è‹¥ä¸å­˜åœ¨åˆ™ä¾æ®status/ç›®å½•è®¡ç®—ä¸‹ä¸€ä¸ªç‰ˆæœ¬ï¼Œå¹¶å†™å…¥ .current_run_version
        """
        base_dir = self.base_cache_dir / research_id
        marker = base_dir / ".current_run_version"
        try:
            if marker.exists():
                with open(marker, "r", encoding="utf-8") as f:
                    v = int(f.read().strip())
                    return v
        except Exception:
            pass

        # è®¡ç®—æ–°ç‰ˆæœ¬
        reviewer_root = base_dir / self.feedback_subpath
        reviewer_root.mkdir(parents=True, exist_ok=True)
        status = self._load_status(research_id)
        version = self._detect_next_version(research_id, reviewer_root, status)
        try:
            with open(marker, "w", encoding="utf-8") as f:
                f.write(str(version))
        except Exception as e:
            logger.warning(f"å†™å…¥.current_run_versionå¤±è´¥: {e}")
        return version

    def _write_status(self, research_id: str, status: Dict[str, Any]) -> None:
        """å†™å› step5.statusã€‚"""
        status_path = self.base_cache_dir / research_id / "step5.status"
        try:
            with open(status_path, "w", encoding="utf-8") as f:
                json.dump(status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"å†™å…¥step5.statuså¤±è´¥: {e}")

    def _detect_next_version(self, research_id: str, output_dir: Path, status: Dict[str, Any]) -> int:
        """åŸºäºç°æœ‰statuså’Œç›®å½•å†…æ–‡ä»¶æ£€æµ‹ä¸‹ä¸€ä¸ªç‰ˆæœ¬å·ã€‚ä¼˜å…ˆä½¿ç”¨status.latest_versionã€‚
        å…¼å®¹æ‰«æfeedback/revieweræ ¹ç›®å½•ä¸å…¶ä¸‹çš„æ•°å­—å­ç›®å½•ã€‚"""
        latest_version = int(status.get("latest_version", 0))
        if latest_version > 0:
            return latest_version + 1
        # å…œåº•ï¼šä»ç›®å½•æ‰«æåŒ¹é… review_<version>_*.json æ¨æ–­æœ€å¤§ç‰ˆæœ¬ï¼ˆå…¼å®¹æ—§ç»“æ„ä¸æ–°ç»“æ„ï¼‰
        max_found = 0
        # æ—§ç»“æ„ï¼šreviewer/ ä¸‹ç›´æ¥æ–‡ä»¶
        for p in output_dir.glob("review_*_*.json"):
            name = p.stem  # review_<v>_<ts>
            parts = name.split("_")
            if len(parts) >= 3 and parts[0] == "review":
                try:
                    v = int(parts[1])
                    if v > max_found:
                        max_found = v
                except Exception:
                    continue
        # æ–°ç»“æ„ï¼šreviewer/<version>/ å­ç›®å½•
        for sub in (self.base_cache_dir / research_id / self.feedback_subpath).glob("*"):
            if sub.is_dir():
                try:
                    v = int(sub.name)
                    if v > max_found:
                        max_found = v
                except Exception:
                    continue
        return max_found + 1

    def _save_outputs(self, research_id: str, mode: str, content_text: str, agent_result: str, forced_version: Optional[int] = None) -> Dict[str, Any]:
        """
        å°†æœ¬æ¬¡è¿è¡Œäº§ç‰©æŒ‰ç…§è§„èŒƒå‘½åå†™å…¥ï¼š
        - ç›®å½•ï¼š.cache/pmc_literature/<research_id>/feedback/reviewer/
        - åŸºåï¼šreview_<version>_<timestamp>
        - æ‰©å±•ï¼š.jsonï¼ˆç»“æ„åŒ–ï¼‰ï¼Œ.mdï¼ˆåŸå§‹è¾“å‡ºï¼‰ï¼Œ.txtï¼ˆåŸå§‹è¾“å‡ºçº¯æ–‡æœ¬ï¼‰
        è¿”å›ï¼š{"version": int, "timestamp": str, "files": {ext: path}}
        """
        research_id = self._ensure_research_id(research_id)
        base_output_dir = self._get_output_dir(research_id)
        status = self._load_status(research_id)
        version = forced_version if forced_version is not None else self._detect_next_version(research_id, base_output_dir, status)
        ts = self._now_ts()

        # ä½¿ç”¨ç‰ˆæœ¬å­ç›®å½•
        version_dir = self._get_output_dir(research_id, version)
        verification_dir = version_dir / "verification"
        verification_dir.mkdir(parents=True, exist_ok=True)
        base_name = f"review_{version}_{ts}"
        json_path = verification_dir / f"{base_name}.json"
        md_path = verification_dir / f"{base_name}.md"
        txt_path = verification_dir / f"{base_name}.txt"

        # è§£æagentè¾“å‡ºä¸ºJSONï¼›è‹¥å¤±è´¥åˆ™ä»¥åŒ…è£…ç»“æ„å­˜å‚¨
        json_payload: Dict[str, Any]
        try:
            json_payload = json.loads(agent_result)
        except Exception as e:
            json_payload = {
                "error": "agent_output_not_valid_json",
                "message": str(e),
                "raw_output": agent_result
            }

        # é™„åŠ å…ƒä¿¡æ¯ï¼Œä¾¿äºæº¯æº
        json_payload = {
            "_meta": {
                "mode": mode,
                "research_id": research_id,
                "version": version,
                "timestamp": ts
            },
            "data": json_payload
        }

        # å†™æ–‡ä»¶
        try:
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(json_payload, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"å†™å…¥JSONå¤±è´¥: {e}")

        try:
            with open(md_path, "w", encoding="utf-8") as f:
                f.write(agent_result)
        except Exception as e:
            logger.error(f"å†™å…¥Markdownå¤±è´¥: {e}")

        try:
            with open(txt_path, "w", encoding="utf-8") as f:
                f.write(agent_result)
        except Exception as e:
            logger.error(f"å†™å…¥TXTå¤±è´¥: {e}")

        # æ±‡æ€»åˆ°statusï¼ˆæŒ‰ç‰ˆæœ¬å½’æ¡£ï¼‰
        status["latest_version"] = version
        versions = status.setdefault("versions", {})
        versions[str(version)] = {
            "generated_at": ts,
            "mode": mode,
            "files": {
                "json": [str(json_path.resolve())],
                "md": [str(md_path.resolve())],
                "txt": [str(txt_path.resolve())],
                "others": []
            }
        }

        self._write_status(research_id, status)

        return {
            "version": version,
            "timestamp": ts,
            "files": {
                "json": str(json_path.resolve()),
                "md": str(md_path.resolve()),
                "txt": str(txt_path.resolve())
            }
        }
    
    def review_literature(self, content: str, research_id: Optional[str] = None) -> str:
        """
        è¯„å®¡ç§‘ç ”æ–‡çŒ®å¹¶æä¾›åé¦ˆ
        
        Args:
            content (str): æ–‡çŒ®å†…å®¹
            research_id (str, optional): ç ”ç©¶IDï¼Œç”¨äºæŒ‡å®šç¼“å­˜å’Œä¸Šä¸‹æ–‡å·¥ä½œç›®å½•
            
        Returns:
            str: æ™ºèƒ½ä½“å“åº”ï¼ŒåŒ…å«è¯„å®¡ç»“æœå’Œä¿®æ­£å»ºè®®
        """
        try:
            start_time = time.time()
            logger.info(f"å¼€å§‹è¯„å®¡æ–‡çŒ®ï¼Œ{'ä½¿ç”¨research_id: ' + research_id if research_id else 'æœªæŒ‡å®šresearch_id'}")
            
            # å‡†å¤‡è¾“å…¥ï¼Œæ·»åŠ research_idä¿¡æ¯
            input_text = content
            if research_id:
                # ç¡®ä¿research_idç›®å½•å­˜åœ¨
                research_dir = self.base_cache_dir / research_id
                research_dir.mkdir(parents=True, exist_ok=True)
                
                # åœ¨è¾“å…¥ä¸­æ·»åŠ research_idä¿¡æ¯
                input_text += f"\n\nresearch_id: {research_id}"
            
            # å›ºå®šæœ¬æ¬¡è¿è¡Œç‰ˆæœ¬
            rid = self._ensure_research_id(research_id)
            run_version = self._get_or_create_run_version(rid)

            # è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†æ–‡çŒ®è¯„å®¡
            result = self.agent(input_text)

            # è½ç›˜ä¸çŠ¶æ€æ›´æ–°ï¼ˆç»Ÿä¸€è¾“å‡ºè§„èŒƒï¼‰
            self._save_outputs(rid, mode="review", content_text=content, agent_result=result, forced_version=run_version)
            
            elapsed_time = time.time() - start_time
            logger.info(f"æ–‡çŒ®è¯„å®¡å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            
            return result
        except Exception as e:
            logger.error(f"æ–‡çŒ®è¯„å®¡å¤±è´¥: {str(e)}")
            return f"æ–‡çŒ®è¯„å®¡è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    def verify_specific_claims(self, content: str, claims: List[str], 
                              research_id: Optional[str] = None) -> str:
        """
        éªŒè¯æ–‡çŒ®ä¸­çš„ç‰¹å®šå£°æ˜
        
        Args:
            content (str): æ–‡çŒ®å†…å®¹
            claims (List[str]): éœ€è¦éªŒè¯çš„å£°æ˜åˆ—è¡¨
            research_id (str, optional): ç ”ç©¶IDï¼Œç”¨äºæŒ‡å®šç¼“å­˜å’Œä¸Šä¸‹æ–‡å·¥ä½œç›®å½•
            
        Returns:
            str: æ™ºèƒ½ä½“å“åº”ï¼ŒåŒ…å«å£°æ˜éªŒè¯ç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹éªŒè¯ç‰¹å®šå£°æ˜ï¼Œå…±{len(claims)}æ¡")
            
            # å‡†å¤‡è¾“å…¥ï¼Œæ ¼å¼åŒ–å£°æ˜åˆ—è¡¨å’Œresearch_idä¿¡æ¯
            claims_text = "\n".join([f"- {claim}" for claim in claims])
            input_text = f"""è¯·éªŒè¯ä»¥ä¸‹æ–‡çŒ®ä¸­çš„ç‰¹å®šå£°æ˜:

{content}

éœ€è¦éªŒè¯çš„å£°æ˜:
{claims_text}

è¯·é’ˆå¯¹æ¯æ¡å£°æ˜è¿›è¡ŒéªŒè¯ï¼Œå¹¶æä¾›æ”¯æŒæˆ–åå¯¹çš„è¯æ®ã€‚
"""
            
            if research_id:
                input_text += f"\n\nresearch_id: {research_id}"
            
            # å›ºå®šæœ¬æ¬¡è¿è¡Œç‰ˆæœ¬
            rid = self._ensure_research_id(research_id)
            run_version = self._get_or_create_run_version(rid)

            # è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†å£°æ˜éªŒè¯
            result = self.agent(input_text)

            # è½ç›˜ä¸çŠ¶æ€æ›´æ–°
            self._save_outputs(rid, mode="verify", content_text=content, agent_result=result, forced_version=run_version)
            
            logger.info("å£°æ˜éªŒè¯å®Œæˆ")
            return result
        except Exception as e:
            logger.error(f"å£°æ˜éªŒè¯å¤±è´¥: {str(e)}")
            return f"å£°æ˜éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    def compare_literature(self, content1: str, content2: str, 
                          research_id: Optional[str] = None) -> str:
        """
        æ¯”è¾ƒä¸¤ç¯‡æ–‡çŒ®çš„å†…å®¹å’Œè´¨é‡
        
        Args:
            content1 (str): ç¬¬ä¸€ç¯‡æ–‡çŒ®å†…å®¹
            content2 (str): ç¬¬äºŒç¯‡æ–‡çŒ®å†…å®¹
            research_id (str, optional): ç ”ç©¶IDï¼Œç”¨äºæŒ‡å®šç¼“å­˜å’Œä¸Šä¸‹æ–‡å·¥ä½œç›®å½•
            
        Returns:
            str: æ™ºèƒ½ä½“å“åº”ï¼ŒåŒ…å«æ–‡çŒ®æ¯”è¾ƒç»“æœ
        """
        try:
            logger.info("å¼€å§‹æ¯”è¾ƒä¸¤ç¯‡æ–‡çŒ®")
            
            # å‡†å¤‡è¾“å…¥ï¼Œæ ¼å¼åŒ–ä¸¤ç¯‡æ–‡çŒ®å†…å®¹å’Œresearch_idä¿¡æ¯
            input_text = f"""è¯·æ¯”è¾ƒä»¥ä¸‹ä¸¤ç¯‡æ–‡çŒ®çš„å†…å®¹å’Œè´¨é‡:

æ–‡çŒ®1:
{content1}

æ–‡çŒ®2:
{content2}

è¯·ä»ç§‘å­¦å‡†ç¡®æ€§ã€æ–¹æ³•è®ºåˆç†æ€§ã€ç»“è®ºæœ‰æ•ˆæ€§ã€åˆ›æ–°æ€§ã€å®Œæ•´æ€§ç­‰ç»´åº¦è¿›è¡Œæ¯”è¾ƒåˆ†æï¼Œå¹¶æŒ‡å‡ºå„è‡ªçš„ä¼˜ç¼ºç‚¹ã€‚
"""
            
            if research_id:
                input_text += f"\n\nresearch_id: {research_id}"
            
            # å›ºå®šæœ¬æ¬¡è¿è¡Œç‰ˆæœ¬
            rid = self._ensure_research_id(research_id)
            run_version = self._get_or_create_run_version(rid)

            # è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†æ–‡çŒ®æ¯”è¾ƒ
            result = self.agent(input_text)

            # è½ç›˜ä¸çŠ¶æ€æ›´æ–°
            self._save_outputs(rid, mode="compare", content_text=f"[DOC1]\n{content1}\n\n[DOC2]\n{content2}", agent_result=result, forced_version=run_version)
            
            logger.info("æ–‡çŒ®æ¯”è¾ƒå®Œæˆ")
            return result
        except Exception as e:
            logger.error(f"æ–‡çŒ®æ¯”è¾ƒå¤±è´¥: {str(e)}")
            return f"æ–‡çŒ®æ¯”è¾ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    def get_assessment_history(self, research_id: str) -> str:
        """
        è·å–æŒ‡å®šresearch_idçš„è¯„ä¼°å†å²
        
        Args:
            research_id (str): ç ”ç©¶ID
            
        Returns:
            str: è¯„ä¼°å†å²ä¿¡æ¯
        """
        try:
            logger.info(f"è·å–research_id: {research_id}çš„è¯„ä¼°å†å²")
            
            # æ£€æŸ¥research_idç›®å½•æ˜¯å¦å­˜åœ¨
            research_dir = self.base_cache_dir / research_id
            if not research_dir.exists():
                return f"æœªæ‰¾åˆ°research_id: {research_id}çš„è¯„ä¼°å†å²"
            
            # æŸ¥æ‰¾æ‰€æœ‰assessmentæ–‡ä»¶
            assessment_files = list(research_dir.glob("assessment_*.json"))
            if not assessment_files:
                return f"research_id: {research_id}æ²¡æœ‰è¯„ä¼°è®°å½•"
            
            # è¯»å–è¯„ä¼°æ–‡ä»¶å†…å®¹
            assessments = []
            for file_path in sorted(assessment_files):
                try:
                    with open(file_path, 'r') as f:
                        assessment = json.load(f)
                    
                    # æå–å…³é”®ä¿¡æ¯
                    metadata = assessment.get("metadata", {})
                    overall = assessment.get("overall_assessment", {})
                    
                    assessments.append({
                        "assessment_id": metadata.get("assessment_id", ""),
                        "assessment_date": metadata.get("assessment_date", ""),
                        "document_title": metadata.get("document_title", ""),
                        "overall_score": overall.get("score", 0),
                        "overall_grade": overall.get("grade", ""),
                        "file_path": str(file_path)
                    })
                except Exception as e:
                    logger.warning(f"è¯»å–è¯„ä¼°æ–‡ä»¶{file_path}æ—¶å‡ºé”™: {str(e)}")
            
            # æ ¼å¼åŒ–è¾“å‡º
            if assessments:
                result = f"research_id: {research_id}çš„è¯„ä¼°å†å² (å…±{len(assessments)}æ¡):\n\n"
                for i, assessment in enumerate(assessments, 1):
                    result += f"{i}. {assessment['assessment_date']}: {assessment['document_title']}\n"
                    result += f"   è¯„åˆ†: {assessment['overall_score']}/100 ({assessment['overall_grade']}çº§)\n"
                    result += f"   ID: {assessment['assessment_id']}\n\n"
            else:
                result = f"research_id: {research_id}æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°è®°å½•"
            
            return result
        except Exception as e:
            logger.error(f"è·å–è¯„ä¼°å†å²å¤±è´¥: {str(e)}")
            return f"è·å–è¯„ä¼°å†å²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

def get_pubmed_literature_reviewer(env: str = "production", version: str = "latest", model_id: str = "default") -> PubmedLiteratureReviewer:
    """
    è·å–PubMedæ–‡çŒ®å®¡æ ¸ä¸“å®¶æ™ºèƒ½ä½“å®ä¾‹
    
    Args:
        env (str): ç¯å¢ƒé…ç½® (development, production, testing)
        version (str): æ™ºèƒ½ä½“ç‰ˆæœ¬
        model_id (str): ä½¿ç”¨çš„æ¨¡å‹ID
        
    Returns:
        PubmedLiteratureReviewer: æ™ºèƒ½ä½“å®ä¾‹
    """
    return PubmedLiteratureReviewer(env=env, version=version, model_id=model_id)

# ç›´æ¥ä½¿ç”¨agent_factoryåˆ›å»ºæ™ºèƒ½ä½“çš„ä¾¿æ·æ–¹æ³•
def create_pubmed_literature_reviewer(env: str = "production", version: str = "latest", model_id: str = "default"):
    """
    åˆ›å»ºPubMedæ–‡çŒ®å®¡æ ¸ä¸“å®¶æ™ºèƒ½ä½“
    
    Args:
        env (str): ç¯å¢ƒé…ç½® (development, production, testing)
        version (str): æ™ºèƒ½ä½“ç‰ˆæœ¬
        model_id (str): ä½¿ç”¨çš„æ¨¡å‹ID
        
    Returns:
        Agent: Strandsæ™ºèƒ½ä½“å®ä¾‹
    """
    # æ™ºèƒ½ä½“å‚æ•°
    agent_params = {
        "env": env,
        "version": version,
        "model_id": model_id
    }
    
    # ä½¿ç”¨agent_factoryåˆ›å»ºæ™ºèƒ½ä½“
    return create_agent_from_prompt_template(
        agent_name="generated_agents_prompts/pubmed_literature_review_agent/pubmed_literature_reviewer",
        **agent_params
    )

if __name__ == "__main__":
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='PubMedæ–‡çŒ®å®¡æ ¸ä¸“å®¶æ™ºèƒ½ä½“')
    parser.add_argument('-f', '--file', type=str, 
                       help='æ–‡çŒ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-c', '--claims', type=str, 
                       help='éœ€è¦éªŒè¯çš„å£°æ˜ï¼Œå¤šä¸ªå£°æ˜ç”¨é€—å·åˆ†éš”')
    parser.add_argument('-r', '--research_id', type=str, 
                       default=None,
                       help='ç ”ç©¶IDï¼Œç”¨äºæŒ‡å®šç¼“å­˜å’Œä¸Šä¸‹æ–‡å·¥ä½œç›®å½•')
    parser.add_argument('-m', '--mode', type=str,
                       choices=['review', 'verify', 'history', 'compare'],
                       default='review',
                       help='æ“ä½œæ¨¡å¼: review(è¯„å®¡æ–‡çŒ®), verify(éªŒè¯å£°æ˜), history(æŸ¥çœ‹è¯„ä¼°å†å²), compare(æ¯”è¾ƒæ–‡çŒ®)')
    parser.add_argument('-c1', '--compare1', type=str, 
                       help='æ¯”è¾ƒæ¨¡å¼ä¸‹çš„ç¬¬ä¸€ç¯‡æ–‡çŒ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-c2', '--compare2', type=str, 
                       help='æ¯”è¾ƒæ¨¡å¼ä¸‹çš„ç¬¬äºŒç¯‡æ–‡çŒ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--session_id', type=str,
                       default=None,
                       help='å¯é€‰ï¼šæŒ‡å®šsession_id')
    args = parser.parse_args()
    
    # è®¾ç½®ä¼šè¯ç®¡ç†å™¨
    session_id = args.session_id if args.session_id else str(uuid.uuid4())
    session_manager = FileSessionManager(
        session_id=session_id,
        storage_dir="./.cache/session_cache"
    )
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent_params = {
        "env": "production",
        "version": "latest",
        "model_id": "default"
    }
    
    reviewer = PubmedLiteratureReviewer(session_manager=session_manager, **agent_params)
    print(f"âœ… PubMedæ–‡çŒ®å®¡æ ¸ä¸“å®¶æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ: {reviewer.agent.name}")
    
    # æ ¹æ®æ¨¡å¼æ‰§è¡Œä¸åŒæ“ä½œ
    if args.mode == 'review':
        if args.file:
            try:
                with open(args.file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                print(f"ğŸ“„ æ­£åœ¨è¯„å®¡æ–‡çŒ®: {args.file}")
                result = reviewer.review_literature(content, args.research_id)
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
                exit(1)
        else:
            print("è¯·è¾“å…¥æ–‡çŒ®å†…å®¹ (è¾“å…¥å®ŒæˆåæŒ‰Ctrl+Dç»“æŸ):")
            try:
                content = ""
                while True:
                    line = input()
                    content += line + "\n"
            except EOFError:
                print("\nğŸ“„ æ­£åœ¨è¯„å®¡æ–‡çŒ®...")
                result = reviewer.review_literature(content, args.research_id)
    
    elif args.mode == 'verify':
        if not args.claims:
            print("âŒ éœ€è¦æä¾›è¦éªŒè¯çš„å£°æ˜ (ä½¿ç”¨ --claims å‚æ•°)")
            exit(1)
            
        claims = [claim.strip() for claim in args.claims.split(',')]
        
        if args.file:
            try:
                with open(args.file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                print(f"ğŸ” æ­£åœ¨éªŒè¯æ–‡çŒ®ä¸­çš„{len(claims)}æ¡å£°æ˜")
                result = reviewer.verify_specific_claims(content, claims, args.research_id)
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
                exit(1)
        else:
            print("è¯·è¾“å…¥æ–‡çŒ®å†…å®¹ (è¾“å…¥å®ŒæˆåæŒ‰Ctrl+Dç»“æŸ):")
            try:
                content = ""
                while True:
                    line = input()
                    content += line + "\n"
            except EOFError:
                print(f"\nğŸ” æ­£åœ¨éªŒè¯æ–‡çŒ®ä¸­çš„{len(claims)}æ¡å£°æ˜")
                result = reviewer.verify_specific_claims(content, claims, args.research_id)
    
    elif args.mode == 'compare':
        if not args.compare1 or not args.compare2:
            print("âŒ æ¯”è¾ƒæ¨¡å¼éœ€è¦æä¾›ä¸¤ä¸ªæ–‡çŒ®æ–‡ä»¶è·¯å¾„ (ä½¿ç”¨ --compare1 å’Œ --compare2 å‚æ•°)")
            exit(1)
            
        try:
            with open(args.compare1, 'r', encoding='utf-8') as f:
                content1 = f.read()
                
            with open(args.compare2, 'r', encoding='utf-8') as f:
                content2 = f.read()
            
            print(f"ğŸ” æ­£åœ¨æ¯”è¾ƒä¸¤ç¯‡æ–‡çŒ®: {args.compare1} å’Œ {args.compare2}")
            result = reviewer.compare_literature(content1, content2, args.research_id)
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
            exit(1)
    
    elif args.mode == 'history':
        if not args.research_id:
            print("âŒ éœ€è¦æä¾›research_id (ä½¿ç”¨ --research_id å‚æ•°)")
            exit(1)
            
        print(f"ğŸ“‹ è·å–research_id: {args.research_id}çš„è¯„ä¼°å†å²")
        result = reviewer.get_assessment_history(args.research_id)
    
    # è¾“å‡ºç»“æœ
    print(f"\nğŸ“‹ æ™ºèƒ½ä½“å“åº”:\n{result}")