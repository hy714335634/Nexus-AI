#!/usr/bin/env python3
"""
å·¥ä½œæµæ€»ç»“æŠ¥å‘Šç”Ÿæˆå™¨
ç”¨äºè§£æå·¥ä½œæµæ‰§è¡Œç»“æœå¹¶ç”Ÿæˆè¯¦ç»†çš„æ€»ç»“æŠ¥å‘Š
åŸºäºå®˜æ–¹Strands GraphResultæ•°æ®ç»“æ„
"""

import os
import json
import time
from datetime import datetime
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict


@dataclass
class StageMetrics:
    """å•ä¸ªé˜¶æ®µçš„æ‰§è¡ŒæŒ‡æ ‡"""
    stage_name: str
    start_time: Optional[str] = None
    end_time: Optional[str] = None
    duration: Optional[float] = None
    input_tokens: int = 0
    output_tokens: int = 0
    tool_calls: int = 0
    tool_call_details: List[Dict[str, Any]] = None
    success: bool = True
    error_message: Optional[str] = None
    
    def __post_init__(self):
        if self.tool_call_details is None:
            self.tool_call_details = []


@dataclass
class WorkflowSummary:
    """å·¥ä½œæµæ€»ä½“æ€»ç»“"""
    project_name: str
    workflow_start_time: str
    workflow_end_time: str
    total_duration: float
    total_input_tokens: int
    total_output_tokens: int
    total_tool_calls: int
    successful_stages: int
    failed_stages: int
    stages: List[StageMetrics]
    tool_usage_summary: Dict[str, int]
    cost_estimation: Dict[str, Any]


class WorkflowReportGenerator:
    """å·¥ä½œæµæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.stages_order = [
            "orchestrator",
            "requirements_analyzer", 
            "system_architect",
            "agent_designer",
            "agent_developer_manager"
        ]
    
    def parse_workflow_result(self, graph_result: Any) -> WorkflowSummary:
        """è§£æGraphResultå¯¹è±¡"""
        try:
            # æå–é¡¹ç›®åç§°
            project_name = self._extract_project_name_from_orchestrator(graph_result)
            
            # æå–æ—¶é—´ä¿¡æ¯
            workflow_start_time = datetime.now().isoformat()  # è¿™é‡Œåº”è¯¥ä»å®é™…æ‰§è¡Œæ—¶é—´è·å–
            workflow_end_time = datetime.now().isoformat()
            
            # è§£æå„ä¸ªé˜¶æ®µçš„æŒ‡æ ‡
            stages = self._parse_stages_metrics(graph_result)
            
            # ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿçº§åˆ«çš„çœŸå®Tokenç»Ÿè®¡
            total_input_tokens = 0
            total_output_tokens = 0
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç³»ç»Ÿçº§åˆ«çš„accumulated_usage
            # GraphResultç»§æ‰¿è‡ªMultiAgentResultï¼Œaccumulated_usageå¯èƒ½åœ¨çˆ¶ç±»ä¸­
            usage = None
            if hasattr(graph_result, 'accumulated_usage'):
                usage = graph_result.accumulated_usage
            elif hasattr(graph_result, '__dict__'):
                # æ£€æŸ¥æ‰€æœ‰å±æ€§ï¼Œå¯»æ‰¾usageç›¸å…³ä¿¡æ¯
                for attr_name, attr_value in graph_result.__dict__.items():
                    if 'usage' in attr_name.lower() and hasattr(attr_value, 'inputTokens'):
                        usage = attr_value
                        break
            
            if usage and hasattr(usage, 'inputTokens') and hasattr(usage, 'outputTokens'):
                total_input_tokens = usage.inputTokens
                total_output_tokens = usage.outputTokens
                print(f"ğŸ” ä½¿ç”¨ç³»ç»Ÿçº§åˆ«Tokenç»Ÿè®¡: input={total_input_tokens}, output={total_output_tokens}")
            else:
                # å¦‚æœæ²¡æœ‰ç³»ç»Ÿçº§åˆ«ç»Ÿè®¡ï¼Œä½¿ç”¨å„é˜¶æ®µç´¯åŠ 
                total_input_tokens = sum(stage.input_tokens for stage in stages)
                total_output_tokens = sum(stage.output_tokens for stage in stages)
                print(f"ğŸ” ä»å„é˜¶æ®µç´¯åŠ Tokenç»Ÿè®¡: input={total_input_tokens}, output={total_output_tokens}")
                print(f"âš ï¸ æœªæ‰¾åˆ°ç³»ç»Ÿçº§åˆ«accumulated_usageï¼Œä½¿ç”¨å„é˜¶æ®µä¼°ç®—å€¼")
            
            # è®¡ç®—å…¶ä»–æŒ‡æ ‡
            total_tool_calls = sum(stage.tool_calls for stage in stages)
            successful_stages = sum(1 for stage in stages if stage.success)
            failed_stages = len(stages) - successful_stages
            
            # è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
            total_duration = sum(stage.duration or 0 for stage in stages)
            
            # ç”Ÿæˆå·¥å…·ä½¿ç”¨æ€»ç»“
            tool_usage_summary = self._generate_tool_usage_summary(stages)
            
            # æˆæœ¬ä¼°ç®—
            cost_estimation = self._estimate_costs(total_input_tokens, total_output_tokens)
            
            return WorkflowSummary(
                project_name=project_name,
                workflow_start_time=workflow_start_time,
                workflow_end_time=workflow_end_time,
                total_duration=total_duration,
                total_input_tokens=total_input_tokens,
                total_output_tokens=total_output_tokens,
                total_tool_calls=total_tool_calls,
                successful_stages=successful_stages,
                failed_stages=failed_stages,
                stages=stages,
                tool_usage_summary=tool_usage_summary,
                cost_estimation=cost_estimation
            )
            
        except Exception as e:
            print(f"âŒ è§£æå·¥ä½œæµç»“æœå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çš„ç©ºæ€»ç»“
            return self._create_empty_summary()
    
    def _extract_project_name_from_orchestrator(self, graph_result: Any) -> str:
        """ä»orchestratoré˜¶æ®µçš„project_initå·¥å…·è°ƒç”¨ä¸­æå–é¡¹ç›®åç§°"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰resultså±æ€§
            if not hasattr(graph_result, 'results') or not graph_result.results:
                return "unknown_project"
            
            results = graph_result.results
            
            # æŸ¥æ‰¾orchestratoré˜¶æ®µ
            if 'orchestrator' not in results:
                return "unknown_project"
            
            orchestrator_result = results['orchestrator']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰resultå±æ€§
            if not hasattr(orchestrator_result, 'result'):
                return "unknown_project"
            
            orchestrator_agent_result = orchestrator_result.result
            
            # æ£€æŸ¥æ˜¯å¦æœ‰metricså’Œtool_metrics
            if (not hasattr(orchestrator_agent_result, 'metrics') or
                not hasattr(orchestrator_agent_result.metrics, 'tool_metrics')):
                return "unknown_project"
            
            tool_metrics = orchestrator_agent_result.metrics.tool_metrics
            
            # æŸ¥æ‰¾project_initå·¥å…·è°ƒç”¨
            if 'project_init' not in tool_metrics:
                return "unknown_project"
            
            project_init_tool = tool_metrics['project_init']
            
            # ä»å·¥å…·è¾“å…¥ä¸­æå–é¡¹ç›®åç§°
            if hasattr(project_init_tool, 'tool') and project_init_tool.tool:
                tool_info = project_init_tool.tool
                if isinstance(tool_info, dict) and 'input' in tool_info:
                    project_name = tool_info['input'].get('project_name')
                    if project_name:
                        return project_name
            
            # å¦‚æœæ²¡æ‰¾åˆ°project_initï¼Œå°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–é¡¹ç›®åç§°
            if hasattr(graph_result, 'obj_str'):
                import re
                # æŸ¥æ‰¾é¡¹ç›®åç§°æ¨¡å¼
                project_patterns = [
                    r"'([^']+_generator)'",
                    r"'([^']+_agent)'",
                    r"'([^']+_tool)'",
                    r"'([^']+_cloner)'"
                ]
                
                for pattern in project_patterns:
                    match = re.search(pattern, graph_result.obj_str)
                    if match:
                        project_name = match.group(1)
                        if len(project_name) > 3 and not project_name.startswith('_'):
                            return project_name
            
            return "unknown_project"
            
        except Exception as e:
            print(f"âš ï¸ ä»orchestratoræå–é¡¹ç›®åç§°å¤±è´¥: {e}")
            return "unknown_project"
    
    def _parse_stages_metrics(self, graph_result: Any) -> List[StageMetrics]:
        """è§£æå„ä¸ªé˜¶æ®µçš„æ‰§è¡ŒæŒ‡æ ‡"""
        stages = []
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰resultså±æ€§
            if not hasattr(graph_result, 'results') or not graph_result.results:
                # åˆ›å»ºé»˜è®¤é˜¶æ®µ
                for stage_name in self.stages_order:
                    stages.append(StageMetrics(
                        stage_name=stage_name,
                        success=False,
                        error_message="æ²¡æœ‰æ‰¾åˆ°resultså±æ€§"
                    ))
                return stages
            
            results = graph_result.results
            
            # éå†å„ä¸ªé˜¶æ®µ
            for stage_name in self.stages_order:
                stage_metrics = self._parse_single_stage(stage_name, results)
                stages.append(stage_metrics)
            
        except Exception as e:
            print(f"âš ï¸ è§£æé˜¶æ®µæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            # åˆ›å»ºé»˜è®¤é˜¶æ®µ
            for stage_name in self.stages_order:
                stages.append(StageMetrics(
                    stage_name=stage_name,
                    success=False,
                    error_message=f"è§£æé”™è¯¯: {str(e)}"
                ))
        
        return stages
    
    def _parse_single_stage(self, stage_name: str, results: dict) -> StageMetrics:
        """è§£æå•ä¸ªé˜¶æ®µçš„æŒ‡æ ‡"""
        try:
            # åˆå§‹åŒ–é˜¶æ®µæŒ‡æ ‡
            stage_metrics = StageMetrics(stage_name=stage_name)
            
            # æ£€æŸ¥è¯¥é˜¶æ®µæ˜¯å¦å­˜åœ¨
            if stage_name not in results:
                stage_metrics.success = False
                stage_metrics.error_message = "é˜¶æ®µæœªæ‰§è¡Œ"
                return stage_metrics
            
            node_result = results[stage_name]
            
            # æå–execution_time
            if hasattr(node_result, 'execution_time'):
                stage_metrics.duration = node_result.execution_time / 1000.0  # è½¬æ¢ä¸ºç§’
            
            # æå–status
            if hasattr(node_result, 'status'):
                status_str = str(node_result.status)
                stage_metrics.success = 'COMPLETED' in status_str or 'completed' in status_str
            
            # æå–è¯¥é˜¶æ®µè‡ªå·±çš„accumulated_usageä¸­çš„tokenä¿¡æ¯
            if hasattr(node_result, 'accumulated_usage'):
                usage = node_result.accumulated_usage
                if hasattr(usage, 'inputTokens'):
                    stage_metrics.input_tokens = usage.inputTokens
                if hasattr(usage, 'outputTokens'):
                    stage_metrics.output_tokens = usage.outputTokens
                print(f"ğŸ” é˜¶æ®µ {stage_name} Tokenç»Ÿè®¡: input={stage_metrics.input_tokens}, output={stage_metrics.output_tokens}")
            else:
                print(f"ğŸ” é˜¶æ®µ {stage_name} æ— accumulated_usageä¿¡æ¯")
            
            # æå–AgentResultä¸­çš„metricsä¿¡æ¯
            if hasattr(node_result, 'result'):
                agent_result = node_result.result
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯AgentResult
                if hasattr(agent_result, 'metrics'):
                    metrics = agent_result.metrics
                    
                    # æå–cycle_count
                    if hasattr(metrics, 'cycle_count'):
                        cycle_count = metrics.cycle_count
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°tokenä¿¡æ¯ï¼Œä½¿ç”¨cycle_countä¼°ç®—
                        if stage_metrics.input_tokens == 0:
                            stage_metrics.input_tokens = cycle_count * 150
                        if stage_metrics.output_tokens == 0:
                            stage_metrics.output_tokens = cycle_count * 75
                    
                    # æå–tool_metrics
                    if hasattr(metrics, 'tool_metrics'):
                        tool_metrics = metrics.tool_metrics
                        
                        # è®¡ç®—å·¥å…·è°ƒç”¨æ¬¡æ•°
                        stage_metrics.tool_calls = len(tool_metrics)
                        
                        # è§£ææ¯ä¸ªå·¥å…·çš„è¯¦ç»†ä¿¡æ¯
                        for tool_name, tool_metric in tool_metrics.items():
                            tool_detail = {
                                'tool_name': tool_name,
                                'call_count': getattr(tool_metric, 'call_count', 0),
                                'success_count': getattr(tool_metric, 'success_count', 0),
                                'error_count': getattr(tool_metric, 'error_count', 0),
                                'total_time': getattr(tool_metric, 'total_time', 0.0)
                            }
                            stage_metrics.tool_call_details.append(tool_detail)
            
            # å¦‚æœæ²¡æœ‰ä»metricsè·å–åˆ°æ‰§è¡Œæ—¶é—´ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if stage_metrics.duration is None or stage_metrics.duration == 0:
                stage_metrics.duration = 2.0  # é»˜è®¤2ç§’
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°tokenä¿¡æ¯ï¼Œä½¿ç”¨åŸºäºå·¥å…·è°ƒç”¨æ¬¡æ•°çš„åˆç†ä¼°ç®—
            if stage_metrics.input_tokens == 0:
                # åŸºäºå·¥å…·è°ƒç”¨æ¬¡æ•°ä¼°ç®—ï¼šæ¯ä¸ªå·¥å…·è°ƒç”¨çº¦200-500 tokens
                estimated_input = max(200, stage_metrics.tool_calls * 300)
                stage_metrics.input_tokens = estimated_input
            if stage_metrics.output_tokens == 0:
                # è¾“å‡ºtokensé€šå¸¸æ˜¯è¾“å…¥çš„30-50%
                estimated_output = max(100, int(stage_metrics.input_tokens * 0.4))
                stage_metrics.output_tokens = estimated_output
            
            return stage_metrics
            
        except Exception as e:
            return StageMetrics(
                stage_name=stage_name,
                success=False,
                error_message=f"è§£æé˜¶æ®µæŒ‡æ ‡å¤±è´¥: {str(e)}"
            )
    
    def _generate_tool_usage_summary(self, stages: List[StageMetrics]) -> Dict[str, int]:
        """ç”Ÿæˆå·¥å…·ä½¿ç”¨æ€»ç»“"""
        tool_summary = {}
        
        for stage in stages:
            for tool_detail in stage.tool_call_details:
                tool_name = tool_detail['tool_name']
                call_count = tool_detail['call_count']
                tool_summary[tool_name] = tool_summary.get(tool_name, 0) + call_count
        
        return tool_summary
    
    def _format_tokens(self, tokens: int) -> str:
        """æ ¼å¼åŒ–Tokenæ•°é‡ï¼ŒæŒ‰Kä¸ºå•ä½æ˜¾ç¤º"""
        if tokens >= 1000:
            return f"{tokens/1000:.1f}K"
        else:
            return str(tokens)
    
    def _estimate_costs(self, input_tokens: int, output_tokens: int) -> Dict[str, Any]:
        """ä¼°ç®—æˆæœ¬ï¼ˆåŸºäºClaude 3.7 Sonnetå®šä»·ï¼‰"""
        # Claude 3.7 Sonnetå®šä»·ï¼ˆæ¯1000ä¸ªtokenï¼‰
        input_cost_per_1k = 0.003  # $0.003 per 1K input tokens
        output_cost_per_1k = 0.015  # $0.015 per 1K output tokens
        
        input_cost = (input_tokens / 1000) * input_cost_per_1k
        output_cost = (output_tokens / 1000) * output_cost_per_1k
        total_cost = input_cost + output_cost
        
        return {
            "input_cost_usd": round(input_cost, 6),
            "output_cost_usd": round(output_cost, 6),
            "total_cost_usd": round(total_cost, 6),
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "pricing_model": "Claude 3.7 Sonnet",
            "input_rate_per_1k": input_cost_per_1k,
            "output_rate_per_1k": output_cost_per_1k
        }
    
    def _create_empty_summary(self) -> WorkflowSummary:
        """åˆ›å»ºç©ºçš„æ€»ç»“ï¼ˆå½“è§£æå¤±è´¥æ—¶ï¼‰"""
        current_time = datetime.now().isoformat()
        
        return WorkflowSummary(
            project_name="unknown_project",
            workflow_start_time=current_time,
            workflow_end_time=current_time,
            total_duration=0.0,
            total_input_tokens=0,
            total_output_tokens=0,
            total_tool_calls=0,
            successful_stages=0,
            failed_stages=len(self.stages_order),
            stages=[],
            tool_usage_summary={},
            cost_estimation={
                "total_cost_usd": 0.0, 
                "pricing_model": "Claude 3.7 Sonnet",
                "input_rate_per_1k": 0.003,
                "output_rate_per_1k": 0.015
            }
        )
    
    def generate_markdown_report(self, summary: WorkflowSummary, output_path: str) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        try:
            report_content = self._format_markdown_report(summary)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"âœ… å·¥ä½œæµæ€»ç»“æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def _format_markdown_report(self, summary: WorkflowSummary) -> str:
        """æ ¼å¼åŒ–MarkdownæŠ¥å‘Šå†…å®¹"""
        report_lines = [
            "# å·¥ä½œæµæ‰§è¡Œæ€»ç»“æŠ¥å‘Š",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**é¡¹ç›®åç§°**: {summary.project_name}",
            "",
            "## ğŸ“Š æ€»ä½“æ¦‚è§ˆ",
            "",
            f"- **å·¥ä½œæµçŠ¶æ€**: {'âœ… æˆåŠŸå®Œæˆ' if summary.failed_stages == 0 else f'âš ï¸ éƒ¨åˆ†å¤±è´¥ ({summary.failed_stages}ä¸ªé˜¶æ®µå¤±è´¥)'}",
            f"- **æ€»æ‰§è¡Œæ—¶é—´**: {summary.total_duration:.2f} ç§’",
            f"- **æˆåŠŸé˜¶æ®µæ•°**: {summary.successful_stages}/{len(summary.stages)}",
            f"- **æ€»è¾“å…¥Token**: {self._format_tokens(summary.total_input_tokens)}",
            f"- **æ€»è¾“å‡ºToken**: {self._format_tokens(summary.total_output_tokens)}",
            f"- **æ€»å·¥å…·è°ƒç”¨æ¬¡æ•°**: {summary.total_tool_calls}",
            "",
            "## ğŸ’° æˆæœ¬ä¼°ç®—",
            "",
            f"- **è¾“å…¥æˆæœ¬**: ${summary.cost_estimation.get('input_cost_usd', 0):.6f} USD",
            f"- **è¾“å‡ºæˆæœ¬**: ${summary.cost_estimation.get('output_cost_usd', 0):.6f} USD", 
            f"- **æ€»æˆæœ¬**: ${summary.cost_estimation.get('total_cost_usd', 0):.6f} USD",
            f"- **å®šä»·æ¨¡å‹**: {summary.cost_estimation.get('pricing_model', 'Unknown')}",
            f"- **è¾“å…¥è´¹ç‡**: ${summary.cost_estimation.get('input_rate_per_1k', 0):.3f} USD/1K tokens",
            f"- **è¾“å‡ºè´¹ç‡**: ${summary.cost_estimation.get('output_rate_per_1k', 0):.3f} USD/1K tokens",
            "",
            "## ğŸ”„ é˜¶æ®µæ‰§è¡Œè¯¦æƒ…",
            "",
            "| é˜¶æ®µåç§° | çŠ¶æ€ | æ‰§è¡Œæ—¶é—´(ç§’) | è¾“å…¥Token | è¾“å‡ºToken | å·¥å…·è°ƒç”¨æ¬¡æ•° |",
            "|---------|------|-------------|-----------|-----------|-------------|"
        ]
        
        # æ·»åŠ å„é˜¶æ®µè¯¦æƒ…
        for stage in summary.stages:
            status_icon = "âœ…" if stage.success else "âŒ"
            duration = f"{stage.duration:.2f}" if stage.duration else "N/A"
            
            report_lines.append(
                f"| {stage.stage_name} | {status_icon} | {duration} | {self._format_tokens(stage.input_tokens)} | {self._format_tokens(stage.output_tokens)} | {stage.tool_calls} |"
            )
            
            # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œæ·»åŠ è¯¦ç»†ä¿¡æ¯
            if stage.error_message:
                report_lines.append(f"| | **é”™è¯¯**: {stage.error_message} | | | | |")
        
        report_lines.extend([
            "",
            "## ğŸ› ï¸ å·¥å…·ä½¿ç”¨ç»Ÿè®¡",
            "",
            "| å·¥å…·åç§° | è°ƒç”¨æ¬¡æ•° |",
            "|---------|----------|"
        ])
        
        # æ·»åŠ å·¥å…·ä½¿ç”¨ç»Ÿè®¡
        if summary.tool_usage_summary:
            for tool_name, call_count in sorted(summary.tool_usage_summary.items(), key=lambda x: x[1], reverse=True):
                report_lines.append(f"| {tool_name} | {call_count} |")
        else:
            report_lines.append("| æ— å·¥å…·è°ƒç”¨è®°å½• | 0 |")
        
        report_lines.extend([
            "",
            "## ğŸ“ˆ æ€§èƒ½åˆ†æ",
            "",
            f"- **å¹³å‡æ¯é˜¶æ®µæ‰§è¡Œæ—¶é—´**: {summary.total_duration / len(summary.stages):.2f} ç§’",
            f"- **Tokenæ•ˆç‡**: {summary.total_output_tokens / max(summary.total_input_tokens, 1):.2f} (è¾“å‡º/è¾“å…¥æ¯”)",
            f"- **å·¥å…·è°ƒç”¨é¢‘ç‡**: {summary.total_tool_calls / max(summary.total_duration, 1):.2f} æ¬¡/ç§’",
            "",
            "## ğŸ” è¯¦ç»†å·¥å…·è°ƒç”¨è®°å½•",
            ""
        ])
        
        # æ·»åŠ è¯¦ç»†å·¥å…·è°ƒç”¨è®°å½•
        for stage in summary.stages:
            if stage.tool_call_details:
                report_lines.extend([
                    f"### {stage.stage_name}",
                    "",
                    "| å·¥å…·åç§° | è°ƒç”¨æ¬¡æ•° | æˆåŠŸæ¬¡æ•° | å¤±è´¥æ¬¡æ•° | æ€»è€—æ—¶(ç§’) |",
                    "|---------|----------|----------|----------|------------|"
                ])
                
                for tool_detail in stage.tool_call_details:
                    report_lines.append(
                        f"| {tool_detail['tool_name']} | {tool_detail['call_count']} | "
                        f"{tool_detail['success_count']} | {tool_detail['error_count']} | "
                        f"{tool_detail['total_time']:.3f} |"
                    )
                report_lines.append("")
        
        report_lines.extend([
            "## ğŸ“ æ€»ç»“",
            "",
            f"æœ¬æ¬¡å·¥ä½œæµæ‰§è¡Œå…±æ¶‰åŠ {len(summary.stages)} ä¸ªé˜¶æ®µï¼Œ",
            f"æˆåŠŸå®Œæˆ {summary.successful_stages} ä¸ªé˜¶æ®µï¼Œ",
            f"æ€»è€—æ—¶ {summary.total_duration:.2f} ç§’ï¼Œ",
            f"æ¶ˆè€—Token {self._format_tokens(summary.total_input_tokens + summary.total_output_tokens)} ä¸ªï¼Œ",
            f"è°ƒç”¨å·¥å…· {summary.total_tool_calls} æ¬¡ã€‚",
            "",
            "---",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        ])
        
        return "\n".join(report_lines)


def generate_workflow_summary_report(graph_result: Any, 
                                   default_project_root_path: str) -> str:
    """
    ç”Ÿæˆå·¥ä½œæµæ€»ç»“æŠ¥å‘Šçš„ä¸»å‡½æ•°
    
    Args:
        graph_result: GraphResultå¯¹è±¡
        default_project_root_path: é¡¹ç›®æ ¹è·¯å¾„
    
    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    try:
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = WorkflowReportGenerator()
        
        # è§£æå·¥ä½œæµç»“æœ
        summary = generator.parse_workflow_result(graph_result)
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if default_project_root_path.startswith('/projects/'):
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            project_root = os.path.join(os.getcwd(), default_project_root_path.lstrip('/'))
        else:
            project_root = default_project_root_path
        
        # åœ¨projects/<project_name>ä¸‹ç”ŸæˆæŠ¥å‘Š
        project_dir = os.path.join(project_root, summary.project_name)
        output_path = os.path.join(project_dir, "workflow_summary_report.md")
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = generator.generate_markdown_report(summary, output_path)
        
        return report_path
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå·¥ä½œæµæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
        return ""


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("å·¥ä½œæµæŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯•")
    print("è¯·ç›´æ¥ä¼ é€’GraphResultå¯¹è±¡ç»™generate_workflow_summary_reportå‡½æ•°")
    print("ç¤ºä¾‹ç”¨æ³•:")
    print("  from utils.workflow_report_generator import generate_workflow_summary_report")
    print("  report_path = generate_workflow_summary_report(graph_result, './projects')")