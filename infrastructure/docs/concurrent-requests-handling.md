# 并发请求处理机制说明

## 问题：单个Fargate实例处理多个创建请求

当后端只有一个API Fargate任务实例时，如果前端同时提交了多个项目创建请求，系统会如何处理？

## 处理机制

### 1. FastAPI异步处理层

**FastAPI支持并发请求处理**：
- FastAPI基于Starlette构建，原生支持异步请求处理
- 使用ASGI服务器（uvicorn），可以并发处理多个HTTP请求
- 每个HTTP请求在独立的异步任务中处理，互不阻塞

**处理流程**：
```
前端请求 → ALB → Fargate容器 → FastAPI → 异步处理
```

### 2. 请求处理流程

当收到多个创建请求时：

1. **HTTP请求层**（无限制）
   - FastAPI可以同时接收多个HTTP请求
   - 每个请求独立处理，互不阻塞
   - 只受ALB连接限制和容器资源限制

2. **业务逻辑层**（异步）
   - 创建项目记录 → 写入DynamoDB（并发安全）
   - 初始化阶段 → 写入DynamoDB（并发安全）
   - 提交构建任务 → ThreadPoolExecutor

3. **工作流执行层**（有并发限制）
   - 任务提交到ThreadPoolExecutor（max_workers=5）
   - 最多同时执行5个工作流
   - 超过5个的请求会在队列中等待

### 3. 并发控制点

#### 3.1 HTTP请求处理（无限制）
- **FastAPI**: 可以同时处理多个请求
- **限制因素**: 
  - ALB连接限制（默认1024）
  - 容器CPU/内存资源
  - uvicorn worker数量（默认1个worker）

#### 3.2 DynamoDB操作（并发安全）
- DynamoDB支持并发写入
- 每个项目创建操作都是独立的PutItem
- **没有阻塞问题**

#### 3.3 工作流执行（有并发限制）
- **ThreadPoolExecutor**: max_workers=5
- **行为**: 
  - 前5个请求立即开始执行工作流
  - 第6个及以后的请求会等待工作线程可用
  - 等待是自动的，不需要额外代码

### 4. 实际场景分析

#### 场景1：同时提交3个创建请求

```
时间线：
T0: 请求1、2、3同时到达
T1: 所有请求的HTTP处理完成，项目记录已创建
T2: 请求1、2、3的工作流同时提交到ThreadPoolExecutor
T3: 工作流1、2、3同时开始执行（都在5个工作线程内）
```

**结果**: ✅ 所有请求立即处理，无阻塞

#### 场景2：同时提交10个创建请求

```
时间线：
T0: 请求1-10同时到达
T1: 所有请求的HTTP处理完成，项目记录已创建
T2: 请求1-10的工作流提交到ThreadPoolExecutor
T3: 工作流1-5立即开始执行
T4: 工作流6-10等待工作线程可用
T5: 工作流1完成，工作流6开始执行
T6: 工作流2完成，工作流7开始执行
...（依此类推）
```

**结果**: ✅ 前5个立即执行，后5个排队等待

### 5. 关键代码位置

#### 5.1 创建项目接口
```python
# api/routers/projects.py
@router.post("/projects")
async def create_project(...):
    # 1. 创建项目记录（DynamoDB）
    project = project_service.create_project(...)
    
    # 2. 提交异步构建任务
    build_agent(...)  # 提交到ThreadPoolExecutor
```

#### 5.2 工作流执行器
```python
# api/tasks/async_agent_build_tasks.py
_executor = ThreadPoolExecutor(max_workers=5, ...)

def build_agent(...):
    # 提交任务到线程池
    future = _executor.submit(_execute_build_agent, ...)
```

### 6. 资源使用情况

#### 单个工作流资源需求
- CPU: 中等（主要是AI模型调用）
- 内存: 较高（LLM上下文）
- 网络: 中等（API调用）
- I/O: 低（EFS文件操作）

#### 5个并发工作流资源需求
- CPU: 高（需要4 vCPU）
- 内存: 高（需要8GB+）
- 网络: 高（多个并发API调用）
- I/O: 中等（并发EFS访问）

### 7. 性能优化建议

#### 7.1 增加服务实例数（推荐）

如果经常有超过5个并发请求：

```hcl
# terraform.tfvars
api_desired_count = 3  # 3个实例，每个5个工作流 = 15个并发工作流
```

**优势**:
- 线性扩展并发能力
- 提高可用性（单实例故障不影响整体）
- 负载分散

#### 7.2 调整工作流并发数

根据实际负载调整：

```hcl
# terraform.tfvars
max_workflow_workers = 3  # 降低并发数，确保资源充足
# 或者
max_workflow_workers = 10  # 增加并发数，如果资源允许
```

**注意**: 需要相应调整CPU和内存配置

#### 7.3 使用任务队列（高级）

对于大量请求，可以考虑：
- SQS队列管理任务分发
- 多个Worker服务消费队列
- 更好的任务优先级和重试机制

### 8. 监控和告警

#### 8.1 关键指标

- **HTTP请求数**: CloudWatch Metrics
- **活跃工作流数**: 应用日志
- **等待队列长度**: 应用日志
- **CPU/内存使用率**: CloudWatch Container Insights

#### 8.2 告警设置

```hcl
# 建议设置以下告警：
- CPU使用率 > 80%
- 内存使用率 > 80%
- HTTP 5xx错误率 > 1%
- 工作流执行时间 > 阈值
```

### 9. 最佳实践

#### 9.1 生产环境配置

```hcl
# 推荐配置（中等负载）
api_cpu = 4096              # 4 vCPU
api_memory = 8192           # 8GB
api_desired_count = 2       # 2个实例
max_workflow_workers = 5    # 每个实例5个工作流
# 总并发能力：2 × 5 = 10个工作流
```

#### 9.2 高负载配置

```hcl
# 高负载配置
api_cpu = 4096              # 4 vCPU
api_memory = 8192           # 8GB
api_desired_count = 4       # 4个实例
max_workflow_workers = 5    # 每个实例5个工作流
# 总并发能力：4 × 5 = 20个工作流
```

#### 9.3 资源限制

**单实例最大工作流数**:
- 受CPU限制：4 vCPU可以支持约5-7个工作流
- 受内存限制：8GB可以支持约5个工作流（每个约1.5GB）
- **建议**: 不要超过5个，除非增加资源配置

### 10. 常见问题

#### Q1: 如果同时提交100个请求会怎样？

**A**: 
- HTTP请求都会立即返回（项目记录已创建）
- 前5个工作流立即开始执行
- 其余95个在工作队列中等待
- 随着工作流完成，队列中的任务会依次执行

#### Q2: 等待队列中的请求会超时吗？

**A**: 
- HTTP请求不会超时（已立即返回）
- 工作流执行有超时保护（可通过配置设置）
- 建议：前端通过轮询API检查项目状态

#### Q3: 如何知道工作流是否在等待？

**A**: 
- 查看项目状态：`status = "BUILDING"`
- 查看阶段快照：检查`stages_snapshot`中的阶段状态
- 查看日志：检查工作流执行日志

#### Q4: 单个实例故障会影响其他请求吗？

**A**: 
- 如果只有1个实例，故障会影响所有请求
- 建议：至少2个实例，提高可用性
- ECS会自动重启故障的任务

## 总结

✅ **单个Fargate实例可以处理多个创建请求**

- HTTP请求层：无限制并发
- 业务逻辑层：并发安全（DynamoDB）
- 工作流执行层：有限并发（默认5个）

✅ **超过并发限制的请求会自动排队**

- 无需额外代码
- ThreadPoolExecutor自动管理队列
- 工作流完成后自动执行下一个

✅ **推荐配置**

- 生产环境：至少2个实例
- 每个实例：4 vCPU + 8GB内存 + 5个工作流
- 总并发能力：实例数 × 5

