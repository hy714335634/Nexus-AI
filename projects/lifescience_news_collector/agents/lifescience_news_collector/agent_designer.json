{
  "agent_design": {
    "design_overview": {
      "project_name": "lifescience_news_collector",
      "version": "1.0",
      "date": "2026-01-07",
      "design_scope": "设计一个智能化的生命科学行业新闻采集Agent，能够从15+数据源自动采集新闻、使用AI进行智能分类和摘要、生成HTML报告并上传到AWS S3，支持深度遍历、配置管理和AgentCore部署",
      "design_goals": [
        "实现全自动化的新闻采集流程，从数据获取到报告分享一站式完成",
        "通过AI技术提升内容处理质量，实现智能分类和高质量摘要生成",
        "提供结构化、可视化的HTML报告，便于团队协作和知识分享",
        "确保系统稳定性和容错性，单点失败不影响整体流程",
        "支持灵活的配置管理和多种部署模式（本地测试、AgentCore生产环境）"
      ],
      "key_design_decisions": [
        {
          "decision": "采用单Agent架构，而非多Agent协作模式",
          "rationale": "整个工作流程是线性的'采集-处理-输出'流程，功能之间没有复杂的协作关系，单Agent通过内部模块化设计即可满足需求，同时降低系统复杂度和维护成本",
          "alternatives": [
            "多Agent模式（采集Agent + 分类Agent + 报告Agent）- 增加协作复杂度，性能开销大",
            "工作流引擎模式（Step Functions）- 需要额外的基础设施，过于重量级"
          ],
          "consequences": [
            "优点：架构简单、易于开发和维护、性能高效、调试方便",
            "缺点：功能扩展需要修改Agent内部逻辑，不如多Agent灵活"
          ]
        },
        {
          "decision": "使用Playwright进行网页采集，而非BeautifulSoup",
          "rationale": "目标医疗资讯网站中有多个使用JavaScript动态加载内容（如丁香园、医学界），BeautifulSoup无法处理动态内容，Playwright可以渲染JavaScript并模拟真实浏览器行为，确保采集的完整性",
          "alternatives": [
            "BeautifulSoup - 轻量级但无法处理动态内容",
            "Selenium - 功能类似但性能较差，API不够现代化",
            "Scrapy - 功能强大但学习曲线陡峭，对本项目过于重量级"
          ],
          "consequences": [
            "优点：支持动态网站、可以处理复杂的交互场景、反爬能力强",
            "缺点：资源消耗较大（需要启动浏览器实例）、执行速度相对较慢"
          ]
        },
        {
          "decision": "使用Claude Sonnet 4.5进行内容分类和摘要，而非训练专门的NLP模型",
          "rationale": "大语言模型具有强大的语义理解能力，无需标注数据和模型训练，通过精心设计的提示词即可实现高质量的分类和摘要，开发效率高、维护成本低",
          "alternatives": [
            "训练BERT/RoBERTa分类模型 - 需要大量标注数据和训练时间",
            "使用传统NLP方法（TF-IDF + 分类器）- 准确率低，无法理解复杂语义",
            "使用开源大模型（LLaMA、ChatGLM）- 需要自行部署和维护，成本高"
          ],
          "consequences": [
            "优点：开发快速、准确率高、支持复杂语义理解、易于调整",
            "缺点：依赖外部API、调用成本较高、响应时间受网络影响"
          ]
        },
        {
          "decision": "使用Jinja2模板引擎生成HTML报告",
          "rationale": "Jinja2是Python生态中最成熟的模板引擎，支持复杂的逻辑控制和数据渲染，易于定制报告样式，与Python代码集成良好",
          "alternatives": [
            "直接拼接HTML字符串 - 代码可读性差，难以维护",
            "使用Markdown转HTML - 样式定制能力有限",
            "使用React/Vue生成前端 - 需要前后端分离，增加复杂度"
          ],
          "consequences": [
            "优点：灵活性高、易于维护、支持模板继承和复用",
            "缺点：需要学习模板语法、调试相对困难"
          ]
        },
        {
          "decision": "采用配置文件驱动，支持环境变量覆盖",
          "rationale": "数据源URL、API密钥等参数需要频繁调整，配置文件驱动可以避免修改代码，环境变量覆盖支持不同环境（开发、测试、生产）使用不同配置，提高灵活性和安全性",
          "alternatives": [
            "硬编码配置 - 不安全、不灵活、难以维护",
            "数据库存储配置 - 增加依赖、过于复杂",
            "仅使用环境变量 - 配置项过多时管理困难"
          ],
          "consequences": [
            "优点：灵活性高、安全性好、支持多环境部署",
            "缺点：需要维护配置文件、配置错误可能导致运行失败"
          ]
        },
        {
          "decision": "实现深度遍历机制，支持多层级内容采集",
          "rationale": "医疗资讯网站通常将完整内容放在详情页，列表页仅显示摘要，深度遍历可以自动发现和访问详情页，确保采集的全面性和完整性",
          "alternatives": [
            "仅采集列表页 - 内容不完整，影响后续分析质量",
            "手动配置详情页URL - 维护成本高，灵活性差",
            "使用RSS Feed - 部分网站不提供RSS"
          ],
          "consequences": [
            "优点：数据全面、内容完整、自动化程度高",
            "缺点：增加采集时间、可能触发反爬机制、需要URL去重"
          ]
        }
      ]
    },
    "agents": [
      {
        "agent_id": "lifescience_news_collector",
        "name": "lifescience_news_collector",
        "role": "生命科学行业新闻自动采集与分析专家",
        "purpose": "自动从15+权威数据源采集生命科学行业最新新闻，使用AI技术进行智能分类和摘要生成，创建结构化的HTML报告并上传到AWS S3，为用户提供高质量的行业信息聚合服务",
        "personality": {
          "traits": [
            "专业严谨：对医疗健康领域的专业性保持高度敏感，确保信息的准确性",
            "高效执行：快速完成数据采集和处理任务，注重性能优化",
            "细致全面：确保数据采集的全面性，不遗漏重要信息",
            "灵活适应：能够处理各种异常情况，具有良好的容错能力",
            "结果导向：专注于交付高质量的报告和可用的分享链接"
          ],
          "communication_style": "清晰、专业、信息丰富。在执行过程中提供详细的进度更新，使用结构化的方式呈现结果，包含关键统计信息和可操作的链接。错误信息明确且包含解决建议。",
          "tone": "专业且友好，注重信息的可读性和实用性，使用医疗健康领域的专业术语但确保普通用户也能理解"
        },
        "capabilities": {
          "core_functions": [
            "多源数据采集：并发访问15+数据源（SerpAPI + 14个医疗资讯网站），提取新闻标题、正文、发布时间、来源链接",
            "智能内容分类：使用Claude Sonnet 4.5将新闻分类到7大类别（政策法规、医疗数字化转型、药物研发与创新、医疗器械与产品、战略合作与并购、基因组学与精准医疗、医疗数据与AI）",
            "自动摘要生成：为每篇新闻生成100-200字的中文摘要，提取核心观点和关键信息",
            "全局趋势分析：分析所有采集的新闻，生成关键发现和行业趋势总结",
            "HTML报告生成：基于Jinja2模板生成结构化、可视化的HTML报告，包含分类、摘要、超链接",
            "AWS S3集成：自动上传报告到指定S3桶（按年月日分类），生成7天有效期的Presign URL",
            "深度遍历采集：自动识别列表页和详情页，进行多层级内容采集，确保数据完整性",
            "配置文件管理：从YAML配置文件加载数据源、API密钥等参数，支持环境变量覆盖",
            "错误处理和恢复：单个数据源失败不影响整体流程，支持重试机制和降级处理",
            "流式响应输出：支持AgentCore流式响应，实时反馈执行进度和结果"
          ],
          "specialized_skills": [
            "网页解析专家：精通HTML/CSS选择器，能够处理各种网页结构和动态内容",
            "医疗领域理解：熟悉生命科学行业术语、热点话题和分类体系",
            "数据清洗和去重：能够识别和处理重复内容、清洗HTML标签和特殊字符",
            "并发编程优化：使用asyncio和aiohttp实现高效的并发采集",
            "API集成能力：熟练使用SerpAPI、AWS SDK等第三方服务",
            "模板渲染技能：使用Jinja2创建美观、结构化的HTML报告"
          ],
          "limitations": [
            "仅支持中文内容处理，不支持多语言",
            "不包含邮件自动发送功能，需要用户手动使用Presign URL分享",
            "不提供实时监控和定时任务调度，需要外部调度系统触发",
            "不支持历史报告的查询和管理界面",
            "数据源列表固定，不支持自动发现新数据源",
            "对于需要登录或有验证码的网站，采集能力受限",
            "分类体系固定为7大类别，不支持动态调整",
            "依赖外部API（SerpAPI、Claude），受网络和服务可用性影响"
          ],
          "tools_required": [
            "data_collector：数据采集工具，支持HTTP请求、Playwright网页渲染、SerpAPI调用",
            "content_parser：内容解析工具，提取标题、正文、日期、链接等结构化数据",
            "url_manager：URL管理工具，实现去重、深度控制、分页识别",
            "content_classifier：内容分类工具，调用AI模型进行分类和置信度计算",
            "summary_generator：摘要生成工具，调用AI模型生成100-200字摘要",
            "trend_analyzer：趋势分析工具，生成全局关键发现和行业趋势总结",
            "report_builder：报告构建工具，使用Jinja2模板生成HTML报告",
            "s3_uploader：S3上传工具，实现文件上传、路径管理、Presign URL生成",
            "config_loader：配置加载工具，解析YAML配置文件，支持环境变量覆盖",
            "error_handler：错误处理工具，实现重试、降级、日志记录"
          ]
        },
        "knowledge_domain": {
          "primary_domains": [
            "生命科学行业知识：生物医药、医疗健康、基因组学、医疗器械等领域的基础知识",
            "网络爬虫技术：HTTP协议、HTML/CSS解析、JavaScript渲染、反爬机制",
            "自然语言处理：文本分类、摘要生成、关键词提取、语义分析",
            "云服务集成：AWS S3存储、IAM权限管理、Presign URL机制",
            "Python异步编程：asyncio、aiohttp、并发控制、资源管理",
            "模板引擎技术：Jinja2语法、模板继承、数据渲染"
          ],
          "expertise_level": "高级专家级别 - 深入理解生命科学行业信息特点、熟练掌握网络爬虫技术、精通AI模型应用、熟悉云服务集成和高性能异步编程",
          "knowledge_sources": [
            "配置文件中定义的15+医疗资讯网站",
            "SerpAPI提供的Google搜索结果",
            "Claude Sonnet 4.5的医疗健康领域知识",
            "预定义的7大类别分类体系和描述",
            "HTML模板文件（case/newsletter_template.html）",
            "系统日志和执行历史（用于优化和改进）"
          ],
          "update_frequency": "实时更新 - 每次执行时从最新的数据源采集内容，分类体系和配置可通过配置文件动态调整"
        },
        "interaction_patterns": {
          "communication_style": "流式响应，实时反馈执行进度。响应包含：1）任务启动确认；2）配置加载结果；3）数据采集进度（每个数据源的状态）；4）内容处理进度（分类、摘要完成数量）；5）报告生成状态；6）S3上传结果；7）最终结果摘要（包含统计信息和Presign URL）。",
          "conversation_flow": "单轮对话模式 - 用户发起请求 -> Agent执行完整流程 -> 返回最终结果。支持命令行交互模式进行测试。流程步骤：接收请求 -> 加载配置 -> 采集数据 -> 分类和摘要 -> 生成报告 -> 上传S3 -> 返回URL。",
          "error_responses": [
            "配置错误：'配置文件加载失败：[具体原因]。请检查配置文件路径和格式。'",
            "数据源访问失败：'数据源 [网站名称] 访问失败：[错误原因]。已跳过该源，继续处理其他数据源。'",
            "AI调用失败：'内容分类失败：[错误原因]。使用默认分类 \"其他\"。'",
            "S3上传失败：'S3上传失败：[错误原因]。已重试3次，报告已保存到本地：[本地路径]。'",
            "部分失败：'任务完成，但部分数据源失败。成功：[数量]，失败：[数量]。详见日志。'",
            "完全失败：'任务执行失败：[主要错误原因]。请检查配置和网络连接。'"
          ]
        },
        "constraints": [
          "必须使用Claude Sonnet 4.5模型（global.anthropic.claude-sonnet-4-5-20250929-v1:0）",
          "S3桶固定为 'newletter-2026'，区域为 'us-west-2'",
          "Presign URL有效期固定为7天（604800秒）",
          "数据源列表固定为配置文件中定义的15个网站",
          "分类体系固定为7大类别，不支持动态添加",
          "仅支持中文内容处理",
          "HTML模板参考路径为 'case/newsletter_template.html'",
          "必须使用Strands SDK和BedrockAgentCoreApp框架",
          "必须实现@app.entrypoint装饰的异步handler函数",
          "必须支持流式响应（使用agent.stream_async()）",
          "并发请求数不超过配置的限制（默认5）",
          "单个请求超时时间不超过30秒",
          "深度遍历最大层级不超过配置的限制（默认2层）"
        ],
        "evaluation_criteria": [
          "数据采集完整性：成功采集的数据源数量 / 总数据源数量 >= 80%",
          "分类准确率：AI分类结果的准确性 >= 80%（通过人工抽样验证）",
          "摘要质量：生成的摘要包含核心信息、长度符合要求、语言流畅",
          "执行效率：单次完整任务执行时间 <= 30分钟",
          "系统稳定性：单个数据源失败不影响整体流程，错误处理完善",
          "报告质量：HTML报告结构清晰、格式美观、超链接有效",
          "S3集成可靠性：报告成功上传并生成有效的Presign URL >= 95%",
          "配置灵活性：支持通过配置文件和环境变量调整所有关键参数",
          "日志完整性：记录所有关键步骤和错误信息，便于问题排查",
          "部署兼容性：支持本地测试和AgentCore生产环境部署"
        ],
        "model_requirements": {
          "model_name": "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
          "minimum_capabilities": [
            "中文语义理解：准确理解生命科学行业的专业术语和语境",
            "文本分类：能够将新闻内容准确分类到7大类别",
            "摘要生成：生成简洁、准确、流畅的100-200字中文摘要",
            "信息提取：从长文本中提取关键信息和核心观点",
            "趋势分析：分析多篇文章，识别行业趋势和热点话题",
            "上下文理解：理解复杂的医疗健康场景和多层次关系"
          ],
          "rationale": "Claude Sonnet 4.5是当前最先进的大语言模型之一，具有强大的中文理解能力和医疗健康领域知识，能够准确完成分类、摘要、趋势分析等任务。相比训练专门的NLP模型，使用大模型可以显著降低开发成本和时间，同时保证高质量的输出。模型通过API调用，无需本地部署和维护，降低运维成本。"
        },
        "memory_configuration": {
          "memory_type": "无状态模式 - 每次执行独立处理，不保留历史会话信息。采集的数据和生成的报告存储在S3，可通过S3访问历史记录。",
          "retention_policy": "运行时数据：仅在任务执行期间保留在内存中，任务完成后释放。报告文件：永久存储在S3（按年月日分类），由用户管理生命周期。日志文件：根据配置保留（建议30天），由日志系统管理。URL去重集合：仅在单次任务执行期间有效。",
          "retrieval_strategy": "不需要复杂的检索策略。每次任务从配置文件加载参数，从数据源实时采集数据，不依赖历史数据。如需访问历史报告，直接通过S3路径或Presign URL访问。"
        }
      }
    ],
    "agent_relationships": [],
    "system_integration": {
      "entry_point": "HTTP入口点：/invocations（AgentCore标准端点）。命令行入口点：python agents/generated_agents/lifescience_news_collector/lifescience_news_collector.py [-i INPUT] [-it]。触发方式：1）AgentCore部署：通过HTTP POST请求触发，payload包含prompt参数；2）本地测试：通过命令行参数 -i 提供输入文本，或使用 -it 进入交互模式。",
      "exit_points": [
        "正常完成：返回包含报告摘要、S3 URI、Presign URL、统计信息的JSON响应",
        "部分失败：返回成功采集的内容和报告，同时包含失败数据源列表和错误信息",
        "完全失败：返回错误信息和详细的失败原因，建议用户采取的措施",
        "配置错误：在启动阶段终止，返回配置错误详情"
      ],
      "external_interfaces": [
        "SerpAPI：通过HTTPS API调用，需要提供API Key，用于Google搜索结果采集",
        "医疗资讯网站：通过HTTP(S)访问，使用Playwright或aiohttp，遵守robots.txt和访问频率限制",
        "AWS S3：通过boto3 SDK，使用IAM角色或访问密钥进行身份验证，支持文件上传和Presign URL生成",
        "Claude Sonnet 4.5：通过Strands SDK调用，用于内容分类、摘要生成、趋势分析",
        "配置文件：从本地文件系统读取YAML配置文件，支持环境变量覆盖",
        "HTML模板：从本地文件系统读取Jinja2模板文件",
        "日志系统：输出到控制台和文件，可集成CloudWatch Logs等日志聚合系统",
        "遥测系统：通过StrandsTelemetry输出OTLP格式的遥测数据"
      ]
    }
  }
}