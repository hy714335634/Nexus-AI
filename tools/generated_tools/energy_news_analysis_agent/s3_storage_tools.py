#!/usr/bin/env python3
"""
S3 storage tools using boto3 for file upload and management.
Supports direct upload, batch upload, and public URL generation.
"""

import json
import os
import mimetypes
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from urllib.parse import quote

from strands import tool

try:
    import boto3
    from botocore.exceptions import ClientError, NoCredentialsError
    BOTO3_AVAILABLE = True
except ImportError:
    BOTO3_AVAILABLE = False


@tool
def upload_file_to_s3(
    file_path: str,
    bucket_name: str,
    s3_key: Optional[str] = None,
    public_read: bool = True,
    content_type: Optional[str] = None,
    metadata: Optional[Dict[str, str]] = None
) -> str:
    """
    ä¸Šä¼ æ–‡ä»¶åˆ°S3å­˜å‚¨æ¡¶
    
    Args:
        file_path (str): æœ¬åœ°æ–‡ä»¶è·¯å¾„
        bucket_name (str): S3å­˜å‚¨æ¡¶åç§°
        s3_key (str, optional): S3å¯¹è±¡é”®ï¼ˆä¸æŒ‡å®šåˆ™ä½¿ç”¨æ–‡ä»¶åï¼‰
        public_read (bool): æ˜¯å¦è®¾ç½®ä¸ºå…¬å¼€å¯è¯»
        content_type (str, optional): æ–‡ä»¶MIMEç±»å‹ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
        metadata (Dict, optional): è‡ªå®šä¹‰å…ƒæ•°æ®
        
    Returns:
        str: JSONæ ¼å¼çš„ä¸Šä¼ ç»“æœ
    """
    try:
        if not BOTO3_AVAILABLE:
            return json.dumps({
                "status": "error",
                "message": "boto3åº“æœªå®‰è£…ã€‚è¯·å®‰è£…: pip install boto3"
            }, ensure_ascii=False)
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        file_path_obj = Path(file_path)
        if not file_path_obj.exists():
            return json.dumps({
                "status": "error",
                "message": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }, ensure_ascii=False)
        
        # ç”ŸæˆS3é”®
        if not s3_key:
            s3_key = file_path_obj.name
        
        # è‡ªåŠ¨æ£€æµ‹Content-Type
        if not content_type:
            content_type, _ = mimetypes.guess_type(file_path)
            if not content_type:
                content_type = "application/octet-stream"
        
        # åˆ›å»ºS3å®¢æˆ·ç«¯
        s3_client = boto3.client('s3')
        
        # å‡†å¤‡ä¸Šä¼ å‚æ•°
        extra_args = {
            'ContentType': content_type
        }
        
        if public_read:
            extra_args['ACL'] = 'public-read'
        
        if metadata:
            extra_args['Metadata'] = metadata
        
        # ä¸Šä¼ æ–‡ä»¶
        s3_client.upload_file(
            Filename=file_path,
            Bucket=bucket_name,
            Key=s3_key,
            ExtraArgs=extra_args
        )
        
        # ç”Ÿæˆå…¬å¼€URL
        if public_read:
            region = s3_client.get_bucket_location(Bucket=bucket_name)['LocationConstraint']
            if region is None:
                region = 'us-east-1'
            
            public_url = f"https://{bucket_name}.s3.{region}.amazonaws.com/{quote(s3_key)}"
        else:
            public_url = None
        
        return json.dumps({
            "status": "success",
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
            "file_path": file_path,
            "bucket_name": bucket_name,
            "s3_key": s3_key,
            "public_url": public_url,
            "file_size": file_path_obj.stat().st_size,
            "content_type": content_type,
            "upload_time": datetime.now().isoformat()
        }, ensure_ascii=False, indent=2)
        
    except NoCredentialsError:
        return json.dumps({
            "status": "error",
            "message": "AWSå‡­è¯æœªé…ç½®ã€‚è¯·é…ç½®AWS_ACCESS_KEY_IDå’ŒAWS_SECRET_ACCESS_KEY"
        }, ensure_ascii=False)
    except ClientError as e:
        return json.dumps({
            "status": "error",
            "message": f"S3æ“ä½œå¤±è´¥: {e.response['Error']['Message']}"
        }, ensure_ascii=False)
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"ä¸Šä¼ å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def batch_upload_to_s3(
    file_paths: List[str],
    bucket_name: str,
    s3_prefix: Optional[str] = None,
    public_read: bool = True
) -> str:
    """
    æ‰¹é‡ä¸Šä¼ æ–‡ä»¶åˆ°S3
    
    Args:
        file_paths (List[str]): æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        bucket_name (str): S3å­˜å‚¨æ¡¶åç§°
        s3_prefix (str, optional): S3é”®å‰ç¼€ï¼ˆç›®å½•ï¼‰
        public_read (bool): æ˜¯å¦è®¾ç½®ä¸ºå…¬å¼€å¯è¯»
        
    Returns:
        str: JSONæ ¼å¼çš„æ‰¹é‡ä¸Šä¼ ç»“æœ
    """
    try:
        results = {
            "status": "success",
            "bucket_name": bucket_name,
            "s3_prefix": s3_prefix or "",
            "total_files": len(file_paths),
            "successful_uploads": 0,
            "failed_uploads": 0,
            "upload_results": [],
            "upload_time": datetime.now().isoformat()
        }
        
        for file_path in file_paths:
            try:
                # ç”ŸæˆS3é”®
                file_name = Path(file_path).name
                s3_key = f"{s3_prefix}/{file_name}" if s3_prefix else file_name
                
                # ä¸Šä¼ æ–‡ä»¶
                upload_result_json = upload_file_to_s3(
                    file_path=file_path,
                    bucket_name=bucket_name,
                    s3_key=s3_key,
                    public_read=public_read
                )
                upload_result = json.loads(upload_result_json)
                
                if upload_result["status"] == "success":
                    results["successful_uploads"] += 1
                else:
                    results["failed_uploads"] += 1
                
                results["upload_results"].append({
                    "file_path": file_path,
                    "status": upload_result["status"],
                    "s3_key": upload_result.get("s3_key"),
                    "public_url": upload_result.get("public_url"),
                    "message": upload_result.get("message")
                })
                
            except Exception as e:
                results["failed_uploads"] += 1
                results["upload_results"].append({
                    "file_path": file_path,
                    "status": "error",
                    "message": str(e)
                })
        
        return json.dumps(results, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"æ‰¹é‡ä¸Šä¼ å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def upload_directory_to_s3(
    directory_path: str,
    bucket_name: str,
    s3_prefix: Optional[str] = None,
    public_read: bool = True,
    recursive: bool = True,
    file_patterns: Optional[List[str]] = None
) -> str:
    """
    ä¸Šä¼ ç›®å½•åˆ°S3
    
    Args:
        directory_path (str): æœ¬åœ°ç›®å½•è·¯å¾„
        bucket_name (str): S3å­˜å‚¨æ¡¶åç§°
        s3_prefix (str, optional): S3é”®å‰ç¼€
        public_read (bool): æ˜¯å¦è®¾ç½®ä¸ºå…¬å¼€å¯è¯»
        recursive (bool): æ˜¯å¦é€’å½’ä¸Šä¼ å­ç›®å½•
        file_patterns (List[str], optional): æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆå¦‚["*.html", "*.json"]ï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„ä¸Šä¼ ç»“æœ
    """
    try:
        dir_path = Path(directory_path)
        if not dir_path.exists() or not dir_path.is_dir():
            return json.dumps({
                "status": "error",
                "message": f"ç›®å½•ä¸å­˜åœ¨: {directory_path}"
            }, ensure_ascii=False)
        
        # æ”¶é›†è¦ä¸Šä¼ çš„æ–‡ä»¶
        files_to_upload = []
        
        if recursive:
            if file_patterns:
                for pattern in file_patterns:
                    files_to_upload.extend(dir_path.rglob(pattern))
            else:
                files_to_upload.extend(dir_path.rglob("*"))
        else:
            if file_patterns:
                for pattern in file_patterns:
                    files_to_upload.extend(dir_path.glob(pattern))
            else:
                files_to_upload.extend(dir_path.glob("*"))
        
        # è¿‡æ»¤å‡ºæ–‡ä»¶ï¼ˆæ’é™¤ç›®å½•ï¼‰
        files_to_upload = [f for f in files_to_upload if f.is_file()]
        
        # æ‰¹é‡ä¸Šä¼ 
        file_paths = [str(f) for f in files_to_upload]
        
        results = {
            "status": "success",
            "directory_path": directory_path,
            "bucket_name": bucket_name,
            "s3_prefix": s3_prefix or "",
            "total_files": len(file_paths),
            "successful_uploads": 0,
            "failed_uploads": 0,
            "upload_results": [],
            "upload_time": datetime.now().isoformat()
        }
        
        for file_path in file_paths:
            try:
                # ä¿æŒç›®å½•ç»“æ„
                relative_path = Path(file_path).relative_to(dir_path)
                s3_key = f"{s3_prefix}/{relative_path}" if s3_prefix else str(relative_path)
                s3_key = s3_key.replace("\\", "/")  # Windowsè·¯å¾„è½¬æ¢
                
                # ä¸Šä¼ æ–‡ä»¶
                upload_result_json = upload_file_to_s3(
                    file_path=file_path,
                    bucket_name=bucket_name,
                    s3_key=s3_key,
                    public_read=public_read
                )
                upload_result = json.loads(upload_result_json)
                
                if upload_result["status"] == "success":
                    results["successful_uploads"] += 1
                else:
                    results["failed_uploads"] += 1
                
                results["upload_results"].append({
                    "file_path": file_path,
                    "status": upload_result["status"],
                    "s3_key": upload_result.get("s3_key"),
                    "public_url": upload_result.get("public_url")
                })
                
            except Exception as e:
                results["failed_uploads"] += 1
                results["upload_results"].append({
                    "file_path": file_path,
                    "status": "error",
                    "message": str(e)
                })
        
        return json.dumps(results, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"ç›®å½•ä¸Šä¼ å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def list_s3_objects(
    bucket_name: str,
    prefix: Optional[str] = None,
    max_keys: int = 1000
) -> str:
    """
    åˆ—å‡ºS3å­˜å‚¨æ¡¶ä¸­çš„å¯¹è±¡
    
    Args:
        bucket_name (str): S3å­˜å‚¨æ¡¶åç§°
        prefix (str, optional): å¯¹è±¡é”®å‰ç¼€
        max_keys (int): æœ€å¤§è¿”å›æ•°é‡
        
    Returns:
        str: JSONæ ¼å¼çš„å¯¹è±¡åˆ—è¡¨
    """
    try:
        if not BOTO3_AVAILABLE:
            return json.dumps({
                "status": "error",
                "message": "boto3åº“æœªå®‰è£…ã€‚è¯·å®‰è£…: pip install boto3"
            }, ensure_ascii=False)
        
        s3_client = boto3.client('s3')
        
        # åˆ—å‡ºå¯¹è±¡
        params = {
            'Bucket': bucket_name,
            'MaxKeys': max_keys
        }
        
        if prefix:
            params['Prefix'] = prefix
        
        response = s3_client.list_objects_v2(**params)
        
        objects = []
        for obj in response.get('Contents', []):
            objects.append({
                "key": obj['Key'],
                "size": obj['Size'],
                "last_modified": obj['LastModified'].isoformat(),
                "etag": obj['ETag'].strip('"')
            })
        
        return json.dumps({
            "status": "success",
            "bucket_name": bucket_name,
            "prefix": prefix or "",
            "total_objects": len(objects),
            "objects": objects,
            "query_time": datetime.now().isoformat()
        }, ensure_ascii=False, indent=2)
        
    except ClientError as e:
        return json.dumps({
            "status": "error",
            "message": f"S3æ“ä½œå¤±è´¥: {e.response['Error']['Message']}"
        }, ensure_ascii=False)
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"åˆ—å‡ºå¯¹è±¡å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def delete_s3_object(
    bucket_name: str,
    s3_key: str
) -> str:
    """
    åˆ é™¤S3å¯¹è±¡
    
    Args:
        bucket_name (str): S3å­˜å‚¨æ¡¶åç§°
        s3_key (str): S3å¯¹è±¡é”®
        
    Returns:
        str: JSONæ ¼å¼çš„åˆ é™¤ç»“æœ
    """
    try:
        if not BOTO3_AVAILABLE:
            return json.dumps({
                "status": "error",
                "message": "boto3åº“æœªå®‰è£…ã€‚è¯·å®‰è£…: pip install boto3"
            }, ensure_ascii=False)
        
        s3_client = boto3.client('s3')
        
        # åˆ é™¤å¯¹è±¡
        s3_client.delete_object(
            Bucket=bucket_name,
            Key=s3_key
        )
        
        return json.dumps({
            "status": "success",
            "message": "å¯¹è±¡åˆ é™¤æˆåŠŸ",
            "bucket_name": bucket_name,
            "s3_key": s3_key,
            "deletion_time": datetime.now().isoformat()
        }, ensure_ascii=False, indent=2)
        
    except ClientError as e:
        return json.dumps({
            "status": "error",
            "message": f"S3æ“ä½œå¤±è´¥: {e.response['Error']['Message']}"
        }, ensure_ascii=False)
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"åˆ é™¤å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def generate_presigned_url(
    bucket_name: str,
    s3_key: str,
    expiration: int = 3600
) -> str:
    """
    ç”ŸæˆS3å¯¹è±¡çš„é¢„ç­¾åURL
    
    Args:
        bucket_name (str): S3å­˜å‚¨æ¡¶åç§°
        s3_key (str): S3å¯¹è±¡é”®
        expiration (int): URLæœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„é¢„ç­¾åURL
    """
    try:
        if not BOTO3_AVAILABLE:
            return json.dumps({
                "status": "error",
                "message": "boto3åº“æœªå®‰è£…ã€‚è¯·å®‰è£…: pip install boto3"
            }, ensure_ascii=False)
        
        s3_client = boto3.client('s3')
        
        # ç”Ÿæˆé¢„ç­¾åURL
        presigned_url = s3_client.generate_presigned_url(
            'get_object',
            Params={
                'Bucket': bucket_name,
                'Key': s3_key
            },
            ExpiresIn=expiration
        )
        
        return json.dumps({
            "status": "success",
            "bucket_name": bucket_name,
            "s3_key": s3_key,
            "presigned_url": presigned_url,
            "expiration_seconds": expiration,
            "generation_time": datetime.now().isoformat()
        }, ensure_ascii=False, indent=2)
        
    except ClientError as e:
        return json.dumps({
            "status": "error",
            "message": f"S3æ“ä½œå¤±è´¥: {e.response['Error']['Message']}"
        }, ensure_ascii=False)
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"ç”Ÿæˆé¢„ç­¾åURLå¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def upload_report_to_s3(
    report_path: str,
    bucket_name: str,
    report_category: str = "energy_reports",
    public_read: bool = True
) -> str:
    """
    ä¸Šä¼ åˆ†ææŠ¥å‘Šåˆ°S3ï¼ˆå¸¦è‡ªåŠ¨åˆ†ç±»å’Œå‘½åï¼‰
    
    Args:
        report_path (str): æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        bucket_name (str): S3å­˜å‚¨æ¡¶åç§°
        report_category (str): æŠ¥å‘Šåˆ†ç±»ï¼ˆç”¨ä½œS3å‰ç¼€ï¼‰
        public_read (bool): æ˜¯å¦è®¾ç½®ä¸ºå…¬å¼€å¯è¯»
        
    Returns:
        str: JSONæ ¼å¼çš„ä¸Šä¼ ç»“æœ
    """
    try:
        report_file = Path(report_path)
        if not report_file.exists():
            return json.dumps({
                "status": "error",
                "message": f"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_path}"
            }, ensure_ascii=False)
        
        # ç”ŸæˆS3é”®ï¼ˆåŒ…å«æ—¥æœŸåˆ†ç±»ï¼‰
        date_prefix = datetime.now().strftime("%Y/%m/%d")
        s3_key = f"{report_category}/{date_prefix}/{report_file.name}"
        
        # æ·»åŠ å…ƒæ•°æ®
        metadata = {
            "upload_time": datetime.now().isoformat(),
            "report_category": report_category,
            "file_type": report_file.suffix.lstrip('.')
        }
        
        # ä¸Šä¼ æ–‡ä»¶
        upload_result_json = upload_file_to_s3(
            file_path=report_path,
            bucket_name=bucket_name,
            s3_key=s3_key,
            public_read=public_read,
            metadata=metadata
        )
        upload_result = json.loads(upload_result_json)
        
        if upload_result["status"] == "success":
            upload_result["report_category"] = report_category
            upload_result["date_prefix"] = date_prefix
        
        return json.dumps(upload_result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"æŠ¥å‘Šä¸Šä¼ å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def batch_upload_reports_to_s3(
    report_directory: str,
    bucket_name: str,
    report_category: str = "energy_reports",
    file_patterns: Optional[List[str]] = None,
    public_read: bool = True
) -> str:
    """
    æ‰¹é‡ä¸Šä¼ æŠ¥å‘Šç›®å½•åˆ°S3
    
    Args:
        report_directory (str): æŠ¥å‘Šç›®å½•è·¯å¾„
        bucket_name (str): S3å­˜å‚¨æ¡¶åç§°
        report_category (str): æŠ¥å‘Šåˆ†ç±»
        file_patterns (List[str], optional): æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆå¦‚["*.html", "*.json"]ï¼‰
        public_read (bool): æ˜¯å¦è®¾ç½®ä¸ºå…¬å¼€å¯è¯»
        
    Returns:
        str: JSONæ ¼å¼çš„æ‰¹é‡ä¸Šä¼ ç»“æœ
    """
    try:
        # é»˜è®¤ä¸Šä¼ æ‰€æœ‰æŠ¥å‘Šæ ¼å¼
        if not file_patterns:
            file_patterns = ["*.html", "*.md", "*.json", "*.pdf"]
        
        # ä½¿ç”¨ç›®å½•ä¸Šä¼ åŠŸèƒ½
        result_json = upload_directory_to_s3(
            directory_path=report_directory,
            bucket_name=bucket_name,
            s3_prefix=report_category,
            public_read=public_read,
            recursive=True,
            file_patterns=file_patterns
        )
        
        return result_json
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"æ‰¹é‡ä¸Šä¼ æŠ¥å‘Šå¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


if __name__ == "__main__":
    # æµ‹è¯•å·¥å…·
    print("ğŸ§ª æµ‹è¯•S3å­˜å‚¨å·¥å…·...")
    
    # æ³¨æ„ï¼šå®é™…æµ‹è¯•éœ€è¦é…ç½®AWSå‡­è¯å’ŒS3å­˜å‚¨æ¡¶
    print("âš ï¸  S3å·¥å…·éœ€è¦é…ç½®AWSå‡­è¯æ‰èƒ½æµ‹è¯•")
    print("âœ… å·¥å…·å®šä¹‰å®Œæˆï¼")
