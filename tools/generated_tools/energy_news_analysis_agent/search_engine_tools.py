#!/usr/bin/env python3
"""
Search engine tools using SerpAPI for comprehensive web search.
Supports general web search, news search, and academic search.
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from urllib.parse import quote_plus

from strands import tool

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False


@tool
def serpapi_search(
    query: str,
    api_key: str,
    num_results: int = 10,
    time_range: str = "w",  # d=day, w=week, m=month, y=year
    language: str = "zh-cn",
    country: str = "cn"
) -> str:
    """
    ä½¿ç”¨SerpAPIè¿›è¡ŒGoogleæœç´¢
    
    Args:
        query: æœç´¢æŸ¥è¯¢è¯
        api_key: SerpAPI APIå¯†é’¥
        num_results: è¿”å›ç»“æœæ•°é‡ï¼ˆé»˜è®¤10ï¼‰
        time_range: æ—¶é—´èŒƒå›´ï¼ˆd=å¤©, w=å‘¨, m=æœˆ, y=å¹´ï¼‰
        language: æœç´¢è¯­è¨€ï¼ˆé»˜è®¤zh-cnï¼‰
        country: æœç´¢å›½å®¶ï¼ˆé»˜è®¤cnï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„æœç´¢ç»“æœ
    """
    try:
        if not REQUESTS_AVAILABLE:
            return json.dumps({
                "status": "error",
                "message": "requestsåº“æœªå®‰è£…ã€‚è¯·å®‰è£…: pip install requests"
            }, ensure_ascii=False)
        
        url = "https://serpapi.com/search"
        params = {
            "q": query,
            "api_key": api_key,
            "num": num_results,
            "tbs": f"qdr:{time_range}",
            "hl": language,
            "gl": country,
            "engine": "google"
        }
        
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        # æå–æœ‰æœºæœç´¢ç»“æœ
        organic_results = data.get("organic_results", [])
        
        results = []
        for item in organic_results:
            results.append({
                "title": item.get("title", ""),
                "url": item.get("link", ""),
                "snippet": item.get("snippet", ""),
                "displayed_link": item.get("displayed_link", ""),
                "date": item.get("date", ""),
                "source": "SerpAPI Google Search"
            })
        
        return json.dumps({
            "status": "success",
            "query": query,
            "total_results": len(results),
            "results": results,
            "search_time": datetime.now().isoformat(),
            "source": "SerpAPI Google Search"
        }, ensure_ascii=False, indent=2)
        
    except requests.exceptions.Timeout:
        return json.dumps({
            "status": "error",
            "query": query,
            "message": "SerpAPIè¯·æ±‚è¶…æ—¶"
        }, ensure_ascii=False)
    except requests.exceptions.RequestException as e:
        return json.dumps({
            "status": "error",
            "query": query,
            "message": f"SerpAPIè¯·æ±‚å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)
    except Exception as e:
        return json.dumps({
            "status": "error",
            "query": query,
            "message": f"æœç´¢å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def bing_web_search(
    query: str,
    count: int = 10,
    market: str = "zh-CN",
    freshness: Optional[str] = None
) -> str:
    """
    ä½¿ç”¨Bing Search APIè¿›è¡Œç½‘é¡µæœç´¢ï¼ˆå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨serpapi_searchï¼‰
    
    Args:
        query (str): æœç´¢æŸ¥è¯¢è¯
        count (int): è¿”å›ç»“æœæ•°é‡ï¼ˆ1-50ï¼‰
        market (str): å¸‚åœºåœ°åŒºä»£ç ï¼ˆzh-CN, en-USç­‰ï¼‰
        freshness (str, optional): ç»“æœæ—¶æ•ˆæ€§ï¼ˆDay, Week, Monthï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„æœç´¢ç»“æœ
    """
    return json.dumps({
        "status": "error",
        "message": "æ­¤å·¥å…·å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ serpapi_search"
    }, ensure_ascii=False)


@tool
def serpapi_news_search(
    query: str,
    api_key: str,
    num_results: int = 10,
    time_range: str = "w",
    language: str = "zh-cn",
    country: str = "cn"
) -> str:
    """
    ä½¿ç”¨SerpAPIè¿›è¡ŒGoogleæ–°é—»æœç´¢
    
    Args:
        query: æœç´¢æŸ¥è¯¢è¯
        api_key: SerpAPI APIå¯†é’¥
        num_results: è¿”å›ç»“æœæ•°é‡ï¼ˆé»˜è®¤10ï¼‰
        time_range: æ—¶é—´èŒƒå›´ï¼ˆd=å¤©, w=å‘¨, m=æœˆ, y=å¹´ï¼‰
        language: æœç´¢è¯­è¨€ï¼ˆé»˜è®¤zh-cnï¼‰
        country: æœç´¢å›½å®¶ï¼ˆé»˜è®¤cnï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„æ–°é—»æœç´¢ç»“æœ
    """
    try:
        if not REQUESTS_AVAILABLE:
            return json.dumps({
                "status": "error",
                "message": "requestsåº“æœªå®‰è£…ã€‚è¯·å®‰è£…: pip install requests"
            }, ensure_ascii=False)
        
        url = "https://serpapi.com/search"
        params = {
            "q": query,
            "api_key": api_key,
            "num": num_results,
            "tbs": f"qdr:{time_range}",
            "hl": language,
            "gl": country,
            "engine": "google",
            "tbm": "nws"  # æ–°é—»æœç´¢
        }
        
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        # æå–æ–°é—»ç»“æœ
        news_results = data.get("news_results", [])
        
        results = []
        for item in news_results:
            results.append({
                "title": item.get("title", ""),
                "url": item.get("link", ""),
                "snippet": item.get("snippet", ""),
                "date": item.get("date", ""),
                "source": item.get("source", ""),
                "displayed_link": item.get("link", ""),
            })
        
        return json.dumps({
            "status": "success",
            "query": query,
            "total_results": len(results),
            "results": results,
            "search_time": datetime.now().isoformat(),
            "source": "SerpAPI Google News Search"
        }, ensure_ascii=False, indent=2)
        
    except requests.exceptions.Timeout:
        return json.dumps({
            "status": "error",
            "query": query,
            "message": "SerpAPIè¯·æ±‚è¶…æ—¶"
        }, ensure_ascii=False)
    except requests.exceptions.RequestException as e:
        return json.dumps({
            "status": "error",
            "query": query,
            "message": f"SerpAPIè¯·æ±‚å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)
    except Exception as e:
        return json.dumps({
            "status": "error",
            "query": query,
            "message": f"æœç´¢å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def multi_keyword_search(
    keywords: List[str],
    api_key: str,
    search_type: str = "web",
    count_per_keyword: int = 5,
    time_range: str = "w"
) -> str:
    """
    å¤šå…³é”®è¯æ‰¹é‡æœç´¢ï¼ˆä½¿ç”¨SerpAPIï¼‰
    
    Args:
        keywords: å…³é”®è¯åˆ—è¡¨
        api_key: SerpAPI APIå¯†é’¥
        search_type: æœç´¢ç±»å‹ï¼ˆweb, newsï¼‰
        count_per_keyword: æ¯ä¸ªå…³é”®è¯çš„ç»“æœæ•°é‡
        time_range: æ—¶é—´èŒƒå›´ï¼ˆd=å¤©, w=å‘¨, m=æœˆ, y=å¹´ï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„æ‰¹é‡æœç´¢ç»“æœ
    """
    try:
        all_results = {
            "keywords": keywords,
            "search_type": search_type,
            "count_per_keyword": count_per_keyword,
            "search_time": datetime.now().isoformat(),
            "results": []
        }
        
        for keyword in keywords:
            try:
                if search_type == "news":
                    result_json = serpapi_news_search(
                        query=keyword,
                        api_key=api_key,
                        num_results=count_per_keyword,
                        time_range=time_range
                    )
                else:
                    result_json = serpapi_search(
                        query=keyword,
                        api_key=api_key,
                        num_results=count_per_keyword,
                        time_range=time_range
                    )
                
                result = json.loads(result_json)
                all_results["results"].append({
                    "keyword": keyword,
                    "status": result["status"],
                    "data": result
                })
                
            except Exception as e:
                all_results["results"].append({
                    "keyword": keyword,
                    "status": "error",
                    "message": str(e)
                })
        
        return json.dumps(all_results, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"æ‰¹é‡æœç´¢å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def search_energy_news(
    topic: str,
    api_key: str,
    time_range: str = "w",
    max_results: int = 20,
    include_sources: Optional[List[str]] = None
) -> str:
    """
    æœç´¢èƒ½æºè¡Œä¸šæ–°é—»ï¼ˆä½¿ç”¨SerpAPIï¼‰
    
    Args:
        topic: æœç´¢ä¸»é¢˜ï¼ˆå¦‚"æ–°èƒ½æºæ±½è½¦"ã€"å‚¨èƒ½æŠ€æœ¯"ç­‰ï¼‰
        api_key: SerpAPI APIå¯†é’¥
        time_range: æ—¶é—´èŒƒå›´ï¼ˆd=å¤©, w=å‘¨, m=æœˆ, y=å¹´ï¼‰
        max_results: æœ€å¤§ç»“æœæ•°é‡
        include_sources: æŒ‡å®šæ–°é—»æ¥æº
        
    Returns:
        str: JSONæ ¼å¼çš„èƒ½æºæ–°é—»æœç´¢ç»“æœ
    """
    try:
        # æ„å»ºèƒ½æºé¢†åŸŸç›¸å…³çš„æœç´¢æŸ¥è¯¢
        energy_keywords = [
            f"{topic} èƒ½æº",
            f"{topic} æ–°èƒ½æº",
            f"{topic} æ”¿ç­–",
            f"{topic} è¡Œä¸šåŠ¨æ€"
        ]
        
        # å¦‚æœæŒ‡å®šäº†æ–°é—»æ¥æºï¼Œæ·»åŠ åˆ°æŸ¥è¯¢ä¸­
        if include_sources:
            energy_keywords = [f"{kw} site:{source}" for kw in energy_keywords for source in include_sources]
        
        # æ‰¹é‡æœç´¢
        results_json = multi_keyword_search(
            keywords=energy_keywords,
            api_key=api_key,
            search_type="news",
            count_per_keyword=max_results // len(energy_keywords),
            time_range=time_range
        )
        results = json.loads(results_json)
        
        # åˆå¹¶å¹¶å»é‡
        all_articles = []
        seen_urls = set()
        
        for keyword_result in results.get("results", []):
            if keyword_result["status"] == "success":
                for article in keyword_result["data"].get("results", []):
                    url = article.get("url", "")
                    if url and url not in seen_urls:
                        seen_urls.add(url)
                        all_articles.append(article)
        
        # æŒ‰æ—¥æœŸæ’åº
        all_articles.sort(key=lambda x: x.get("date", ""), reverse=True)
        
        # é™åˆ¶ç»“æœæ•°é‡
        all_articles = all_articles[:max_results]
        
        return json.dumps({
            "status": "success",
            "topic": topic,
            "time_range": time_range,
            "total_results": len(all_articles),
            "articles": all_articles,
            "search_time": datetime.now().isoformat(),
            "source": "SerpAPI Google News Search"
        }, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "topic": topic,
            "message": f"èƒ½æºæ–°é—»æœç´¢å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def search_with_filters(
    query: str,
    api_key: str,
    search_type: str = "web",
    time_filter: Optional[str] = None,
    site_filter: Optional[str] = None,
    file_type: Optional[str] = None,
    language: str = "zh-cn",
    count: int = 10
) -> str:
    """
    å¸¦é«˜çº§è¿‡æ»¤å™¨çš„æœç´¢ï¼ˆä½¿ç”¨SerpAPIï¼‰
    
    Args:
        query: æœç´¢æŸ¥è¯¢è¯
        api_key: SerpAPI APIå¯†é’¥
        search_type: æœç´¢ç±»å‹ï¼ˆweb, newsï¼‰
        time_filter: æ—¶é—´è¿‡æ»¤å™¨ï¼ˆd=å¤©, w=å‘¨, m=æœˆ, y=å¹´ï¼‰
        site_filter: ç½‘ç«™è¿‡æ»¤å™¨ï¼ˆå¦‚"gov.cn"ï¼‰
        file_type: æ–‡ä»¶ç±»å‹è¿‡æ»¤å™¨ï¼ˆå¦‚"pdf"ï¼‰
        language: è¯­è¨€ä»£ç ï¼ˆé»˜è®¤zh-cnï¼‰
        count: ç»“æœæ•°é‡
        
    Returns:
        str: JSONæ ¼å¼çš„æœç´¢ç»“æœ
    """
    try:
        # æ„å»ºé«˜çº§æŸ¥è¯¢
        advanced_query = query
        
        if site_filter:
            advanced_query += f" site:{site_filter}"
        
        if file_type:
            advanced_query += f" filetype:{file_type}"
        
        # è½¬æ¢æ—¶é—´è¿‡æ»¤å™¨æ ¼å¼
        time_range_map = {
            "Day": "d",
            "Week": "w",
            "Month": "m",
            "Year": "y"
        }
        time_range = time_range_map.get(time_filter, "w") if time_filter else "w"
        
        # æ‰§è¡Œæœç´¢
        if search_type == "news":
            result_json = serpapi_news_search(
                query=advanced_query,
                api_key=api_key,
                num_results=count,
                time_range=time_range,
                language=language
            )
        else:
            result_json = serpapi_search(
                query=advanced_query,
                api_key=api_key,
                num_results=count,
                time_range=time_range,
                language=language
            )
        
        result = json.loads(result_json)
        
        # æ·»åŠ è¿‡æ»¤å™¨ä¿¡æ¯
        if result["status"] == "success":
            result["filters"] = {
                "time_filter": time_filter,
                "site_filter": site_filter,
                "file_type": file_type,
                "language": language
            }
        
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "query": query,
            "message": f"é«˜çº§æœç´¢å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def search_government_sources(
    topic: str,
    api_key: str,
    government_domains: Optional[List[str]] = None,
    time_range: str = "m",
    max_results: int = 10
) -> str:
    """
    æœç´¢æ”¿åºœå®˜æ–¹æ¥æºï¼ˆä½¿ç”¨SerpAPIï¼‰
    
    Args:
        topic: æœç´¢ä¸»é¢˜
        api_key: SerpAPI APIå¯†é’¥
        government_domains: æ”¿åºœåŸŸååˆ—è¡¨
        time_range: æ—¶é—´èŒƒå›´ï¼ˆd=å¤©, w=å‘¨, m=æœˆ, y=å¹´ï¼‰
        max_results: æœ€å¤§ç»“æœæ•°é‡
        
    Returns:
        str: JSONæ ¼å¼çš„æ”¿åºœæ¥æºæœç´¢ç»“æœ
    """
    try:
        # é»˜è®¤æ”¿åºœåŸŸå
        if not government_domains:
            government_domains = [
                "gov.cn",
                "nea.gov.cn",  # å›½å®¶èƒ½æºå±€
                "ndrc.gov.cn",  # å›½å®¶å‘æ”¹å§”
                "mee.gov.cn",  # ç”Ÿæ€ç¯å¢ƒéƒ¨
                "miit.gov.cn"  # å·¥ä¿¡éƒ¨
            ]
        
        all_results = []
        
        for domain in government_domains:
            try:
                result_json = search_with_filters(
                    query=topic,
                    api_key=api_key,
                    search_type="web",
                    time_filter=time_range,
                    site_filter=domain,
                    language="zh-cn",
                    count=max_results // len(government_domains)
                )
                result = json.loads(result_json)
                
                if result["status"] == "success":
                    for item in result.get("results", []):
                        item["government_source"] = domain
                        all_results.append(item)
                        
            except Exception as e:
                continue
        
        # æŒ‰æ—¥æœŸæ’åº
        all_results.sort(key=lambda x: x.get("date", ""), reverse=True)
        
        return json.dumps({
            "status": "success",
            "topic": topic,
            "government_domains": government_domains,
            "total_results": len(all_results),
            "results": all_results,
            "search_time": datetime.now().isoformat(),
            "source": "SerpAPI Google Search"
        }, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "topic": topic,
            "message": f"æ”¿åºœæ¥æºæœç´¢å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def search_academic_papers(
    topic: str,
    api_key: str,
    academic_sites: Optional[List[str]] = None,
    max_results: int = 10
) -> str:
    """
    æœç´¢å­¦æœ¯è®ºæ–‡å’Œç ”ç©¶æŠ¥å‘Šï¼ˆä½¿ç”¨SerpAPIï¼‰
    
    Args:
        topic: æœç´¢ä¸»é¢˜
        api_key: SerpAPI APIå¯†é’¥
        academic_sites: å­¦æœ¯ç½‘ç«™åˆ—è¡¨
        max_results: æœ€å¤§ç»“æœæ•°é‡
        
    Returns:
        str: JSONæ ¼å¼çš„å­¦æœ¯æœç´¢ç»“æœ
    """
    try:
        # é»˜è®¤å­¦æœ¯ç½‘ç«™
        if not academic_sites:
            academic_sites = [
                "scholar.google.com",
                "arxiv.org",
                "researchgate.net",
                "ieee.org",
                "cnki.net"
            ]
        
        # æ„å»ºå­¦æœ¯æŸ¥è¯¢
        academic_query = f"{topic} (è®ºæ–‡ OR paper OR research OR ç ”ç©¶)"
        
        all_results = []
        
        for site in academic_sites:
            try:
                result_json = search_with_filters(
                    query=academic_query,
                    api_key=api_key,
                    search_type="web",
                    site_filter=site,
                    language="zh-cn",
                    count=max_results // len(academic_sites)
                )
                result = json.loads(result_json)
                
                if result["status"] == "success":
                    for item in result.get("results", []):
                        item["academic_source"] = site
                        all_results.append(item)
                        
            except Exception as e:
                continue
        
        return json.dumps({
            "status": "success",
            "topic": topic,
            "academic_sites": academic_sites,
            "total_results": len(all_results),
            "results": all_results,
            "search_time": datetime.now().isoformat(),
            "source": "SerpAPI Google Search"
        }, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "topic": topic,
            "message": f"å­¦æœ¯æœç´¢å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


@tool
def comprehensive_energy_search(
    topic: str,
    api_key: str,
    include_news: bool = True,
    include_government: bool = True,
    include_academic: bool = True,
    time_range: str = "m",
    max_results_per_type: int = 10
) -> str:
    """
    ç»¼åˆèƒ½æºä¿¡æ¯æœç´¢ï¼ˆæ–°é—»+æ”¿åºœ+å­¦æœ¯ï¼Œä½¿ç”¨SerpAPIï¼‰
    
    Args:
        topic: æœç´¢ä¸»é¢˜
        api_key: SerpAPI APIå¯†é’¥
        include_news: æ˜¯å¦åŒ…å«æ–°é—»
        include_government: æ˜¯å¦åŒ…å«æ”¿åºœæ¥æº
        include_academic: æ˜¯å¦åŒ…å«å­¦æœ¯æ¥æº
        time_range: æ—¶é—´èŒƒå›´ï¼ˆd=å¤©, w=å‘¨, m=æœˆ, y=å¹´ï¼‰
        max_results_per_type: æ¯ç§ç±»å‹çš„æœ€å¤§ç»“æœæ•°
        
    Returns:
        str: JSONæ ¼å¼çš„ç»¼åˆæœç´¢ç»“æœ
    """
    try:
        comprehensive_results = {
            "topic": topic,
            "time_range": time_range,
            "search_time": datetime.now().isoformat(),
            "results": {
                "news": [],
                "government": [],
                "academic": []
            },
            "summary": {
                "total_news": 0,
                "total_government": 0,
                "total_academic": 0,
                "total_all": 0
            }
        }
        
        # æœç´¢æ–°é—»
        if include_news:
            news_json = search_energy_news(
                topic=topic,
                api_key=api_key,
                time_range=time_range,
                max_results=max_results_per_type
            )
            news_result = json.loads(news_json)
            if news_result["status"] == "success":
                comprehensive_results["results"]["news"] = news_result.get("articles", [])
                comprehensive_results["summary"]["total_news"] = len(news_result.get("articles", []))
        
        # æœç´¢æ”¿åºœæ¥æº
        if include_government:
            gov_json = search_government_sources(
                topic=topic,
                api_key=api_key,
                time_range=time_range,
                max_results=max_results_per_type
            )
            gov_result = json.loads(gov_json)
            if gov_result["status"] == "success":
                comprehensive_results["results"]["government"] = gov_result.get("results", [])
                comprehensive_results["summary"]["total_government"] = len(gov_result.get("results", []))
        
        # æœç´¢å­¦æœ¯æ¥æº
        if include_academic:
            academic_json = search_academic_papers(
                topic=topic,
                api_key=api_key,
                max_results=max_results_per_type
            )
            academic_result = json.loads(academic_json)
            if academic_result["status"] == "success":
                comprehensive_results["results"]["academic"] = academic_result.get("results", [])
                comprehensive_results["summary"]["total_academic"] = len(academic_result.get("results", []))
        
        # è®¡ç®—æ€»æ•°
        comprehensive_results["summary"]["total_all"] = (
            comprehensive_results["summary"]["total_news"] +
            comprehensive_results["summary"]["total_government"] +
            comprehensive_results["summary"]["total_academic"]
        )
        
        return json.dumps(comprehensive_results, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "status": "error",
            "topic": topic,
            "message": f"ç»¼åˆæœç´¢å¤±è´¥: {str(e)}"
        }, ensure_ascii=False)


if __name__ == "__main__":
    # æµ‹è¯•å·¥å…·
    print("ğŸ§ª æµ‹è¯•æœç´¢å¼•æ“å·¥å…·...")
    
    # éœ€è¦æä¾› SerpAPI API Key è¿›è¡Œæµ‹è¯•
    api_key = os.getenv("SERPAPI_API_KEY", "")
    if api_key:
        # æµ‹è¯•ç½‘é¡µæœç´¢
        web_result = serpapi_search("æ–°èƒ½æºæ±½è½¦", api_key=api_key, num_results=5)
        print("ğŸ” ç½‘é¡µæœç´¢:", json.loads(web_result)["status"])
        
        # æµ‹è¯•æ–°é—»æœç´¢
        news_result = serpapi_news_search("å‚¨èƒ½æŠ€æœ¯", api_key=api_key, num_results=5)
        print("ğŸ“° æ–°é—»æœç´¢:", json.loads(news_result)["status"])
        
        # æµ‹è¯•èƒ½æºæ–°é—»æœç´¢
        energy_result = search_energy_news("æ°¢èƒ½", api_key=api_key, time_range="w", max_results=10)
        print("âš¡ èƒ½æºæ–°é—»æœç´¢:", json.loads(energy_result)["status"])
    else:
        print("âš ï¸ æœªè®¾ç½® SERPAPI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡æµ‹è¯•")
    
    print("âœ… å·¥å…·æµ‹è¯•å®Œæˆï¼")
