"""
çŒ«å’ªå“ç§è¯†åˆ«å·¥å…·é›†

æœ¬æ¨¡å—ä¸ºcat_breed_identifier Agentæä¾›æ ¸å¿ƒå·¥å…·æ”¯æŒã€‚
ç”±äºAgentè®¾è®¡é‡‡ç”¨"æç¤ºè¯å·¥ç¨‹ä¸ºæ ¸å¿ƒ"çš„ç­–ç•¥ï¼Œå……åˆ†åˆ©ç”¨LLMå†…ç½®çŸ¥è¯†ï¼Œ
å› æ­¤æœ¬æ¨¡å—ä¸»è¦æä¾›è¾…åŠ©åŠŸèƒ½ï¼Œè€Œéæ ¸å¿ƒè¯†åˆ«é€»è¾‘ã€‚

æ ¸å¿ƒåŠŸèƒ½ç”±LLMé€šè¿‡æç¤ºè¯å¼•å¯¼å®Œæˆï¼š
- ç‰¹å¾æå–
- å“ç§åŒ¹é…
- ç½®ä¿¡åº¦è¯„ä¼°
- ä¹ æ€§ä¿¡æ¯ç”Ÿæˆ

å·¥å…·æä¾›çš„è¾…åŠ©åŠŸèƒ½ï¼š
- è¾“å…¥éªŒè¯å’Œæ¸…ç†
- ç‰¹å¾ç»“æ„åŒ–
- å“åº”æ ¼å¼åŒ–
- ä¼šè¯çŠ¶æ€ç®¡ç†ï¼ˆå¦‚éœ€è¦ï¼‰

è®¾è®¡åŸåˆ™ï¼š
1. æœ€å°åŒ–å·¥å…·å¤æ‚åº¦ï¼Œé¿å…é‡å¤LLMèƒ½åŠ›
2. å·¥å…·åªåšæ•°æ®å¤„ç†å’ŒéªŒè¯ï¼Œä¸åšä¸šåŠ¡åˆ¤æ–­
3. ä¿æŒå·¥å…·çš„é€šç”¨æ€§å’Œå¯å¤ç”¨æ€§
4. éµå¾ªStrandsæ¡†æ¶è§„èŒƒ

æŠ€æœ¯æ ˆï¼š
- Python 3.13+
- Strandsæ¡†æ¶ï¼ˆ@toolè£…é¥°å™¨ï¼‰
- æ ‡å‡†åº“ï¼ˆre, jsonç­‰ï¼‰
"""

from strands import tool
from typing import Dict, Any, List, Optional
import re
import json


@tool
def validate_user_input(
    user_input: str,
    max_length: int = 500,
    min_length: int = 5
) -> str:
    """
    éªŒè¯å’Œæ¸…ç†ç”¨æˆ·è¾“å…¥
    
    åŠŸèƒ½ï¼š
    - æ£€æŸ¥è¾“å…¥é•¿åº¦æ˜¯å¦åœ¨åˆç†èŒƒå›´
    - ç§»é™¤å¤šä½™ç©ºç™½å­—ç¬¦
    - æ£€æµ‹å¹¶æ ‡è®°æ½œåœ¨çš„æ¶æ„è¾“å…¥
    - æä¾›æ¸…ç†åçš„æ–‡æœ¬å’ŒéªŒè¯çŠ¶æ€
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥çš„åŸå§‹æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦é™åˆ¶ï¼ˆé»˜è®¤500å­—ç¬¦ï¼‰
        min_length: æœ€å°é•¿åº¦é™åˆ¶ï¼ˆé»˜è®¤5å­—ç¬¦ï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„éªŒè¯ç»“æœ
        {
            "is_valid": bool,
            "cleaned_input": str,
            "validation_errors": List[str],
            "warnings": List[str],
            "metadata": {
                "original_length": int,
                "cleaned_length": int,
                "removed_chars": int
            }
        }
    """
    try:
        result = {
            "is_valid": True,
            "cleaned_input": "",
            "validation_errors": [],
            "warnings": [],
            "metadata": {
                "original_length": 0,
                "cleaned_length": 0,
                "removed_chars": 0
            }
        }
        
        # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºç©º
        if not user_input or not isinstance(user_input, str):
            result["is_valid"] = False
            result["validation_errors"].append("è¾“å…¥ä¸ºç©ºæˆ–ç±»å‹æ— æ•ˆ")
            return json.dumps(result, ensure_ascii=False, indent=2)
        
        original_length = len(user_input)
        result["metadata"]["original_length"] = original_length
        
        # é•¿åº¦éªŒè¯
        if original_length < min_length:
            result["is_valid"] = False
            result["validation_errors"].append(f"è¾“å…¥è¿‡çŸ­ï¼ˆå°‘äº{min_length}ä¸ªå­—ç¬¦ï¼‰ï¼Œè¯·æä¾›æ›´è¯¦ç»†çš„æè¿°")
        
        if original_length > max_length:
            result["is_valid"] = False
            result["validation_errors"].append(f"è¾“å…¥è¿‡é•¿ï¼ˆè¶…è¿‡{max_length}ä¸ªå­—ç¬¦ï¼‰ï¼Œè¯·ç²¾ç®€æè¿°")
        
        # æ¸…ç†è¾“å…¥
        cleaned = user_input.strip()
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦ï¼ˆè¿ç»­å¤šä¸ªç©ºæ ¼/æ¢è¡Œæ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼ï¼‰
        cleaned = re.sub(r'\s+', ' ', cleaned)
        # ç§»é™¤æ§åˆ¶å­—ç¬¦
        cleaned = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f]', '', cleaned)
        
        result["cleaned_input"] = cleaned
        result["metadata"]["cleaned_length"] = len(cleaned)
        result["metadata"]["removed_chars"] = original_length - len(cleaned)
        
        # æ£€æµ‹å¯èƒ½çš„é—®é¢˜æ¨¡å¼
        # æ£€æµ‹æ˜¯å¦åŒ…å«è¿‡å¤šé‡å¤å­—ç¬¦ï¼ˆå¯èƒ½æ˜¯åƒåœ¾è¾“å…¥ï¼‰
        if re.search(r'(.)\1{10,}', cleaned):
            result["warnings"].append("æ£€æµ‹åˆ°å¤§é‡é‡å¤å­—ç¬¦ï¼Œå¯èƒ½å½±å“è¯†åˆ«å‡†ç¡®æ€§")
        
        # æ£€æµ‹æ˜¯å¦åªåŒ…å«ç‰¹æ®Šå­—ç¬¦å’Œæ•°å­—ï¼ˆç¼ºå°‘æœ‰æ„ä¹‰çš„æ–‡æœ¬ï¼‰
        if re.match(r'^[^a-zA-Z\u4e00-\u9fff]+$', cleaned):
            result["warnings"].append("è¾“å…¥ç¼ºå°‘æœ‰æ„ä¹‰çš„æ–‡å­—æè¿°")
        
        # æ£€æµ‹æ˜¯å¦åŒ…å«URLï¼ˆå¯èƒ½æ˜¯æ¶æ„è¾“å…¥ï¼‰
        if re.search(r'https?://', cleaned, re.IGNORECASE):
            result["warnings"].append("æ£€æµ‹åˆ°URLé“¾æ¥ï¼Œå·²ä¿ç•™ä½†è¯·æ³¨æ„è¿™ä¸ä¼šå½±å“è¯†åˆ«")
        
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        error_result = {
            "is_valid": False,
            "cleaned_input": "",
            "validation_errors": [f"è¾“å…¥éªŒè¯å¤±è´¥: {str(e)}"],
            "warnings": [],
            "metadata": {
                "original_length": 0,
                "cleaned_length": 0,
                "removed_chars": 0
            }
        }
        return json.dumps(error_result, ensure_ascii=False, indent=2)


@tool
def extract_feature_keywords(
    text: str,
    feature_categories: Optional[List[str]] = None
) -> str:
    """
    ä»æ–‡æœ¬ä¸­æå–ç‰¹å¾å…³é”®è¯
    
    åŠŸèƒ½ï¼š
    - è¯†åˆ«æ¯›è‰²ã€ä½“å‹ã€è„¸å‹ã€è€³æœµã€çœ¼ç›ã€å°¾å·´ç­‰ç‰¹å¾å…³é”®è¯
    - å¯¹å…³é”®è¯è¿›è¡Œåˆ†ç±»å’Œç»“æ„åŒ–
    - è¯†åˆ«ç‰¹å¾çš„ä¿®é¥°è¯ï¼ˆå¦‚"å¾ˆé•¿"ã€"ç‰¹åˆ«åœ†"ï¼‰
    - æ ‡è®°å¯èƒ½çš„çŸ›ç›¾ç‰¹å¾
    
    æ³¨æ„ï¼šè¿™ä¸ªå·¥å…·åªåšå…³é”®è¯æå–ï¼Œä¸åšå“ç§æ¨ç†ã€‚
    å“ç§æ¨ç†ç”±LLMé€šè¿‡æç¤ºè¯å®Œæˆã€‚
    
    Args:
        text: åŒ…å«ç‰¹å¾æè¿°çš„æ–‡æœ¬
        feature_categories: è¦æå–çš„ç‰¹å¾ç±»åˆ«åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
                          é»˜è®¤: ["coat_color", "coat_length", "body_type", 
                                "face_shape", "ear_type", "eye_color", "tail_type"]
        
    Returns:
        str: JSONæ ¼å¼çš„æå–ç»“æœ
        {
            "extracted_features": {
                "coat_color": List[str],
                "coat_length": List[str],
                "body_type": List[str],
                "face_shape": List[str],
                "ear_type": List[str],
                "eye_color": List[str],
                "tail_type": List[str],
                "other": List[str]
            },
            "feature_modifiers": Dict[str, List[str]],
            "potential_conflicts": List[str],
            "completeness_score": float,
            "missing_categories": List[str]
        }
    """
    try:
        if feature_categories is None:
            feature_categories = [
                "coat_color", "coat_length", "body_type", 
                "face_shape", "ear_type", "eye_color", "tail_type"
            ]
        
        # ç‰¹å¾å…³é”®è¯åº“
        feature_patterns = {
            "coat_color": [
                "ç™½è‰²", "é»‘è‰²", "ç°è‰²", "æ©™è‰²", "æ£•è‰²", "å¥¶æ²¹è‰²", "è“è‰²", "é“¶è‰²",
                "ä¸‰èŠ±", "ç³ç‘", "è™æ–‘", "é‡ç‚¹è‰²", "åŒè‰²", "çº¯è‰²", "æ¸å±‚",
                "ç™½", "é»‘", "ç°", "æ©™", "æ£•", "è“", "é“¶", "é‡‘è‰²", "é»„è‰²"
            ],
            "coat_length": [
                "é•¿æ¯›", "çŸ­æ¯›", "ä¸­é•¿æ¯›", "æ— æ¯›", "å·æ¯›",
                "æ¯›å¾ˆé•¿", "æ¯›å¾ˆçŸ­", "æ¯›èŒ¸èŒ¸", "å…‰æ»‘"
            ],
            "body_type": [
                "å¤§å‹", "ä¸­å‹", "å°å‹", "å£®å®", "çº¤ç»†", "è‹—æ¡", "è‚Œè‚‰å‘è¾¾",
                "åœ†æ»šæ»š", "èƒ–", "ç˜¦", "ç²—å£®", "ä¼˜é›…", "ç´§å‡‘"
            ],
            "face_shape": [
                "åœ†è„¸", "æ‰è„¸", "å°–è„¸", "ä¸‰è§’å½¢è„¸", "æ¥”å½¢è„¸",
                "è„¸å¾ˆåœ†", "è„¸å¾ˆæ‰", "é¼»å­æ‰", "é¼»å­é•¿", "é¼»å­çŸ­"
            ],
            "ear_type": [
                "ç«‹è€³", "æŠ˜è€³", "å¤§è€³æœµ", "å°è€³æœµ", "è€³æœµå°–", "è€³æœµåœ†",
                "è€³æœµå‘å‰æŠ˜", "è€³æœµå‘ä¸‹æŠ˜", "è€³æœµå¾ˆå¤§", "è€³æœµå¾ˆå°"
            ],
            "eye_color": [
                "è“çœ¼", "ç»¿çœ¼", "é»„çœ¼", "é‡‘çœ¼", "ç¥ç€è‰²çœ¼", "é¸³é¸¯çœ¼", "å¼‚è‰²ç³",
                "çœ¼ç›è“è‰²", "çœ¼ç›ç»¿è‰²", "çœ¼ç›é»„è‰²", "çœ¼ç›æ˜¯è“è‰²çš„"
            ],
            "tail_type": [
                "é•¿å°¾", "çŸ­å°¾", "æ— å°¾", "å°¾å·´è“¬æ¾", "å°¾å·´ç»†é•¿",
                "å°¾å·´å¾ˆé•¿", "å°¾å·´å¾ˆçŸ­", "å°¾å·´ç²—", "å°¾å·´ç»†"
            ]
        }
        
        # ä¿®é¥°è¯æ¨¡å¼
        modifier_patterns = [
            "å¾ˆ", "éå¸¸", "ç‰¹åˆ«", "æå…¶", "è¶…çº§", "æ¯”è¾ƒ", "ç¨å¾®", "æœ‰ç‚¹",
            "æ˜æ˜¾", "æ˜¾è‘—", "ç•¥å¾®", "ç›¸å½“"
        ]
        
        result = {
            "extracted_features": {cat: [] for cat in feature_categories},
            "feature_modifiers": {},
            "potential_conflicts": [],
            "completeness_score": 0.0,
            "missing_categories": []
        }
        
        # æ·»åŠ "other"ç±»åˆ«ç”¨äºæœªåˆ†ç±»çš„å…³é”®è¯
        if "other" not in result["extracted_features"]:
            result["extracted_features"]["other"] = []
        
        text_lower = text.lower()
        
        # æå–ç‰¹å¾å…³é”®è¯
        for category, keywords in feature_patterns.items():
            if category not in feature_categories:
                continue
                
            for keyword in keywords:
                if keyword in text_lower:
                    # æŸ¥æ‰¾ä¿®é¥°è¯
                    modifiers = []
                    for modifier in modifier_patterns:
                        pattern = f"{modifier}[^ï¼Œã€‚ï¼ï¼Ÿ]*{keyword}"
                        if re.search(pattern, text_lower):
                            modifiers.append(modifier)
                    
                    result["extracted_features"][category].append(keyword)
                    if modifiers:
                        result["feature_modifiers"][keyword] = modifiers
        
        # æ£€æµ‹æ½œåœ¨å†²çª
        conflicts = []
        
        # æ¯›é•¿å†²çª
        coat_length = result["extracted_features"].get("coat_length", [])
        if "é•¿æ¯›" in coat_length and "çŸ­æ¯›" in coat_length:
            conflicts.append("æ¯›é•¿æè¿°å†²çªï¼šåŒæ—¶æåˆ°'é•¿æ¯›'å’Œ'çŸ­æ¯›'")
        
        # ä½“å‹å†²çª
        body_type = result["extracted_features"].get("body_type", [])
        if ("å¤§å‹" in body_type or "å£®å®" in body_type) and ("å°å‹" in body_type or "çº¤ç»†" in body_type):
            conflicts.append("ä½“å‹æè¿°å†²çªï¼šåŒæ—¶æåˆ°å¤§å‹å’Œå°å‹ç‰¹å¾")
        
        # è€³æœµå†²çª
        ear_type = result["extracted_features"].get("ear_type", [])
        if "ç«‹è€³" in ear_type and "æŠ˜è€³" in ear_type:
            conflicts.append("è€³æœµæè¿°å†²çªï¼šåŒæ—¶æåˆ°'ç«‹è€³'å’Œ'æŠ˜è€³'")
        
        result["potential_conflicts"] = conflicts
        
        # è®¡ç®—å®Œæ•´æ€§è¯„åˆ†
        extracted_count = sum(1 for cat in feature_categories 
                            if result["extracted_features"].get(cat, []))
        result["completeness_score"] = extracted_count / len(feature_categories)
        
        # è¯†åˆ«ç¼ºå¤±çš„ç±»åˆ«
        result["missing_categories"] = [
            cat for cat in feature_categories 
            if not result["extracted_features"].get(cat, [])
        ]
        
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        error_result = {
            "extracted_features": {},
            "feature_modifiers": {},
            "potential_conflicts": [],
            "completeness_score": 0.0,
            "missing_categories": feature_categories or [],
            "error": f"ç‰¹å¾æå–å¤±è´¥: {str(e)}"
        }
        return json.dumps(error_result, ensure_ascii=False, indent=2)


@tool
def format_breed_response(
    breed_name: str,
    confidence: str,
    characteristics: Dict[str, Any],
    alternative_breeds: Optional[List[str]] = None,
    follow_up_questions: Optional[List[str]] = None
) -> str:
    """
    æ ¼å¼åŒ–å“ç§è¯†åˆ«å“åº”
    
    åŠŸèƒ½ï¼š
    - å°†è¯†åˆ«ç»“æœæ ¼å¼åŒ–ä¸ºç»“æ„åŒ–ã€æ˜“è¯»çš„è¾“å‡º
    - æ·»åŠ é€‚å½“çš„emojiå’Œæ ¼å¼åŒ–æ ‡è®°
    - ç»„ç»‡ä¹ æ€§ä¿¡æ¯çš„å±‚æ¬¡ç»“æ„
    - ç”Ÿæˆå‹å¥½çš„æ–‡æœ¬æè¿°
    
    Args:
        breed_name: è¯†åˆ«å‡ºçš„å“ç§åç§°
        confidence: ç½®ä¿¡åº¦ç­‰çº§ ("é«˜" / "ä¸­" / "ä½")
        characteristics: å“ç§ç‰¹æ€§å­—å…¸ï¼ŒåŒ…å«ï¼š
            - personality: æ€§æ ¼ç‰¹ç‚¹
            - care_level: é¥²å…»éš¾åº¦
            - health_notes: å¥åº·æ³¨æ„äº‹é¡¹
            - living_environment: ç¯å¢ƒè¦æ±‚
            - diet: é¥®é£Ÿç‰¹ç‚¹
            - sociability: ç¤¾äº¤èƒ½åŠ›
        alternative_breeds: å…¶ä»–å¯èƒ½çš„å“ç§åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        follow_up_questions: è¿½é—®é—®é¢˜åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        str: æ ¼å¼åŒ–çš„å“åº”æ–‡æœ¬
    """
    try:
        # ç½®ä¿¡åº¦emojiæ˜ å°„
        confidence_emoji = {
            "é«˜": "âœ…",
            "ä¸­": "ğŸ¤”",
            "ä½": "â“"
        }
        
        # æ„å»ºå“åº”
        lines = []
        
        # æ ‡é¢˜å’Œç½®ä¿¡åº¦
        emoji = confidence_emoji.get(confidence, "ğŸ”")
        lines.append(f"{emoji} **å“ç§è¯†åˆ«ç»“æœ**")
        lines.append("")
        lines.append(f"**å“ç§åç§°**: {breed_name}")
        lines.append(f"**è¯†åˆ«ç½®ä¿¡åº¦**: {confidence}")
        lines.append("")
        
        # ç½®ä¿¡åº¦è¯´æ˜
        if confidence == "é«˜":
            lines.append("æ ¹æ®æ‚¨çš„æè¿°ï¼Œè¿™åªçŒ«å’ªçš„ç‰¹å¾éå¸¸ç¬¦åˆè¯¥å“ç§çš„å…¸å‹ç‰¹å¾ã€‚")
        elif confidence == "ä¸­":
            lines.append("æ ¹æ®æ‚¨çš„æè¿°ï¼Œè¿™åªçŒ«å’ªçš„éƒ¨åˆ†ç‰¹å¾ç¬¦åˆè¯¥å“ç§ï¼Œä½†å¯èƒ½éœ€è¦æ›´å¤šä¿¡æ¯æ¥ç¡®è®¤ã€‚")
        else:
            lines.append("æ ¹æ®æ‚¨çš„æè¿°ï¼Œè¿™åªçŒ«å’ªå¯èƒ½æ˜¯è¯¥å“ç§ï¼Œä½†ç‰¹å¾æè¿°è¾ƒå°‘ï¼Œå»ºè®®æä¾›æ›´å¤šä¿¡æ¯ã€‚")
        lines.append("")
        
        # ä¹ æ€§ä¿¡æ¯
        lines.append("---")
        lines.append("## ğŸ± å“ç§ç‰¹æ€§")
        lines.append("")
        
        if "personality" in characteristics:
            lines.append(f"**æ€§æ ¼ç‰¹ç‚¹**: {characteristics['personality']}")
            lines.append("")
        
        if "care_level" in characteristics:
            lines.append(f"**é¥²å…»éš¾åº¦**: {characteristics['care_level']}")
            lines.append("")
        
        if "health_notes" in characteristics:
            lines.append(f"**å¥åº·æ³¨æ„**: {characteristics['health_notes']}")
            lines.append("")
        
        if "living_environment" in characteristics:
            lines.append(f"**ç¯å¢ƒè¦æ±‚**: {characteristics['living_environment']}")
            lines.append("")
        
        if "diet" in characteristics:
            lines.append(f"**é¥®é£Ÿç‰¹ç‚¹**: {characteristics['diet']}")
            lines.append("")
        
        if "sociability" in characteristics:
            lines.append(f"**ç¤¾äº¤èƒ½åŠ›**: {characteristics['sociability']}")
            lines.append("")
        
        # å…¶ä»–å¯èƒ½çš„å“ç§
        if alternative_breeds:
            lines.append("---")
            lines.append("## ğŸ”„ å…¶ä»–å¯èƒ½çš„å“ç§")
            lines.append("")
            lines.append("æ ¹æ®æè¿°ï¼Œä»¥ä¸‹å“ç§ä¹Ÿæœ‰ç›¸ä¼¼ç‰¹å¾ï¼š")
            for alt_breed in alternative_breeds:
                lines.append(f"- {alt_breed}")
            lines.append("")
        
        # è¿½é—®é—®é¢˜
        if follow_up_questions:
            lines.append("---")
            lines.append("## â“ éœ€è¦æ›´å¤šä¿¡æ¯")
            lines.append("")
            lines.append("ä¸ºäº†æé«˜è¯†åˆ«å‡†ç¡®åº¦ï¼Œèƒ½å¦è¡¥å……ä»¥ä¸‹ä¿¡æ¯ï¼Ÿ")
            for i, question in enumerate(follow_up_questions, 1):
                lines.append(f"{i}. {question}")
            lines.append("")
        
        # å…è´£å£°æ˜
        lines.append("---")
        lines.append("**æ³¨æ„**: ä»¥ä¸Šä¿¡æ¯æ˜¯è¯¥å“ç§çš„ä¸€èˆ¬ç‰¹æ€§ï¼Œä¸ªä½“çŒ«å’ªå¯èƒ½ä¼šæœ‰å·®å¼‚ã€‚å¦‚éœ€ä¸“ä¸šå»ºè®®ï¼Œè¯·å’¨è¯¢å…½åŒ»æˆ–ä¸“ä¸šé¥²å…»å‘˜ã€‚")
        
        return "\n".join(lines)
        
    except Exception as e:
        return f"Error: æ ¼å¼åŒ–å“åº”å¤±è´¥: {str(e)}"


@tool
def generate_follow_up_questions(
    missing_features: List[str],
    current_confidence: str,
    candidate_breeds: Optional[List[str]] = None
) -> str:
    """
    ç”Ÿæˆè¿½é—®é—®é¢˜
    
    åŠŸèƒ½ï¼š
    - æ ¹æ®ç¼ºå¤±çš„ç‰¹å¾ç”Ÿæˆé’ˆå¯¹æ€§çš„è¿½é—®é—®é¢˜
    - æ ¹æ®å€™é€‰å“ç§ç”ŸæˆåŒºåˆ†æ€§é—®é¢˜
    - ä¼˜å…ˆè¯¢é—®å…³é”®ç‰¹å¾
    - æä¾›é€‰é¡¹å¼é—®é¢˜é™ä½å›ç­”éš¾åº¦
    
    Args:
        missing_features: ç¼ºå¤±çš„ç‰¹å¾ç±»åˆ«åˆ—è¡¨
        current_confidence: å½“å‰è¯†åˆ«çš„ç½®ä¿¡åº¦ ("é«˜" / "ä¸­" / "ä½")
        candidate_breeds: å€™é€‰å“ç§åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºç”ŸæˆåŒºåˆ†æ€§é—®é¢˜ï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„è¿½é—®é—®é¢˜åˆ—è¡¨
        {
            "should_ask": bool,
            "questions": List[Dict[str, Any]],
            "rationale": str
        }
    """
    try:
        result = {
            "should_ask": False,
            "questions": [],
            "rationale": ""
        }
        
        # å†³å®šæ˜¯å¦éœ€è¦è¿½é—®
        # é«˜ç½®ä¿¡åº¦ä¸”ç¼ºå¤±ç‰¹å¾å°‘äº3ä¸ªï¼šä¸è¿½é—®
        if current_confidence == "é«˜" and len(missing_features) < 3:
            result["rationale"] = "è¯†åˆ«ç½®ä¿¡åº¦é«˜ä¸”ç‰¹å¾ä¿¡æ¯è¾ƒå®Œæ•´ï¼Œæ— éœ€è¿½é—®"
            return json.dumps(result, ensure_ascii=False, indent=2)
        
        # ä½ç½®ä¿¡åº¦æˆ–ç¼ºå¤±å…³é”®ç‰¹å¾ï¼šéœ€è¦è¿½é—®
        if current_confidence in ["ä½", "ä¸­"] or len(missing_features) >= 3:
            result["should_ask"] = True
        
        # ç‰¹å¾ç±»åˆ«åˆ°é—®é¢˜çš„æ˜ å°„
        feature_questions = {
            "coat_color": {
                "question": "è¿™åªçŒ«å’ªçš„æ¯›è‰²æ˜¯ä»€ä¹ˆï¼Ÿ",
                "options": ["çº¯è‰²ï¼ˆå•ä¸€é¢œè‰²ï¼‰", "åŒè‰²", "ä¸‰èŠ±", "è™æ–‘", "é‡ç‚¹è‰²", "å…¶ä»–"],
                "priority": 1
            },
            "coat_length": {
                "question": "è¿™åªçŒ«å’ªçš„æ¯›é•¿å¦‚ä½•ï¼Ÿ",
                "options": ["çŸ­æ¯›", "ä¸­é•¿æ¯›", "é•¿æ¯›", "å·æ¯›", "å‡ ä¹æ— æ¯›"],
                "priority": 1
            },
            "ear_type": {
                "question": "è¿™åªçŒ«å’ªçš„è€³æœµæ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ",
                "options": ["æ­£å¸¸ç«‹è€³", "å‘å‰æŠ˜å ", "å‘ä¸‹æŠ˜å ", "è€³æœµç‰¹åˆ«å¤§", "è€³æœµç‰¹åˆ«å°"],
                "priority": 2
            },
            "face_shape": {
                "question": "è¿™åªçŒ«å’ªçš„è„¸å‹å¦‚ä½•ï¼Ÿ",
                "options": ["åœ†è„¸æ‰é¼»", "æ™®é€šè„¸å‹", "å°–è„¸é•¿é¼»", "ä¸‰è§’å½¢è„¸"],
                "priority": 2
            },
            "body_type": {
                "question": "è¿™åªçŒ«å’ªçš„ä½“å‹å¦‚ä½•ï¼Ÿ",
                "options": ["å°å‹çº¤ç»†", "ä¸­å‹", "å¤§å‹å£®å®", "è‚Œè‚‰å‘è¾¾"],
                "priority": 3
            },
            "eye_color": {
                "question": "è¿™åªçŒ«å’ªçš„çœ¼ç›æ˜¯ä»€ä¹ˆé¢œè‰²ï¼Ÿ",
                "options": ["è“è‰²", "ç»¿è‰²", "é»„è‰²/é‡‘è‰²", "å¼‚è‰²ç³", "ä¸ç¡®å®š"],
                "priority": 3
            },
            "tail_type": {
                "question": "è¿™åªçŒ«å’ªçš„å°¾å·´å¦‚ä½•ï¼Ÿ",
                "options": ["é•¿å°¾", "çŸ­å°¾", "å‡ ä¹æ— å°¾", "å°¾å·´ç‰¹åˆ«è“¬æ¾"],
                "priority": 4
            }
        }
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºç¼ºå¤±ç‰¹å¾
        prioritized_features = sorted(
            [f for f in missing_features if f in feature_questions],
            key=lambda f: feature_questions[f]["priority"]
        )
        
        # ç”Ÿæˆé—®é¢˜ï¼ˆæœ€å¤š3ä¸ªï¼‰
        for feature in prioritized_features[:3]:
            question_info = feature_questions[feature]
            result["questions"].append({
                "feature_category": feature,
                "question": question_info["question"],
                "options": question_info["options"],
                "priority": question_info["priority"]
            })
        
        # å¦‚æœæœ‰å¤šä¸ªå€™é€‰å“ç§ï¼Œç”ŸæˆåŒºåˆ†æ€§é—®é¢˜
        if candidate_breeds and len(candidate_breeds) > 1:
            # è¿™é‡Œå¯ä»¥æ ¹æ®å€™é€‰å“ç§ç”Ÿæˆæ›´å…·é’ˆå¯¹æ€§çš„é—®é¢˜
            # ç®€åŒ–ç‰ˆæœ¬ï¼šè¯¢é—®æ˜¯å¦æœ‰ç‰¹å®šå“ç§çš„æ ‡å¿—æ€§ç‰¹å¾
            result["questions"].append({
                "feature_category": "breed_specific",
                "question": "è¿™åªçŒ«å’ªæœ‰æ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«æ˜æ˜¾çš„ç‰¹å¾ï¼Ÿæ¯”å¦‚æŠ˜è€³ã€æ‰è„¸ã€æ— å°¾ã€è“çœ¼ç­‰ï¼Ÿ",
                "options": ["æœ‰ï¼Œè¯·æè¿°", "æ²¡æœ‰ç‰¹åˆ«æ˜æ˜¾çš„ç‰¹å¾"],
                "priority": 1
            })
        
        if result["questions"]:
            result["rationale"] = f"å½“å‰ç½®ä¿¡åº¦ä¸º{current_confidence}ï¼Œç¼ºå¤±{len(missing_features)}ä¸ªç‰¹å¾ç±»åˆ«ï¼Œå»ºè®®è¿½é—®ä»¥æé«˜å‡†ç¡®åº¦"
        else:
            result["should_ask"] = False
            result["rationale"] = "æ— éœ€è¿½é—®æˆ–æ— æ³•ç”Ÿæˆæœ‰æ•ˆé—®é¢˜"
        
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        error_result = {
            "should_ask": False,
            "questions": [],
            "rationale": f"ç”Ÿæˆè¿½é—®é—®é¢˜å¤±è´¥: {str(e)}"
        }
        return json.dumps(error_result, ensure_ascii=False, indent=2)


@tool
def calculate_feature_completeness(
    extracted_features: Dict[str, List[str]],
    required_features: Optional[List[str]] = None
) -> str:
    """
    è®¡ç®—ç‰¹å¾å®Œæ•´æ€§è¯„åˆ†
    
    åŠŸèƒ½ï¼š
    - è¯„ä¼°å·²æä¾›ç‰¹å¾çš„å®Œæ•´ç¨‹åº¦
    - è¯†åˆ«å…³é”®ç¼ºå¤±ç‰¹å¾
    - ä¸ºç½®ä¿¡åº¦è¯„ä¼°æä¾›ä¾æ®
    
    Args:
        extracted_features: å·²æå–çš„ç‰¹å¾å­—å…¸
        required_features: å¿…éœ€ç‰¹å¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        str: JSONæ ¼å¼çš„å®Œæ•´æ€§è¯„ä¼°ç»“æœ
        {
            "completeness_score": float,  # 0.0-1.0
            "completeness_level": str,    # "é«˜" / "ä¸­" / "ä½"
            "provided_features": List[str],
            "missing_features": List[str],
            "critical_missing": List[str],
            "recommendation": str
        }
    """
    try:
        if required_features is None:
            required_features = [
                "coat_color", "coat_length", "body_type",
                "face_shape", "ear_type"
            ]
        
        # è¯†åˆ«å…³é”®ç‰¹å¾ï¼ˆæƒé‡æ›´é«˜ï¼‰
        critical_features = ["coat_color", "coat_length", "ear_type"]
        
        result = {
            "completeness_score": 0.0,
            "completeness_level": "ä½",
            "provided_features": [],
            "missing_features": [],
            "critical_missing": [],
            "recommendation": ""
        }
        
        # ç»Ÿè®¡å·²æä¾›çš„ç‰¹å¾
        provided = []
        for feature, values in extracted_features.items():
            if values and feature in required_features:
                provided.append(feature)
        
        result["provided_features"] = provided
        
        # è¯†åˆ«ç¼ºå¤±ç‰¹å¾
        missing = [f for f in required_features if f not in provided]
        result["missing_features"] = missing
        
        # è¯†åˆ«å…³é”®ç¼ºå¤±ç‰¹å¾
        critical_missing = [f for f in critical_features if f in missing]
        result["critical_missing"] = critical_missing
        
        # è®¡ç®—å®Œæ•´æ€§è¯„åˆ†
        # åŸºç¡€åˆ†ï¼šå·²æä¾›ç‰¹å¾ / å¿…éœ€ç‰¹å¾
        base_score = len(provided) / len(required_features) if required_features else 0
        
        # å…³é”®ç‰¹å¾æƒ©ç½šï¼šæ¯ç¼ºå¤±ä¸€ä¸ªå…³é”®ç‰¹å¾æ‰£10%
        critical_penalty = len(critical_missing) * 0.1
        
        final_score = max(0.0, base_score - critical_penalty)
        result["completeness_score"] = round(final_score, 2)
        
        # è¯„å®šå®Œæ•´æ€§ç­‰çº§
        if final_score >= 0.7:
            result["completeness_level"] = "é«˜"
            result["recommendation"] = "ç‰¹å¾ä¿¡æ¯è¾ƒå®Œæ•´ï¼Œå¯ä»¥è¿›è¡Œå‡†ç¡®è¯†åˆ«"
        elif final_score >= 0.4:
            result["completeness_level"] = "ä¸­"
            result["recommendation"] = "ç‰¹å¾ä¿¡æ¯éƒ¨åˆ†å®Œæ•´ï¼Œå»ºè®®è¡¥å……å…³é”®ç‰¹å¾ä»¥æé«˜å‡†ç¡®åº¦"
        else:
            result["completeness_level"] = "ä½"
            result["recommendation"] = "ç‰¹å¾ä¿¡æ¯ä¸è¶³ï¼Œå¼ºçƒˆå»ºè®®è¡¥å……æ›´å¤šç‰¹å¾æè¿°"
        
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        error_result = {
            "completeness_score": 0.0,
            "completeness_level": "ä½",
            "provided_features": [],
            "missing_features": required_features or [],
            "critical_missing": [],
            "recommendation": f"è¯„ä¼°å¤±è´¥: {str(e)}"
        }
        return json.dumps(error_result, ensure_ascii=False, indent=2)
